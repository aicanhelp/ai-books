# 1.15. 等式回归

校验者:
        [@STAN,废柴0.1](https://github.com/apachecn/scikit-learn-doc-zh)
翻译者:
        [@Damon](https://github.com/apachecn/scikit-learn-doc-zh)

[`IsotonicRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html#sklearn.isotonic.IsotonicRegression "sklearn.isotonic.IsotonicRegression") 类对数据进行非降函数拟合. 它解决了如下的问题:

* 最小化 ![\sum_i w_i (y_i - \hat{y}_i)^2](img/156554c81cfe5f0230627ac0487fd07f.jpg)

* 服从于 ![\hat{y}_{min} = \hat{y}_1 \le \hat{y}_2 ... \le \hat{y}_n = \hat{y}_{max}](img/6c446734a6837b7541db12e2b55f1a2b.jpg)

其中每一个 ![w_i](img/6689aa593e8e42bb5c2caa474e642b5f.jpg) 是 strictly 正数而且每个 ![y_i](img/4a22ca544916918b2358e5fc7c71b8e6.jpg) 是任意实 数. 它生成一个由平方误差接近的不减元素组成的向量.实际上这一些元素形成 一个分段线性的函数.

[![http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_isotonic_regression_0011.png](img/87ae31ef4f2e7b4385b9a25aa8fed533.jpg)](https://scikit-learn.org/stable/auto_examples/plot_isotonic_regression.html)

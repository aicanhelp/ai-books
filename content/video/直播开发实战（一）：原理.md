# 如何开发出一款仿映客直播APP项目实践篇 -【原理篇】

> 前言：每个成功者多是站在巨人的肩膀上！在做直播开发时 碰到了很多问题，在收集了许多人博客的基础上做出来了成功的直播项目并做了整理，并在最后奉上我的全部代码。

##### 其中采用博客的博主开篇在此感谢，本着开源分享的精神，我会将前辈的知识和自己开发中遇到的问题整理出完整的一套开发流程，再次希望采用的博主，能够容许使用并再次感谢！ 大多内容其他博客给出不错详解就整理摘抄到此篇，原理篇相关技术点主要来自于[袁峥Seemygo](https://www.jianshu.com/users/b09c3959ab3b)分享整理。采集和服务器推流会有所不同（在原有的基础上添加另一种<LFLiveKit>第三方框架来采集视频、美颜和推流等功能) ,  为节省时间如有雷同之处，也请一些童靴不喜勿喷！

##### 【目录】

- [如何开发出一款仿映客直播APP项目实践篇 -【原理篇】](https://www.jianshu.com/p/b2674fc2ac35)
- [如何开发出一款仿映客直播APP项目实践篇 -【采集篇 】](https://www.jianshu.com/p/099c2c875524)
- [如何开发出一款仿映客直播APP项目实践篇 -【服务器搭建+推流】](https://www.jianshu.com/p/ed9eb96afa78)
- [如何开发出一款仿映客直播APP项目实践篇 -【播放篇】](https://www.jianshu.com/p/f5a41b9ec05f)

## 模块一 ：直播技术

------

#### 【 主要模块】

- **主播端：**  把主播实时录制的视频，经过（采集、美颜处理、编码）推送到服务器
- **服务器：**  处理（转码、录制、截图、鉴黄）后分发给用户播放端
- **播放器：**   获取服务器地址， 进行拉流、解码、渲染
- **互动系统：**  聊天室、礼物系统、赞

示例图：

![img](https:////upload-images.jianshu.io/upload_images/1929699-601a314294b7f5d4.jpg)

七牛云的直播图更直观详细

直播效果图

![img](https:////upload-images.jianshu.io/upload_images/1929699-b34d18fc3dbea080.PNG)

IMG_4340.PNG

#### 【一个完整直播app实现流程】

1.采集、2.滤镜处理、3.编码、4.推流、5.CDN分发、6.拉流、7.解码、8.播放、9.聊天互动

![img](https:////upload-images.jianshu.io/upload_images/1929699-1cfb42e6cd5fd397.png)

直播流程.png

#### 【一个完整直播app架构】

![img](https:////upload-images.jianshu.io/upload_images/1929699-31cf4de9b47447e9.png)

直播架构.png

#### 【一个完整直播app技术点】

![img](https:////upload-images.jianshu.io/upload_images/1929699-4d3ee68aaba2c75d.jpeg)

相关技术点

## 模块二、项目功能模块 ->  技术

------

简介：
 相对于上面图中每个技术点刨开来说都很繁琐 ，也很难掌握，我会在下面的【相关技术知识点概括】中给与大致讲述；由于涉及音视频的编码解码、美颜功能的算法，帧的处理等很多问题，能从底层自己开发的完整功能的绝对是大牛！
 不过正是有这些大牛们的奉献 ，我们不需要处理繁琐的底层问题，一些封装好的库可以完美实现。

------

- **主播端**:    ** [LFLiveKit](https://link.jianshu.com?t=https://github.com/LaiFengiOS/LFLiveKit)** 已包含**采集**、**美颜**、**编码**、**推流**等功能

- **服务器** :  【 ** nginx+rtmp服务器**】免费开源，能搭建本地电脑上，支持RTMP协议，满足直播需求。

- **播放端** :   ** [ijkplayer视频直播框架](https://link.jianshu.com?t=https://github.com/Bilibili/ijkplayer)** 封装很完善只要有url，就可以实时播放

## 模块三、如何快速的开发一个完整的iOS直播app

------

1、利用第三方直播SDK快速的开发

[阿里云](https://link.jianshu.com?t=https://www.aliyun.com/solution/media/?utm_medium=text&utm_source=baidu&utm_campaign=hyy&utm_content=se_119787):  提供低延迟、高清晰、 高并发支持的直播服务，帮您从容应对业务突发峰值。广泛应用于 游戏直播、娱乐直播、泛生活直播、 教育类、 远程医疗、 企业远程视频会议等典型场景，
 [百度直播云](https://link.jianshu.com?t=https://cloud.baidu.com/index.html?t=cp:nsem|pf:pc|pp:baiducloud|pu:baiducloud|kw:1231): 视频直播、点播一站式解决方案，让视频技术零门槛，结合领先的人工智能技术，开放智能图像识别、视频特效、黄反审核功能，让视频内容更丰富，更安全
 [七牛云](https://link.jianshu.com?t=http://www.qiniu.com/?utm_campaign=baiduSEM&utm_source=baiduSEM&utm_medium=baiduSEM&utm_content=baiduSEM):七牛直播云是专为直播平台打造的全球化直播流服务和一站式实现SDK端到端直播场景的企业级直播云服务平台.

2、自研还是使用第三方直播SDK开发？
 自研： 对于一个初创公司或团队来讲，自研直播不管在技术门槛、CDN、带宽上都是有很大的门槛的，而且需要耗费大量的时间和成本才能做出成品，不利于前期发展。
 第三方SDK开发：开发周期短，前期投入少，从长远看，第三方费用较高，占很大一笔支出， 相对来说自研可以节省成本，技术成面比直接用SDK相对可控。

### 模块四、相关技术知识点概括 （[袁峥Seemygo](https://www.jianshu.com/users/b09c3959ab3b)分享）

------

###### 1.采集视频、音频

***** 1.1 采集视频、音频编码框架 *****
 AVFoundation:AVFoundation是用来播放和创建实时的视听媒体数据的框架，同时提供Objective-C接口来操作这些视听数据，比如编辑，旋转，重编码

***** 1.2 视频、音频硬件设备 *****
 CCD:图像传感器： 用于图像采集和处理的过程，把图像转换成电信号。
 拾音器:声音传感器： 用于声音采集和处理的过程，把声音转换成电信号。
 音频采样数据:一般都是PCM格式
 视频采样数据: 一般都是YUV,或RGB格式，采集到的原始音视频的体积是非常大的，需要经过压缩技术处理来提高传输效率

###### 2.视频处理（美颜，水印）

视频处理原理:因为视频最终也是通过GPU，一帧一帧渲染到屏幕上的，所以我们可以利用OpenGL ES，对视频帧进行各种加工，从而视频各种不同的效果，就好像一个水龙头流出的水，经过若干节管道，然后流向不同的目标
 现在的各种美颜和视频添加特效的app都是利用GPUImage
 这个框架实现的,.

***** 视频处理框架 *****
 GPUImage: GPUImage是一个基于OpenGL ES的一个强大的图像/视频处理框架,封装好了各种滤镜同时也可以编写自定义的滤镜,其本身内置了多达120多种常见的滤镜效果。
 OpenGL:OpenGL（全写Open Graphics Library）是个定义了一个跨编程语言、跨平台的编程接口的规格，它用于三维图象（二维的亦可）。OpenGL是个专业的图形程序接口，是一个功能强大，调用方便的底层图形库。
 OpenGL ES:OpenGL ES (OpenGL for Embedded Systems) 是 OpenGL三维图形 API 的子集，针对手机、PDA和游戏主机等嵌入式设备而设计。

###### 3.视频编码解码

***** 3.1 视频编码框架 *****
 FFmpeg :是一个跨平台的开源视频框架,能实现如视频编码,解码,转码,串流,播放等丰富的功能。其支持的视频格式以及播放协议非常丰富,几乎包含了所有音视频编解码、封装格式以及播放协议。-Libswresample:可以对音频进行重采样,rematrixing 以及转换采样格式等操 作。
 -Libavcodec:提供了一个通用的编解码框架,包含了许多视频,音频,字幕流 等编码/解码器。
 -Libavformat:用于对视频进行封装/解封装。
 -Libavutil:包含一些共用的函数,如随机数生成,数据结构,数学运算等。
 -Libpostproc:用于进行视频的一些后期处理。
 -Libswscale:用于视频图像缩放,颜色空间转换等。
 -Libavfilter:提供滤镜功能。

X264 :把视频原数据YUV编码压缩成H.264格式
 VideoToolbox :苹果自带的视频硬解码和硬编码API，但是在iOS8之后才开放。
 AudioToolbox :苹果自带的音频硬解码和硬编码API

***** 3.2 视频编码技术 *****
 视频压缩编码标准：对视频进行压缩(视频编码)或者解压缩（视频解码）的编码技术,比如MPEG，H.264。

这些视频编码技术是压缩编码视频的主要作用:是将视频像素数据压缩成为视频码流，从而降低视频的数据量。如果视频不经过压缩编码的话，体积通常是非常大的，一部电影可能就要上百G的空间。

注意:最影响视频质量的是其视频编码数据和音频编码数据，跟封装格式没有多大关系

MPEG:一种视频压缩方式，它采用了帧间压缩，仅存储连续帧之间有差别的地方 ，从而达到较大的压缩比
 H.264/AVC:一种视频压缩方式,采用事先预测和与MPEG中的P-B帧一样的帧预测方法压缩，它可以根据需要产生适合网络情况传输的视频流,还有更高的压缩比，有更好的图象质量

注意1: 如果是从单个画面清晰度比较，MPEG4有优势；从动作连贯性上的清晰度，H.264有优势
 注意2: 由于264的算法更加复杂，程序实现烦琐，运行它需要更多的处理器和内存资源。因此，运行264对系统要求是比较高的。
 注意3: 由于264的实现更加灵活，它把一些实现留给了厂商自己去实现，虽然这样给实现带来了很多好处，但是不同产品之间互通成了很大的问题，造成了通过A公司的编码器编出的数据，必须通过A公司的解码器去解这样尴尬的事情

H.265/HEVC: 一种视频压缩方式,基于H.264，保留原来的某些技术，同时对一些相关的技术加以改进，以改善码流、编码质量、延时和算法复杂度之间的关系，达到最优化设置。H.265 是一种更为高效的编码标准，能够在同等画质效果下将内容的体积压缩得更小，传输时更快更省带宽

I帧: (关键帧)保留一副完整的画面，解码时只需要本帧数据就可以完成（因为包含完整画面）

P帧 :(差别帧)保留这一帧跟之前帧的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（P帧没有完整画面数据，只有与前一帧的画面差别的数据）

B帧: (双向差别帧)保留的是本帧与前后帧的差别，解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累

帧内（Intraframe）压缩: 当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息,帧内一般采用有损压缩算法

帧间（Interframe）压缩: 时间压缩（Temporal compression），它通过比较时间轴上不同帧之间的数据进行压缩。帧间压缩一般是无损的

muxing（合成）：将视频流、音频流甚至是字幕流封装到一个文件中(容器格式（FLV，TS）)，作为一个信号进行传输。

***** 3.3 音频编码技术 *****
 AAC，mp3：这些属于音频编码技术,压缩音频用

***** 3.4码率控制 *****
 多码率:观众所处的网络情况是非常复杂的，有可能是WiFi，有可能4G、3G、甚至2G，那么怎么满足多方需求呢？多搞几条线路，根据当前网络环境自定义码率。列如：常常看见视频播放软件中的1024，720，高清，标清，流畅等，指的就是各种码率。

***** 3.5 视频封装格式 *****
 TS:  一种流媒体封装格式，流媒体封装有一个好处，就是不需要加载索引再播放，大大减少了首次载入的延迟，如果片子比较长，mp4文件的索引相当大，影响用户体验
 为什么要用TS: 这是因为两个TS片段可以无缝拼接，播放器能连续播放

FLV:  一种流媒体封装格式,由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能,因此FLV格式成为了当今主流视频格式

###### 4.推流

***** 4.1 数据传输框架 *****
 librtmp: 用来传输RTMP协议格式的数据
 ***** 4.2 流媒体数据传输协议 *****
 RTMP: 实时消息传输协议,Adobe Systems公司为Flash播放器和服务器之间音频、视频和数据传输开发的开放协议，因为是开放协议所以都可以使用了。
 RTMP协议用于对象、视频、音频的传输，这个协议建立在TCP协议或者轮询HTTP协议之上。
 RTMP协议就像一个用来装数据包的容器，这些数据可以是FLV中的视音频数据。一个单一的连接可以通过不同的通道传输多路网络流，这些通道中的包都是按照固定大小的包传输的

###### 5.流媒体服务器

***** 5.1常用服务器 *****
 SRS：一款国人开发的优秀开源流媒体服务器系统
 BMS: 也是一款流媒体服务器系统，但不开源，是SRS的商业版，比SRS功能更多
 nginx: 免费开源web服务器，常用来配置流媒体服务器。

***** 5.2数据分发 *****
 CDN：(Content Delivery Network)，即内容分发网络,将网站的内容发布到最接近用户的网络”边缘”，使用户可以就近取得所需的内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度.
 CDN：代理服务器，相当于一个中介。
 CDN工作原理：比如请求流媒体数据1.上传流媒体数据到服务器（源站）
 2.源站存储流媒体数据
 3.客户端播放流媒体，向CDN请求编码后的流媒体数据
 4.CDN的服务器响应请求，若节点上没有该流媒体数据存在，则向源站继续请求流媒体数据；若节点上已经缓存了该视频文件，则跳到第6步。
 5.源站响应CDN的请求，将流媒体分发到相应的CDN节点上
 6.CDN将流媒体数据发送到客户端

回源：当有用户访问某一个URL的时候，如果被解析到的那个CDN节点没有缓存响应的内容，或者是缓存已经到期，就会回源站去获取搜索。如果没有人访问，那么CDN节点不会主动去源站拿.
 带宽: 在固定的时间可传输的数据总量，比如64位、800MHz的前端总线，它的数据传输率就等于64bit×800MHz÷8(Byte)=6.4GB/s

负载均衡: 由多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，都可以单独对外提供服务而无须其他服务器的辅助.通过某种负载分担技术，将外部发送来的请求均匀分配到对称结构中的某一台服务器上，而接收到请求的服务器独立地回应客户的请求。
 均衡负载能够平均分配客户请求到服务器列阵，籍此提供快速获取重要数据，解决大量并发访问服务问题。
 这种群集技术可以用最少的投资获得接近于大型主机的性能。

QoS（带宽管理）:限制每一个组群的带宽，让有限的带宽发挥最大的效用

###### 6.拉流

直播协议选择：即时性要求较高或有互动需求的可以采用RTMP,RTSP

对于有回放或跨平台需求的，推荐使用HLS

直播协议对比:

![img](https:////upload-images.jianshu.io/upload_images/1929699-32eacda85b298668.png)

直播协议对比.png

HLS: 由Apple公司定义的用于实时流传输的协议,HLS基于HTTP协议实现，传输内容包括两部分，一是M3U8描述文件，二是TS媒体文件。可实现流媒体的直播和点播，主要应用在iOS系统HLS是以点播的技术方式
 来实现直播
 HLS是自适应码率流播，客户端会根据网络状况自动选择不同码率的视频流，条件允许的情况下使用高码率，网络繁忙的时候使用低码率，并且自动在二者间随意切换。这对移动设备网络状况不稳定的情况下保障流畅播放非常有帮助。
 实现方法是服务器端提供多码率视频流，并且在列表文件中注明，播放器根据播放进度和下载速度自动调整。

HLS与RTMP对比: HLS主要是延时比较大，RTMP主要优势在于延时低HLS协议的小切片方式会生成大量的文件，存储或处理这些文件会造成大量资源浪费
 相比使用RTSP协议的好处在于，一旦切分完成，之后的分发过程完全不需要额外使用任何专门软件，普通的网络服务器即可，大大降低了CDN边缘服务器的配置要求，可以使用任何现成的CDN,而一般服务器很少支持RTSP。

HTTP-FLV: 基于HTTP协议流式的传输媒体内容。相对于RTMP，HTTP更简单和广为人知，内容延迟同样可以做到1~3秒，打开速度更快，因为HTTP本身没有复杂的状态交互。所以从延迟角度来看，HTTP-FLV要优于RTMP。

RTSP:实时流传输协议,定义了一对多应用程序如何有效地通过IP网络传送多媒体数据.
 RTP: 实时传输协议,RTP是建立在UDP协议上的，常与RTCP一起使用，其本身并没有提供按时发送机制或其它服务质量（QoS）保证，它依赖于低层服务去实现这一过程。
 RTCP: RTP的配套协议,主要功能是为RTP所提供的服务质量（QoS）提供反馈，收集相关媒体连接的统计信息，例如传输字节数，传输分组数，丢失分组数，单向和双向网络延迟等等。

##### 7.解码

***** 7.1 解封装 *****
 demuxing（分离）
 ：从视频流、音频流，字幕流合成的文件(容器格式（FLV，TS）
 )中， 分解出视频、音频或字幕，各自进行解码。

***** 7.2 音频编码框架 *****
 fdk_aac:音频编码解码框架，PCM音频数据和AAC音频数据互转

***** 7.3 解码介绍 *****
 硬解码：用GPU来解码，减少CPU运算　优点：播放流畅、低功耗，解码速度快，　 * 缺点：兼容不好

软解码：用CPU来解码优点：兼容好　　 * 缺点：加大CPU负担，耗电增加、没有硬解码流畅，解码速度相对慢

##### 8.播放

[ijkplayer](https://link.jianshu.com?t=https://github.com/Bilibili/ijkplayer?utm_source=tuicool&utm_medium=referral):一个基于FFmpeg的开源Android/iOS视频播放器API易于集成；
 编译配置可裁剪，方便控制安装包大小；
 支持硬件加速解码，更加省电
 简单易用，指定拉流URL，自动解码播放.

##### 9.聊天互动

IM:(InstantMessaging)即时通讯:是一个实时通信系统，允许两人或多人使用网络实时的传递文字消息、文件、语音与视频交流.IM
 在直播系统中的主要作用是实现观众与主播、观众与观众之间的文字互动.

### 七牛云直播流程

开篇，将从整体介绍直播中的各个环节。

![img](https:////upload-images.jianshu.io/upload_images/1929699-5b2be4958f3eb00d)

**1.采集**
 采集是播放环节中的第一环，iOS 系统因为软硬件种类不多，硬件适配性较好，所以比较简单。Android 则不同，市面上硬件机型非常多，难以做到一个库适配所有硬件。PC 端的采集也跟各种摄像头驱动有关，推荐使用目前市面上最好用的 PC 端开源免费软件 OBS。

- **音频采集**

------

音频数据既能与图像结合组合成视频数据，也能以纯音频的方式采集播放，后者在很多成熟的应用场景如在线电台和语音电台等起着非常重要的作用。音频的采集过程主要通过设备将环境中的模拟信号采集成 PCM 编码的原始数据，然后编码压缩成 MP3 等格式的数据分发出去。常见的音频压缩格式有：MP3，AAC，OGG，WMA，Opus，FLAC，APE，m4a 和 AMR 等。

音频采集和编码主要面临的挑战在于：延时敏感、卡顿敏感、噪声消除（Denoise）、回声消除（AEC）、静音检测（VAD）和各种混音算法等。

在音频采集阶段，参考的主要技术参数有 ：
 采样率（samplerate）：采样就是把模拟信号数字化的过程，采样频率越高，记录这一段音频信号所用的数据量就越大，同时音频质量也就越高。

位宽：每一个采样点都需要用一个数值来表示大小，这个数值的数据类型大小可以是：4bit、8bit、16bit、32bit 等等，位数越多，表示得就越精细，声音质量自然就越好，而数据量也会成倍增大。我们在音频采样过程中常用的位宽是 8bit 或者 16bit。

声道数（channels）：由于音频的采集和播放是可以叠加的，因此，可以同时从多个音频源采集声音，并分别输出到不同的扬声器，故声道数一般表示声音录制时的音源数量或回放时相应的扬声器数量。声道数为 1 和 2 分别称为单声道和双声道，是比较常见的声道参数。

音频帧（frame）：音频跟视频很不一样，视频每一帧就是一张图像，而从上面的正玄波可以看出，音频数据是流式的，本身没有明确的一帧帧的概念，在实际的应用中，为了音频算法处理/传输的方便，一般约定俗成取 2.5ms~60ms 为单位的数据量为一帧音频。这个时间被称之为“采样时间”，其长度没有特别的标准，它是根据编解码器和具体应用的需求来决定的。

根据以上定义，我们可以计算一下一帧音频帧的大小。假设某音频信号是采样率为 8kHz、双通道、位宽为 16bit，20ms 一帧，则一帧音频数据的大小为：
 size = 8000 x 2 x 16bit x 0.02s = 5120 bit = 640 byte

------

- ** 图像采集**

------

图像采集的图片结果组合成一组连续播放的动画，即构成视频中可肉眼观看的内容。图像的采集过程主要由摄像头等设备拍摄成 YUV 编码的原始数据，然后经过编码压缩成 H.264 等格式的数据分发出去。常见的视频封装格式有：MP4、3GP、AVI、MKV、WMV、MPG、VOB、FLV、SWF、MOV、RMVB 和 WebM 等。

图像由于其直观感受最强并且体积也比较大，构成了一个视频内容的主要部分。图像采集和编码面临的主要挑战在于：设备兼容性差、延时敏感、卡顿敏感以及各种对图像的处理操作如美颜和水印等。

在图像采集阶段，参考的主要技术参数有：
 图像传输格式：通用影像传输格式（Common Intermediate Format）是视讯会议（video conference）中常使用的影像传输格式。

图像格式：通常采用 YUV 格式存储原始数据信息，其中包含用 8 位表示的黑白图像灰度值，以及可由 RGB 三种色彩组合成的彩色图像。

传输通道：正常情况下视频的拍摄只需 1 路通道，随着 VR 和 AR 技术的日渐成熟，为了拍摄一个完整的 360° 视频，可能需要通过不同角度拍摄，然后经过多通道传输后合成。

分辨率：随着设备屏幕尺寸的日益增多，视频采集过程中原始视频分辨率起着越来越重要的作用，后续处理环节中使用的所有视频分辨率的定义都以原始视频分辨率为基础。视频采集卡能支持的最大点阵反映了其分辨率的性能。

采样频率：采样频率反映了采集卡处理图像的速度和能力。在进行高度图像采集时，需要注意采集卡的采样频率是否满足要求。采样率越高，图像质量越高，同时保存这些图像信息的数据量也越大。

以上，构成了一个视频采集的主要技术参数，以及视频中音频和图像编码的常用格式。而对于直播 App 开发者来说，了解这些细节虽然更有帮助，但实际开发过程中可能很少能够关注采集环节中技术参数的控制，而是直接在 SDK 中将采集后的数据传递给下一个「处理」和「编码」环节。

**2.处理**

视频或者音频完成采集之后得到原始数据，为了增强一些现场效果或者加上一些额外的效果，我们一般会在将其编码压缩前进行处理，比如打上时间戳或者公司 Logo 的水印，祛斑美颜和声音混淆等处理。在主播和观众连麦场景中，主播需要和某个或者多个观众进行对话，并将对话结果实时分享给其他所有观众，连麦的处理也有部分工作在推流端完成。

开放式设计

![img](https:////upload-images.jianshu.io/upload_images/1929699-b7e3e95075275740)

如上图所示，处理环节中分为音频和视频处理，音频处理中具体包含混音、降噪和声音特效等处理，视频处理中包含美颜、水印、以及各种自定义滤镜等处理。

「80% 的主播没有美颜根本没法看。」不光是美颜，很多其它的视频处理如模糊效果、水印等也都是在这个环节做。目前 iOS 端比较知名的是 GPUImage 这个库，提供了丰富端预处理效果，还可以基于这个库自己写算法实现更丰富端效果。Android 也有 GPUImage 这个库的移植，叫做 android-gpuimage。同时，Google 官方开源了一个伟大的库，覆盖了 Android 上面很多多媒体和图形图像相关的处理。
 美颜的主要原理是通过「磨皮+美白」来达到整体美颜的效果。磨皮的技术术语是「去噪」，也即对图像中的噪点进行去除或者模糊化处理，常见的去噪算法有均值模糊、高斯模糊和中值滤波等。当然， 由于脸部的每个部位不尽相同，脸上的雀斑可能呈现出眼睛黑点的样子，对整张图像进行「去噪」处理的时候不需要将眼睛也去掉，因此这个环节中也涉及到人脸和皮肤检测技术。

**3.编码和封装**
 编码主要难点有两个：1. 处理硬件兼容性问题。2. 在高 fps、低 bitrate 和音质画质之间找到平衡。iOS 端硬件兼容性较好，可以直接采用硬编。而 Android 的硬编的支持则难得多，需要支持各种硬件机型，推荐使用软编。

###### 为什么封装？

原始视频数据存储空间大，一个 1080P 的 7 s 视频需要 817 MB

原始视频数据传输占用带宽大，10 Mbps 的带宽传输上述 7 s 视频需要 11 分钟

而经过 H.264 编码压缩之后，视频大小只有 708 k ,10 Mbps 的带宽仅仅需要 500 ms ，可以满足实时传输的需求，所以从视频采集传感器采集来的原始视频势必要经过视频编码。
 基本原理
 那为什么巨大的原始视频可以编码成很小的视频呢？这其中的技术是什么呢？核心思想就是去除冗余信息：
 空间冗余：图像相邻像素之间有较强的相关性

时间冗余：视频序列的相邻图像之间内容相似

编码冗余：不同像素值出现的概率不同

视觉冗余：人的视觉系统对某些细节不敏感

知识冗余：规律性的结构可由先验知识和背景知识得到
 详细介绍：[七牛的编码和封装原理](https://link.jianshu.com?t=http://blog.qiniu.com/archives/6816)

**4.推流和传输**
 传输涉及到很多端：从主播端到服务端，从收流服务端到边缘节点，以及再从边缘节点到观众端。

推流端和分发端理论上需要支持的并发用户数应该都是亿级的，不过毕竟产生内容的推流端在少数，和消费内容端播放端不是一个量级，但是他们对推流稳定性和速度的要求比播放端高很多，这涉及到所有播放端能否看到直播，以及直播端质量如何。

详情介绍: [推流和传输](https://link.jianshu.com?t=http://blog.qiniu.com/archives/6914)

**5.转码**
 为了让主播推上来的流适配各个平台端各种不同协议，需要在服务端做一些流处理工作，比如转码成不同格式支持不同协议如 RTMP、HLS 和 FLV，一路转多路流来适配各种不同的网络状况和不同分辨率的终端设备。

**6.解码和渲染**
 解码和渲染，也即音视频的播放，目前 iOS 端的播放兼容性较好，在延迟可接受的情况下使用 HLS 协议是最好的选择，我们也提供了能够播放 RTMP 和 HLS 的播放器 SDK。Android 的硬件解码和编码一样也存在兼容性问题，目前比较好的开源播放器是基于 ffplay 的 ijkplayer，

### gitHub代码地址

**Object-C版** :  [https://github.com/one-tea/ZKKLiveDemo](https://link.jianshu.com?t=https://github.com/one-tea/ZKKLiveDemo)
 **Swift版**       : [https://github.com/one-tea/ZKKLiveAPP_Swift3.0](https://link.jianshu.com?t=https://github.com/one-tea/ZKKLiveAPP_Swift3.0)



作者：_方丈
链接：https://www.jianshu.com/p/b2674fc2ac35
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
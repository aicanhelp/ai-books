# 数据格式概述

数据格式（例如Avro，JSON和日志）是对符合公认规范的数据进行编码的方法。

根据阶段类型和要处理的数据类型，阶段处理数据的方式可以相似。例如，基于文件的来源（例如Directory和SFTP / FTP / FTPS客户端）通常将以相同的方式处理数据格式。同样，基于消息的目的地（例如Kafka Producer和JMS Producer）通常以相同的方式处理数据格式。

本章讨论阶段一般如何处理数据格式。有关舞台如何处理不同数据格式的详细信息，请参见舞台文档的“数据格式”部分。

有关每个起点，处理器或目的地支持的数据格式的信息，请参阅[数据格式支持](https://streamsets.com/documentation/controlhub/latest/help/datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_bcw_qzb_kv)。

## 文件压缩格式

读取文件的源和处理器可以读取未压缩的文件，压缩的文件，档案和压缩的档案。

Hadoop FS自动读取压缩文件。对于其他读取文件的来源和处理器，可以配置压缩格式。

下表按扩展名列出了受支持的文件类型：

| 压缩格式 | 描述                                                         |
| :------- | :----------------------------------------------------------- |
| 未压缩   | 处理配置的数据格式的未压缩文件。                             |
| 压缩的   | 处理通过以下压缩格式压缩的文件: gzip, bzip2, xz, lzma, pack200, DEFLATE, Z |
| 封存     | 处理通过以下归档格式归档的文件：7z, ar, arj, cpio, dump, tar, zip |
| 压缩档案 | 处理由支持的压缩和存档格式创建的压缩存档中的文件。           |
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.utils.cpp_extension\n",
    "\n",
    "`torch.utils.cpp_extension.``CppExtension`( _name_ , _sources_ , _*args_ ,\n",
    "_**kwargs_ )[[source]](_modules/torch/utils/cpp_extension.html#CppExtension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建`setuptools.Extension`为C ++。\n",
    "\n",
    "一个创建`setuptools.Extension`与最低限度（但通常​​足以）参数建立一个C ++扩展的便捷方法。\n",
    "\n",
    "所有参数被转发到`setuptools.Extension`构造。\n",
    "\n",
    "例\n",
    "\n",
    "    \n",
    "    \n",
    "    >>> from setuptools import setup\n",
    "    >>> from torch.utils.cpp_extension import BuildExtension, CppExtension\n",
    "    >>> setup(\n",
    "            name='extension',\n",
    "            ext_modules=[\n",
    "                CppExtension(\n",
    "                    name='extension',\n",
    "                    sources=['extension.cpp'],\n",
    "                    extra_compile_args=['-g']),\n",
    "            ],\n",
    "            cmdclass={\n",
    "                'build_ext': BuildExtension\n",
    "            })\n",
    "    \n",
    "\n",
    "`torch.utils.cpp_extension.``CUDAExtension`( _name_ , _sources_ , _*args_ ,\n",
    "_**kwargs_ )[[source]](_modules/torch/utils/cpp_extension.html#CUDAExtension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建`setuptools.Extension  [HTG3用于CUDA / C ++。`\n",
    "\n",
    "一个创建`setuptools.Extension`与最低限度（但通常​​足以）参数建立一个CUDA / C\n",
    "++扩展的便捷方法。这包括CUDA包括路径，库路径和运行时库。\n",
    "\n",
    "All arguments are forwarded to the `setuptools.Extension`constructor.\n",
    "\n",
    "Example\n",
    "\n",
    "    \n",
    "    \n",
    "    >>> from setuptools import setup\n",
    "    >>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
    "    >>> setup(\n",
    "            name='cuda_extension',\n",
    "            ext_modules=[\n",
    "                CUDAExtension(\n",
    "                        name='cuda_extension',\n",
    "                        sources=['extension.cpp', 'extension_kernel.cu'],\n",
    "                        extra_compile_args={'cxx': ['-g'],\n",
    "                                            'nvcc': ['-O2']})\n",
    "            ],\n",
    "            cmdclass={\n",
    "                'build_ext': BuildExtension\n",
    "            })\n",
    "    \n",
    "\n",
    "`torch.utils.cpp_extension.``BuildExtension`( _*args_ , _**kwargs_\n",
    ")[[source]](_modules/torch/utils/cpp_extension.html#BuildExtension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义`setuptools的 `构建扩展。\n",
    "\n",
    "此`setuptools.build_ext`亚类需要经过所需要的最小编译器标志的护理（例如，`-std = C ++ 11`）以及作为混合的C\n",
    "++ / CUDA汇编（和一般为CUDA文件的支持）。\n",
    "\n",
    "当使用 `BuildExtension`，它被允许提供一个字典`extra_compile_args`（而不是通常的列表）从语言映射（`\n",
    "CXX`或`CUDA`）来的额外的编译标志来提供给编译器的列表。这使得可以为混合编译期间提供不同的标记到C ++和CUDA编译器。\n",
    "\n",
    "`torch.utils.cpp_extension.``load`( _name_ , _sources_ , _extra_cflags=None_ ,\n",
    "_extra_cuda_cflags=None_ , _extra_ldflags=None_ , _extra_include_paths=None_ ,\n",
    "_build_directory=None_ , _verbose=False_ , _with_cuda=None_ ,\n",
    "_is_python_module=True_\n",
    ")[[source]](_modules/torch/utils/cpp_extension.html#load)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载PyTorch C ++扩展刚刚在时间（JIT）。\n",
    "\n",
    "要加载的扩展，一个忍者构建文件被发射时，其被用来编译该给定源集成到一个动态库。该库随后被加载到当前的Python程序作为一个模块，并从该函数返回，以备使用。\n",
    "\n",
    "默认情况下，目录到构建文件发出并编译得到的库来为`& LT ; TMP & GT ; / torch_extensions / [ - - ] LT\n",
    ";名称& GT ;`，其中`& LT ; TMP & GT ;`为当前平台上的临时文件夹并`& LT ;名称& GT ;\n",
    "`扩展的名称。这个位置可以通过两种方式来覆盖。首先，如果`TORCH_EXTENSIONS_DIR`环境变量被设置，它取代`& LT ; TMP &\n",
    "GT ; / torch_extensions`和所有的扩展会被编译成这个目录的子文件夹。其次，如果被提供的`BUILD_DIRECTORY\n",
    "`参数给此函数，它会覆盖整个路径，即，库将被直接编译到该文件夹​​。\n",
    "\n",
    "编译源代码，默认的系统编译器（`C ++`）被使用，其可以通过设置`CXX`环境变量被重写。传递额外的参数来编译过程，`\n",
    "EXTRA_CFLAGS`或``可以提供EXTRA_LDFLAGS。例如，为了与编译优化您的扩展，通过`EXTRA_CFLAGS = [ ' -\n",
    "O3']`。您也可以使用`EXTRA_CFLAGS`进一步通过包括目录。\n",
    "\n",
    "提供CUDA支持混合编译。简单地传递CUDA源文件（`.CU`或`.cuh`）与其他来源的沿。这些文件将被检测并与NVCC，而不是C\n",
    "++编译器编译。这包括使CUDA lib64目录作为一个库的目录，和链接`cudart`。可以传递附加标志通过`至NVCC\n",
    "extra_cuda_cflags`，就像`EXTRA_CFLAGS`为C\n",
    "++。为寻找CUDA安装目录各种试探被使用，通常做工精细。如果不是，设置`CUDA_HOME`环境变量是最安全的选择。\n",
    "\n",
    "Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * **名** \\- 扩展的名称来构建。这必须是相同pybind11模块的名称！\n",
    "\n",
    "  * **来源** \\- 相对或绝对路径到C ++源文件的列表。\n",
    "\n",
    "  * **EXTRA_CFLAGS** \\- 编译器标志的可选列表转发到构建。\n",
    "\n",
    "  * **extra_cuda_cflags** \\- 编译器标志的可选列表了建设CUDA源时，NVCC。\n",
    "\n",
    "  * **EXTRA_LDFLAGS** \\- 连接标志的可选列表转发到构建。\n",
    "\n",
    "  * **extra_include_paths** \\- 包括目录的可选列表转发到构建。\n",
    "\n",
    "  * **BUILD_DIRECTORY** \\- 可选路径为构建工作空间使用。\n",
    "\n",
    "  * **冗长** \\- 若`真 `，接通的负载的步骤详细日志记录。\n",
    "\n",
    "  * **with_cuda** \\- 确定CUDA头和库是否被添加到该生成。如果设置为`无 `（默认），该值被自动确定基于的`.CU`或`[HTG11存在] .cuh `在`来源 `。其设置为 TRUE`给力CUDA头文件和库包括在内。\n",
    "\n",
    "  * **is_python_module** \\- 若`真 `（默认），出口所产生的共享库的Python模块。如果`假 `，将其加载到处理作为一个纯动态库。\n",
    "\n",
    "Returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果`is_python_module`是`真 `，返回加载PyTorch扩展作为一个Python模块。如果`is_python_module\n",
    "`是`假 `返回任何（共享库加载到过程作为副作用）。\n",
    "\n",
    "Example\n",
    "\n",
    "    \n",
    "    \n",
    "    >>> from torch.utils.cpp_extension import load\n",
    "    >>> module = load(\n",
    "            name='extension',\n",
    "            sources=['extension.cpp', 'extension_kernel.cu'],\n",
    "            extra_cflags=['-O2'],\n",
    "            verbose=True)\n",
    "    \n",
    "\n",
    "`torch.utils.cpp_extension.``load_inline`( _name_ , _cpp_sources_ ,\n",
    "_cuda_sources=None_ , _functions=None_ , _extra_cflags=None_ ,\n",
    "_extra_cuda_cflags=None_ , _extra_ldflags=None_ , _extra_include_paths=None_ ,\n",
    "_build_directory=None_ , _verbose=False_ , _with_cuda=None_ ,\n",
    "_is_python_module=True_\n",
    ")[[source]](_modules/torch/utils/cpp_extension.html#load_inline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "装载来自串源的PyTorch C ++扩展刚刚在时间（JIT）。\n",
    "\n",
    "此函数的行为完全一样 `负载（） `，但需要它的来源字符串而不是文件名。这些字符串存储到文件中生成目录，之后， `load_inline的行为（） `\n",
    "是相同的 `负载（） `。\n",
    "\n",
    "参见[测试](https://github.com/pytorch/pytorch/blob/master/test/test_cpp_extensions.py)使用此功能的好例子。\n",
    "\n",
    "源可省略典型的非直列C ++扩展的两个必需的部分：必要的头包括，以及所述（pybind11）绑定代码。更精确地，字符串传递给`cpp_sources\n",
    "`首先连接成单个`的.cpp`文件。该文件然后用`前缀的#include  & LT ;torch/ extension.h & GT ;`。\n",
    "\n",
    "此外，如果`功能 `提供参数，绑定将被自动指定为每个功能产生。 `功能\n",
    "`可以是函数名的列表，或者从功能名称来文档字符串的字典映射。如果给出一个列表，每个函数的名称作为它的文档字符串。\n",
    "\n",
    "cuda_sources 被连接到一个单独的`.CU`文件，并通过`torch/ types.h中预先考虑在`来源 `，`cuda.h`和`\n",
    "cuda_runtime.h`包括。的`的.cpp`和`.CU`的文件被单独编译，但最终连接到单个库。注意，没有绑定在`\n",
    "cuda_sources`本身为函数生成的。绑定到一个CUDA内核，你必须创建一个C ++函数调用它，无论是申报或`cpp_sources\n",
    "`的一个定义这个C ++函数（且在HTG36包括它的名字] 功能 `）。\n",
    "\n",
    "参见 `负载（） `为以下省略的参数的描述。\n",
    "\n",
    "Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * **cpp_sources** \\- 一个字符串或字符串的列表中，含有C ++源代码。\n",
    "\n",
    "  * **cuda_sources** \\- 一个字符串或字符串的列表，包含CUDA源代码。\n",
    "\n",
    "  * **功能** \\- 要为其生成功能绑定函数名称的列表。如果字典中给出，它应该映射函数名的文档字符串（否则只是函数名）。\n",
    "\n",
    "  * **with_cuda** \\- 确定CUDA头和库是否被添加到该生成。如果设置为`无 `（默认），该值被自动确定基于是否`cuda_sources提供 `。其设置为 TRUE`给力CUDA头文件和库包括在内。\n",
    "\n",
    "Example\n",
    "\n",
    "    \n",
    "    \n",
    "    >>> from torch.utils.cpp_extension import load_inline\n",
    "    >>> source = '''\n",
    "    at::Tensor sin_add(at::Tensor x, at::Tensor y) {\n",
    "      return x.sin() + y.sin();\n",
    "    }\n",
    "    '''\n",
    "    >>> module = load_inline(name='inline_extension',\n",
    "                             cpp_sources=[source],\n",
    "                             functions=['sin_add'])\n",
    "    \n",
    "\n",
    "`torch.utils.cpp_extension.``include_paths`( _cuda=False_\n",
    ")[[source]](_modules/torch/utils/cpp_extension.html#include_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取包括建立一个C ++或CUDA扩展所需的路径。\n",
    "\n",
    "Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA** \\- CUDA专用如果真，包括包括路径。\n",
    "\n",
    "Returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "名单包括路径字符串。\n",
    "\n",
    "`torch.utils.cpp_extension.``check_compiler_abi_compatibility`( _compiler_\n",
    ")[[source]](_modules/torch/utils/cpp_extension.html#check_compiler_abi_compatibility)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证给定的编译器与PyTorch ABI兼容。\n",
    "\n",
    "Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**编译** （[ _STR_ ](https://docs.python.org/3/library/stdtypes.html#str \"\\(in\n",
    "Python v3.7\\)\")） - 编译器可执行文件的名称来检查（例如，`克++`）。必须在shell进程可执行文件。\n",
    "\n",
    "Returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSE如果编译器（可能）ABI-不符合PyTorch，否则真。\n",
    "\n",
    "`torch.utils.cpp_extension.``verify_ninja_availability`()[[source]](_modules/torch/utils/cpp_extension.html#verify_ninja_availability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回`真 `如果[忍者](https://ninja-build.org/)打造系统可在系统上。\n",
    "\n",
    "[Next ![](_static/images/chevron-right-orange.svg)](data.html\n",
    "\"torch.utils.data\") [![](_static/images/chevron-right-orange.svg)\n",
    "Previous](checkpoint.html \"torch.utils.checkpoint\")\n",
    "\n",
    "* * *\n",
    "\n",
    "©版权所有2019年，Torch 贡献者。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

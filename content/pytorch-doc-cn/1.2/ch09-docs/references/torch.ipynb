{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch\n",
    "\n",
    "> 译者：[@那伊抹微笑](https://github.com/wangyangting)、@yudong、[@小瑶](https://github.com/chenyyx)、[@片刻](https://github.com/jiangzhonglian)、[@李雨龙](https://github.com/sawyer7246)、[@K](https://github.com/YaoSam) [@devin](https://github.com/EVYang1992)、[@张假飞](https://github.com/nothingcouldbebetter)、[@rickllyxu](https://github.com/rickllyxu)\n",
    "> \n",
    "> 校验者：[@张假飞](https://github.com/nothingcouldbebetter)、[@飞龙](https://github.com/wizardforcel)\n",
    "\n",
    "torch package 包含了多维张量的数据结构, 以及基于其上的多种数学操作. 此外, 它还提供了许多用于高效序列化 Tensor 和任意类型的实用工具包, 以及一起其它有用的实用工具包.\n",
    "\n",
    "它有一个 CUDA 的对应实现, 它使您能够在计算能力 &gt;=0.3 的 NVIDIA GPU 上进行张量运算.\n",
    "\n",
    "## Tensors (张量)\n",
    "\n",
    "```py\n",
    "torch.is_tensor(obj)\n",
    "```\n",
    "\n",
    "如果 `obj` 是一个 pytorch tensor, 则返回True.\n",
    "\n",
    "参数：`obj (Object)` – 用于测试的对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.is_storage(obj)\n",
    "```\n",
    "\n",
    "如果 `obj` 是一个 pytorch storage object, 则返回True.\n",
    "\n",
    "参数：`obj (Object)` – 用于测试的对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.set_default_tensor_type(t)\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.numel(input) → int\n",
    "```\n",
    "\n",
    "返回 `input` Tensor 中的元素总数.\n",
    "\n",
    "参数：`input (Tensor)` – 输入的 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1,2,3,4,5)\n",
    ">>> torch.numel(a)\n",
    "120\n",
    ">>> a = torch.zeros(4,4)\n",
    ">>> torch.numel(a)\n",
    "16\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None)\n",
    "```\n",
    "\n",
    "设置打印选项. 从 Numpy 中采集数据\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `precision` – 浮点输出精度的位数 (默认值为 8).\n",
    "*   `threshold` – 触发汇总显示而不是完全显示(repr)的数组元素的总数 (默认值为 1000).\n",
    "*   `edgeitems` – 每个维度开始和结束时总结的数组项数 (默认值为 3).\n",
    "*   `linewidth` – 插入换行符的每行字符数 (默认值为 80). Thresholded matricies(阈值矩阵) 将忽略这个参数.\n",
    "*   `profile` – 用于漂亮格式的打印. 可以用以下任何选项来进行覆盖 (default, short, full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation Ops (创建操作)\n",
    "\n",
    "```py\n",
    "torch.eye(n, m=None, out=None)\n",
    "```\n",
    "\n",
    "返回对角线位置全为1, 其它位置全为0的二维 tensor.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `n (int)` – 行数\n",
    "*   `m (int, 可选)` – 列数. 如果为 None,则默认为 `n`\n",
    "*   `out (Tensor, 可选)` – 输出 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个对角线位置全为1, 其它位置全为0的二维 tensor.\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.eye(3)\n",
    " 1  0  0\n",
    " 0  1  0\n",
    " 0  0  1\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.from_numpy(ndarray) → Tensor\n",
    "```\n",
    "\n",
    "从 [`numpy.ndarray`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray \"(in NumPy v1.14)\") 类 创建一个 [`Tensor`](tensors.html#torch.Tensor \"torch.Tensor\") 类.\n",
    "\n",
    "返回 tensor 和 `ndarray` 共享相同的内存. 对 tensor 的修改将反映在 `ndarray` 中, 反之亦然. 返回 tensor 不可调整大小.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = numpy.array([1, 2, 3])\n",
    ">>> t = torch.from_numpy(a)\n",
    ">>> t\n",
    "torch.LongTensor([1, 2, 3])\n",
    ">>> t[0] = -1\n",
    ">>> a\n",
    "array([-1,  2,  3])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.linspace(start, end, steps=100, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回 `start` 和 `end` 之间等间隔 `steps` 点的一维 Tensor.\n",
    "\n",
    "输出 是尺寸 `steps` 为一维 tensor\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `start (float)` – 点集合的起始值\n",
    "*   `end (float)` – 点集合的结束值\n",
    "*   `steps (int)` – 在 `start` 和 `end` 之间的样本数\n",
    "*   `out (Tensor, 可选)` – 输出结果的 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.linspace(3, 10, steps=5)\n",
    "\n",
    " 3.0000\n",
    " 4.7500\n",
    " 6.5000\n",
    " 8.2500\n",
    " 10.0000\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.linspace(-10, 10, steps=5)\n",
    "\n",
    "-10\n",
    " -5\n",
    " 0\n",
    " 5\n",
    " 10\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.linspace(start=-10, end=10, steps=5)\n",
    "\n",
    "-10\n",
    " -5\n",
    " 0\n",
    " 5\n",
    " 10\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.logspace(start, end, steps=100, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个在 ![10^{start}](img/tex-123da6df98ad3e045d7be9648881f7b7.gif) 和 ![10^{end}](img/tex-1a05cc8eee633a0f91a082916d31f96e.gif) 之间的对数间隔 `steps` 点的一维 Tensor\n",
    "\n",
    "输出是长度为 `steps` 的一维 tensor\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `start (float)` – 点集合的起始值\n",
    "*   `end (float)` – 点集合的结束值\n",
    "*   `steps (int)` – 在 `start` 和 `end` 之间的样本数\n",
    "*   `out (Tensor, 可选)` – 输出结果`Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.logspace(start=-10, end=10, steps=5)\n",
    "\n",
    " 1.0000e-10\n",
    " 1.0000e-05\n",
    " 1.0000e+00\n",
    " 1.0000e+05\n",
    " 1.0000e+10\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.logspace(start=0.1, end=1.0, steps=5)\n",
    "\n",
    " 1.2589\n",
    " 2.1135\n",
    " 3.5481\n",
    " 5.9566\n",
    " 10.0000\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ones(*sizes, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回填充了标量值 `1` 的 Tensor, 其形状由可变参数 `sizes` 定义.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `sizes (int...)` – 一组定义输出 Tensor 形状的整数\n",
    "*   `out (Tensor, 可选)` – 输出结果 Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.ones(2, 3)\n",
    "\n",
    " 1  1  1\n",
    " 1  1  1\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.ones(5)\n",
    "\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ones_like(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个用标量值 `1` 填充的张量, 大小与 `input` 相同.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入的大小将决定输出的大小.\n",
    "*   `out (Tensor, 可选)` – 输出结果 Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> input = torch.FloatTensor(2, 3)\n",
    ">>> torch.ones_like(input)\n",
    "\n",
    " 1  1  1\n",
    " 1  1  1\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.arange(start=0, end, step=1, out=None) → Tensor\n",
    "```\n",
    "\n",
    "从 `start` 用步长为 `step` 开始, 间隔在 `[start, end)` 中的值返回大小层次为 ![floor((end - start) / step)](img/tex-11a8e3f324d6a7b187a0eb8b25d3926e.gif) 的一维 Tensor.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `start (float)` – 点集合的起始值\n",
    "*   `end (float)` – 点集合的结束值\n",
    "*   `step (float)` – 每对相邻点之间的间隔\n",
    "*   `out (Tensor, 可选)` – 输出结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.arange(5)\n",
    "\n",
    " 0\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.arange(1, 4)\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    ">>> torch.arange(1, 2.5, 0.5)\n",
    "\n",
    " 1.0000\n",
    " 1.5000\n",
    " 2.0000\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.range(start, end, step=1, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个在 `start` 到 `end` 并且步长为 `step` 的区间内, 大小为 ![floor((end - start) / step) + 1](img/tex-a8d4b9eb08b29e4455688db33c092ae9.gif) 为一维 Tensor. `step` 是 tensor 中两个值之间的差距. ![x_{i+1} = x_i + step](img/tex-b99fbae9badbed7f3e2e937599966cd4.gif)\n",
    "\n",
    "警告：\n",
    "\n",
    "此功能已被弃用, 以支持 `torch.arange()`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `start (float)` – 点集合的起始值\n",
    "*   `end (float)` – 点集合的结束值\n",
    "*   `step (float)` – 每对相邻点之间的间隔\n",
    "*   `out (Tensor, 可选)` – 输出结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.range(1, 4)\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.range(1, 4, 0.5)\n",
    "\n",
    " 1.0000\n",
    " 1.5000\n",
    " 2.0000\n",
    " 2.5000\n",
    " 3.0000\n",
    " 3.5000\n",
    " 4.0000\n",
    "[torch.FloatTensor of size 7]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.zeros(*sizes, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回填充了标量值为 `0` 的 Tensor, 其形状由可变参量 `sizes` 定义.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `sizes (int...)` – 定义输出 Tensor 形状的一组整数.\n",
    "*   `out (Tensor, 可选)` – 输出结果 Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.zeros(2, 3)\n",
    "\n",
    " 0  0  0\n",
    " 0  0  0\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.zeros(5)\n",
    "\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 0\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.zeros_like(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个用标量值 `0` 填充的 Tensor, 其大小与 `input` 相同.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入的大小将决定输出的大小.\n",
    "*   `out (Tensor, 可选)` – 输出结果 Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> input = torch.FloatTensor(2, 3)\n",
    ">>> torch.zeros_like(input)\n",
    "\n",
    " 0  0  0\n",
    " 0  0  0\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "### Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作\n",
    "\n",
    "```py\n",
    "torch.cat(seq, dim=0, out=None) → Tensor\n",
    "```\n",
    "\n",
    "在给定维度上对输入的张量序列 `seq` 进行连接操作. 所有张量必须具有相同的形状(在 `cat` 维度中除外) 或为空.\n",
    "\n",
    "`torch.cat()` 可以看做是 `torch.split()` 和 `torch.chunk()` 的逆操作.\n",
    "\n",
    "`cat()` 可以通过下面的例子更好地理解.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `seq (_sequence of Tensors_)` – 可以是任何相同类型的 `Tensor` 的 Python 序列.\n",
    "*   `dim (int, 可选)` – tensors 级联的维数\n",
    "*   `out (Tensor, 可选)` – 输出参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(2, 3)\n",
    ">>> x\n",
    "\n",
    " 0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.cat((x, x, x), 0)\n",
    "\n",
    " 0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735\n",
    " 0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735\n",
    " 0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735\n",
    "[torch.FloatTensor of size 6x3]\n",
    "\n",
    ">>> torch.cat((x, x, x), 1)\n",
    "\n",
    " 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735\n",
    "[torch.FloatTensor of size 2x9]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.chunk(tensor, chunks, dim=0)\n",
    "```\n",
    "\n",
    "在给定维度(轴)上将输入张量进行分块处理.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `tensor (Tensor)` – 待分块的输入张量.\n",
    "*   `chunks (int)` – 要返回的分块的个数.\n",
    "*   `dim (int)` – 切分张量所需要沿着的维度.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.gather(input, dim, index, out=None) → Tensor\n",
    "```\n",
    "\n",
    "沿给定轴 `dim` ,将输入索引张量 `index` 指定位置的值进行聚合.\n",
    "\n",
    "对一个 3 维张量,输出可以定义为:\n",
    "\n",
    "```py\n",
    "out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
    "\n",
    "```\n",
    "\n",
    "如果 `input` 是 size 为 ![(x_0, x_1..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})](img/tex-b2b722f612a0a739ffabe888b56158d5.gif) 且 `dim` = i 的 n 维张量,则 `index` 必须是具有 size 为 ![(x_0, x_1, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})](img/tex-07123a18476a076323dd412ea5acc56c.gif) 的 n 维张量,其中 y &gt;= 1 ,并且 `out` 将与 `index` 的 size 相同.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 源张量\n",
    "*   `dim (int)` – 索引的轴\n",
    "*   `index (LongTensor)` – 聚合元素的下标\n",
    "*   `out (Tensor, 可选)` – 目标张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> t = torch.Tensor([[1,2],[3,4]])\n",
    ">>> torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))\n",
    " 1  1\n",
    " 4  3\n",
    "[torch.FloatTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.index_select(input, dim, index, out=None) → Tensor\n",
    "```\n",
    "\n",
    "沿着指定维度 `dim` 对输入进行切片,取 `index` 中指定的相应项 ( `index` 为一个 `LongTensor` ),然后返回到一个新的张量.\n",
    "\n",
    "> 返回的张量与原始张量 `Tensor` 有相同的维度(在指定轴上).\n",
    "\n",
    "注解：\n",
    "\n",
    "返回的张量不与原始张量共享内存空间.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `dim (int)` – 索引的轴\n",
    "*   `index (LongTensor)` – 包含索引下标的一维张量\n",
    "*   `out (Tensor, 可选)` – 输出参数/目标张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(3, 4)\n",
    ">>> x\n",
    "\n",
    " 1.2045  2.4084  0.4001  1.1372\n",
    " 0.5596  1.5677  0.6219 -0.7954\n",
    " 1.3635 -1.2313 -0.5414 -1.8478\n",
    "[torch.FloatTensor of size 3x4]\n",
    "\n",
    ">>> indices = torch.LongTensor([0, 2])\n",
    ">>> torch.index_select(x, 0, indices)\n",
    "\n",
    " 1.2045  2.4084  0.4001  1.1372\n",
    " 1.3635 -1.2313 -0.5414 -1.8478\n",
    "[torch.FloatTensor of size 2x4]\n",
    "\n",
    ">>> torch.index_select(x, 1, indices)\n",
    "\n",
    " 1.2045  0.4001\n",
    " 0.5596  0.6219\n",
    " 1.3635 -0.5414\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.masked_select(input, mask, out=None) → Tensor\n",
    "```\n",
    "\n",
    "根据掩码张量 `mask` 中的二元值,取输入张量中的指定项 ( `mask` 为一个 `ByteTensor` ),将取值返回到一个新的一维张量.\n",
    "\n",
    "张量 `mask` 与 `input` 的 shape 或维度不需要相同,但是他们必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) .\n",
    "\n",
    "注解：\n",
    "\n",
    "返回的张量不与原始张量共享内存空间.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `mask (ByteTensor)` – 掩码张量,包含了二元索引值\n",
    "*   `out (Tensor, 可选)` – 输出参数/目标张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(3, 4)\n",
    ">>> x\n",
    "\n",
    " 1.2045  2.4084  0.4001  1.1372\n",
    " 0.5596  1.5677  0.6219 -0.7954\n",
    " 1.3635 -1.2313 -0.5414 -1.8478\n",
    "[torch.FloatTensor of size 3x4]\n",
    "\n",
    ">>> mask = x.ge(0.5)\n",
    ">>> mask\n",
    "\n",
    " 1  1  0  1\n",
    " 1  1  1  0\n",
    " 1  0  0  0\n",
    "[torch.ByteTensor of size 3x4]\n",
    "\n",
    ">>> torch.masked_select(x, mask)\n",
    "\n",
    " 1.2045\n",
    " 2.4084\n",
    " 1.1372\n",
    " 0.5596\n",
    " 1.5677\n",
    " 0.6219\n",
    " 1.3635\n",
    "[torch.FloatTensor of size 7]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.nonzero(input, out=None) → LongTensor\n",
    "```\n",
    "\n",
    "返回一个包含输入 `input` 中非零元素索引的张量. 输出张量中的每行包含 `input` 中非零元素的索引.\n",
    "\n",
    "如果输入张量 `input` 有 `n` 维,则输出的索引张量 `out` 的 size 为 `z x n` , 这里 `z` 是输入张量 `input` 中所有非零元素的个数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量/源张量\n",
    "*   `out (LongTensor, 可选)` – 包含索引值的输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.nonzero(torch.Tensor([1, 1, 1, 0, 1]))\n",
    "\n",
    " 0\n",
    " 1\n",
    " 2\n",
    " 4\n",
    "[torch.LongTensor of size 4x1]\n",
    "\n",
    ">>> torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "...                             [0.0, 0.4, 0.0, 0.0],\n",
    "...                             [0.0, 0.0, 1.2, 0.0],\n",
    "...                             [0.0, 0.0, 0.0,-0.4]]))\n",
    "\n",
    " 0  0\n",
    " 1  1\n",
    " 2  2\n",
    " 3  3\n",
    "[torch.LongTensor of size 4x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.split(tensor, split_size, dim=0)\n",
    "```\n",
    "\n",
    "将输入张量分割成相等 size 的 chunks (如果可分).\n",
    "\n",
    "如果沿指定维的张量形状大小不能被 `split_size` 整分, 则最后一个分块会小于其它分块.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `tensor (Tensor)` – 待分割张量.\n",
    "*   `split_size (int)` – 单个分块的 size 大小.\n",
    "*   `dim (int)` – 沿着此维进行分割.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.squeeze(input, dim=None, out=None)\n",
    "```\n",
    "\n",
    "将 `input` 张量 size 中的 `1` 去除并返回.\n",
    "\n",
    "如果 `input` 的 shape 如 ![(A x 1 x B x C x 1 x D)](img/tex-1869e4162adae0b82c80adec1915082e.gif) ,那么输出 shape 就为: ![(A x B x C x D)](img/tex-22bdd4f99e29b716e084e048da31a1bb.gif)\n",
    "\n",
    "当给定 `dim` 时,那么挤压操作只在给定维度上.例如, `input` 的 shape 为: ![(A x 1 x B)](img/tex-b06a8b322f4713a58fe712d57c9ceda0.gif) , `squeeze(input, 0)` 将会保持张量不变,只有用 `squeeze(input, 1)` , shape 会变成 ![(A x B)](img/tex-c6d3e8cfc2d4f7d1ef61fc25eb14f67f.gif) .\n",
    "\n",
    "注解：\n",
    "\n",
    "作为上述的一个例外,size 为 1 的一维张量不会改变维度.\n",
    "\n",
    "注解：\n",
    "\n",
    "返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `dim (int, 可选)` – 如果给定 `dim` 时,则 `input` 只会在给定维度执行挤压\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.zeros(2,1,2,1,2)\n",
    ">>> x.size()\n",
    "(2L, 1L, 2L, 1L, 2L)\n",
    ">>> y = torch.squeeze(x)\n",
    ">>> y.size()\n",
    "(2L, 2L, 2L)\n",
    ">>> y = torch.squeeze(x, 0)\n",
    ">>> y.size()\n",
    "(2L, 1L, 2L, 1L, 2L)\n",
    ">>> y = torch.squeeze(x, 1)\n",
    ">>> y.size()\n",
    "(2L, 2L, 1L, 2L)\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.stack(sequence, dim=0, out=None)\n",
    "```\n",
    "\n",
    "沿着一个新维度对输入张量序列进行连接.\n",
    "\n",
    "序列中所有的张量都应该为相同 size .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `sequence (_Sequence_)` – 待连接的张量序列.\n",
    "*   `dim (int)` – 插入的维度.必须介于 0 与待连接的张量序列数（包含）之间.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.t(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "预期 `input` 为一个矩阵 (2 维张量), 并转置 0, 1 维.\n",
    "\n",
    "可以被视为函数 `transpose(input, 0, 1)` 的简写函数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(2, 3)\n",
    ">>> x\n",
    "\n",
    " 0.4834  0.6907  1.3417\n",
    "-0.1300  0.5295  0.2321\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.t(x)\n",
    "\n",
    " 0.4834 -0.1300\n",
    " 0.6907  0.5295\n",
    " 1.3417  0.2321\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.take(input, indices) → Tensor\n",
    "```\n",
    "\n",
    "在给定的索引处返回一个新的 `Tensor` ,其元素为 `input` . 输入张量被看作是一维张量.结果与索引具有相同的 shape .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `indices (LongTensor)` – 进入 `Tensor` 的索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> src = torch.Tensor([[4, 3, 5],\n",
    "...                     [6, 7, 8]])\n",
    ">>> torch.take(src, torch.LongTensor([0, 2, 5]))\n",
    " 4\n",
    " 5\n",
    " 8\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.transpose(input, dim0, dim1, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入矩阵 `input` 的转置.交换给定维度 `dim0` 和 `dim1` .\n",
    "\n",
    "`out` 张量与 `input` 张量共享内存,所以改变其中一个会导致另外一个也被修改.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `dim0 (int)` – 转置的第一个维度\n",
    "*   `dim1 (int)` – 转置的第二个维度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(2, 3)\n",
    ">>> x\n",
    "\n",
    " 0.5983 -0.0341  2.4918\n",
    " 1.5981 -0.5265 -0.8735\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.transpose(x, 0, 1)\n",
    "\n",
    " 0.5983  1.5981\n",
    "-0.0341 -0.5265\n",
    " 2.4918 -0.8735\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.unbind(tensor, dim=0)\n",
    "```\n",
    "\n",
    "移除一个张量的维度.\n",
    "\n",
    "移除指定维后,返回一个元组,包含了沿着指定维切片后的各个切片 (已经没有了移除的维度).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `tensor (Tensor)` – 要执行 unbind 的张量/输入张量.\n",
    "*   `dim (int)` – 要移除的维度.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.unsqueeze(input, dim, out=None)\n",
    "```\n",
    "\n",
    "返回在指定位置插入维度 size 为 1 的新张量.\n",
    "\n",
    "返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个.\n",
    "\n",
    "如果 `dim` 为负,则将会被转化 ![dim + input.dim() + 1](img/tex-722443b33cb36edca0e69759f3fa99de.gif) .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `dim (int)` – 插入维度的索引\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.Tensor([1, 2, 3, 4])\n",
    ">>> torch.unsqueeze(x, 0)\n",
    " 1  2  3  4\n",
    "[torch.FloatTensor of size 1x4]\n",
    ">>> torch.unsqueeze(x, 1)\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 4x1]\n",
    "\n",
    "```\n",
    "\n",
    "## Random sampling (随机采样)\n",
    "\n",
    "```py\n",
    "torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "设置生成随机数的种子,并返回一个 `torch._C.Generator` 对象.\n",
    "\n",
    "参数：`seed (int 或 long)` – 种子."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.initial_seed()\n",
    "```\n",
    "\n",
    "返回用于生成随机数字的初始种子 (python `long`) .\n",
    "\n",
    "```py\n",
    "torch.get_rng_state()\n",
    "```\n",
    "\n",
    "以ByteTensor的形式返回随机数发生器的状态.\n",
    "\n",
    "```py\n",
    "torch.set_rng_state(new_state)\n",
    "```\n",
    "\n",
    "设置随机数发生器的参数.\n",
    "\n",
    "参数：`new_state (torch.ByteTensor)` – 理想状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.default_generator = <torch._C.Generator object at 0x28bcc10>`\n",
    "\n",
    "```py\n",
    "torch.bernoulli(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "从伯努利分布中抽取二进制随机数 (0 或 1).\n",
    "\n",
    "The `input` 张量包含用于抽取二进制随机数的概率. 因此, `input` 中的所有值必须在这个范围内: ![0 &lt;= input_i &lt;= 1](img/tex-bd58cbf26356be324cc21216b3557822.gif)\n",
    "\n",
    "根据 `input` 张量第 `i` 个概率值, 输出张量的第 `i` 个元素将取值为1.\n",
    "\n",
    "返回的 `out` 张量的值只有 0 或者 1 并且大小与 `input` 张量相同.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 伯努利分布的概率值\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.Tensor(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1]\n",
    ">>> a\n",
    "\n",
    " 0.7544  0.8140  0.9842\n",
    " 0.5282  0.0595  0.6445\n",
    " 0.1925  0.9553  0.9732\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.bernoulli(a)\n",
    "\n",
    " 1  1  1\n",
    " 0  0  1\n",
    " 0  1  1\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1\n",
    ">>> torch.bernoulli(a)\n",
    "\n",
    " 1  1  1\n",
    " 1  1  1\n",
    " 1  1  1\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0\n",
    ">>> torch.bernoulli(a)\n",
    "\n",
    " 0  0  0\n",
    " 0  0  0\n",
    " 0  0  0\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.multinomial(input, num_samples, replacement=False, out=None) → LongTensor\n",
    "```\n",
    "\n",
    "返回一个张量, 其中每一行包含在 `input` 张量对应行中多项式分布取样的 `num_samples` 索引.\n",
    "\n",
    "注解：\n",
    "\n",
    "`input` 的每行值不需要总和为 1 (我们只使用这些值作为权重), 但必须是非负且非零和的.\n",
    "\n",
    "取样时从左向右排列(第一个样本在第一列).\n",
    "\n",
    "如果 `input` 是一个向量, 则 `out` 是一个大小为 `num_samples` 的向量.\n",
    "\n",
    "如果 `input` 是一个 `m` 行的矩阵, 则 `out` 是一个 `m × n` 的矩阵.\n",
    "\n",
    "如果参数 `replacement` 是 `True`, 则可重复取样. 否则, 样本在每行不能被重复取样.\n",
    "\n",
    "参数 `num_samples` 必须小于 `input` 长度 (如果是一个矩阵, 则是 `input` 的列数).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 包含概率值的张量\n",
    "*   `num_samples (int)` – 抽取的样本数\n",
    "*   `replacement (bool, 可选)` – 是否重复抽取样本\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights\n",
    ">>> torch.multinomial(weights, 4)\n",
    "\n",
    " 1\n",
    " 2\n",
    " 0\n",
    " 0\n",
    "[torch.LongTensor of size 4]\n",
    "\n",
    ">>> torch.multinomial(weights, 4, replacement=True)\n",
    "\n",
    " 1\n",
    " 2\n",
    " 1\n",
    " 2\n",
    "[torch.LongTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.normal()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.normal(means, std, out=None)\n",
    "```\n",
    "\n",
    "返回一个随机数张量, 随机数从给定平均值和标准差的离散正态分布中抽取.\n",
    "\n",
    "参数 `means` 是一个包含每个输出元素的正态分布均值的张量.\n",
    "\n",
    "参数 `std` 是一个包含每个输出元素的正态分布标准差的张量.\n",
    "\n",
    "其中 `means` 和 `std` 的形状不需要匹配, 但是每个张量中的元素总数需要相同.\n",
    "\n",
    "注解：\n",
    "\n",
    "当形状不匹配时, `means` 的形状将作为返回输出张量的形状.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `means (Tensor)` – 均值\n",
    "*   `std (Tensor)` – 标准差\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    "torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))\n",
    "\n",
    " 1.5104\n",
    " 1.6955\n",
    " 2.4895\n",
    " 4.9185\n",
    " 4.9895\n",
    " 6.9155\n",
    " 7.3683\n",
    " 8.1836\n",
    " 8.7164\n",
    " 9.8916\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.normal(mean=0.0, std, out=None)\n",
    "```\n",
    "\n",
    "功能与上面函数类似, 但所有被抽取的元素共享均值.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `means (float, 可选)` – 所有分布的均值\n",
    "*   `std (Tensor)` – 每个元素标准差的张量\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.normal(mean=0.5, std=torch.arange(1, 6))\n",
    "\n",
    " 0.5723\n",
    " 0.0871\n",
    " -0.3783\n",
    " -2.5689\n",
    " 10.7893\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.normal(means, std=1.0, out=None)\n",
    "```\n",
    "\n",
    "功能与上面函数类似, 但所有被抽取的元素共享标准差.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `means (Tensor)` – 每个元素均值的张量\n",
    "*   `std (float, 可选)` – 所有分布的标准差\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.normal(means=torch.arange(1, 6))\n",
    "\n",
    " 1.1681\n",
    " 2.8884\n",
    " 3.7718\n",
    " 2.5616\n",
    " 4.2500\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.rand(*sizes, out=None) → Tensor\n",
    "```\n",
    "\n",
    "在区间 ![[0, 1)](img/tex-b9d1ea90e68d51c01a351d857cc16e0c.gif) 中, 返回一个填充了均匀分布的随机数的张量.\n",
    "\n",
    "这个张量的形状由可变参数 `sizes` 来定义.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `sizes (int...)` – 定义输出张量形状的整数集.\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.rand(4)\n",
    "\n",
    " 0.9193\n",
    " 0.3347\n",
    " 0.3232\n",
    " 0.7715\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.rand(2, 3)\n",
    "\n",
    " 0.5010  0.5140  0.0719\n",
    " 0.1435  0.5636  0.0538\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.randn(*sizes, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个从正态分布中填充随机数的张量, 其均值为 0 , 方差为 1 .\n",
    "\n",
    "这个张量的形状被可变参数 `sizes` 定义.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `sizes (int...)` – 定义输出张量形状的整数集.\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.randn(4)\n",
    "\n",
    "-0.1145\n",
    " 0.0094\n",
    "-1.1717\n",
    " 0.9846\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.randn(2, 3)\n",
    "\n",
    " 1.4339  0.3351 -1.0999\n",
    " 1.5458 -0.9643 -0.3558\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.randperm(n, out=None) → LongTensor\n",
    "```\n",
    "\n",
    "返回一个从 `0` to `n - 1` 的整数的随机排列.\n",
    "\n",
    "参数：`n (int)` – 上限 (唯一的)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.randperm(4)\n",
    "\n",
    " 2\n",
    " 1\n",
    " 3\n",
    " 0\n",
    "[torch.LongTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "### In-place random sampling (直接随机采样)\n",
    "\n",
    "在Tensors模块上还定义了许多 in-place 随机采样函数,可以点击参考它们的文档:\n",
    "\n",
    "*   `torch.Tensor.bernoulli_()`](tensors.html#torch.Tensor.bernoulli_ \"torch.Tensor.bernoulli_\") - 是 [`torch.bernoulli()` 的 in-place 版本\n",
    "*   [`torch.Tensor.cauchy_()`](tensors.html#torch.Tensor.cauchy_ \"torch.Tensor.cauchy_\") - 从柯西分布中抽取数字\n",
    "*   [`torch.Tensor.exponential_()`](tensors.html#torch.Tensor.exponential_ \"torch.Tensor.exponential_\") - 从指数分布中抽取数字\n",
    "*   [`torch.Tensor.geometric_()`](tensors.html#torch.Tensor.geometric_ \"torch.Tensor.geometric_\") - 从几何分布中抽取元素\n",
    "*   [`torch.Tensor.log_normal_()`](tensors.html#torch.Tensor.log_normal_ \"torch.Tensor.log_normal_\") - 对数正态分布中的样本\n",
    "*   `torch.Tensor.normal_()`](tensors.html#torch.Tensor.normal_ \"torch.Tensor.normal_\") - 是 [`torch.normal()` 的 in-place 版本\n",
    "*   [`torch.Tensor.random_()`](tensors.html#torch.Tensor.random_ \"torch.Tensor.random_\") - 离散均匀分布中采样的数字\n",
    "*   [`torch.Tensor.uniform_()`](tensors.html#torch.Tensor.uniform_ \"torch.Tensor.uniform_\") - 正态分布中采样的数字\n",
    "\n",
    "## Serialization (序列化)\n",
    "\n",
    "```py\n",
    "torch.save(obj, f, pickle_module=<module 'cPickle' from '/usr/lib64/python2.7/lib-dynload/cPickle.so'>, pickle_protocol=2)\n",
    "```\n",
    "\n",
    "将一个对象保存到一个磁盘文件中.\n",
    "\n",
    "另见: [保存模型的推荐方法](notes/serialization.html#recommend-saving-models)\n",
    "\n",
    "参数: obj: 要保存的对象 f: 类文件对象 (必须实现返回文件描述符的 fileno 方法) 或包含文件名的字符串 pickle_module: 用于 pickling 元数据和对象的模块 pickle_protocol: 可以指定来覆盖默认协议\n",
    "\n",
    "```py\n",
    "torch.load(f, map_location=None, pickle_module=<module 'cPickle' from '/usr/lib64/python2.7/lib-dynload/cPickle.so'>)\n",
    "```\n",
    "\n",
    "从磁盘文件中加载一个用 `torch.save()` 保存的对象.\n",
    "\n",
    "| Func: | `torch.load` 使用 Python 的解封 (unpickling) 设施, 但特殊对待张量下的存储 (storages). |\n",
    "| --- | --- |\n",
    "\n",
    "它们首先在 CPU 上反序列化, 然后移动到所保存的设备上. 如果这个过程失败了 (例如, 因为运行时的系统没有确定的设备), 将会抛出异常. 然而, 使用 map_location 参数, 存储可以被动态地重新映射到另一组设备上.\n",
    "\n",
    "如果 map_location 是可调用对象, 则对于每个序列化存储, 它都将以两个参数调用一次: storage 和 location. 参数 storage 是驻留在 CPU 上的存储的初始反序列化. 每个序列化后的存储都有一个与之关联的位置标签, 它标识了保存它的设备, 而此标签是传递给 map_location 的第二个参数. 对于 CPU 张量, 内建的位置标签是 ‘cpu’, 对于 CUDA 张量, 内建的位置标签是 ‘cuda:device_id’ (例如 ‘cuda:2’). map_location 要么返回 None , 要么返回一个存储. 如果 map_location 返回存储, 它将用作已移动到正确设备上的, 最终反序列化的对象. 否则, 如果没有指明 map_location, 即返回 None, `torch.load` 会回落到默认的行为.\n",
    "\n",
    "如果 map_location 是一个字典, 它用于将出现在文件 (键) 中的位置标签, 重新映射到另一个位置标签, 它出现在值中并指明在哪里存放存储.\n",
    "\n",
    "用户扩展可以使用 register_package 来注册他们自己的位置标签, 以及标记和反序列化方法.\n",
    "\n",
    "参数: f: 一个类文件对象 (必须实现返回文件描述符的 fileno, 以及 seek 方法), 或者包含文件名的字符串. map_location: 一个函数或者一个指明如何重新映射存储位置的字典 pickle_module: 用于解封 (unpickling) 元数据和对象的模块 (必须匹配用于序列化文件的 pickle_module) 示例:\n",
    "\n",
    "```py\n",
    ">>> torch.load('tensors.pt')\n",
    "# Load all tensors onto the CPU\n",
    ">>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
    "# Load all tensors onto GPU 1\n",
    ">>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
    "# Map tensors from GPU 1 to GPU 0\n",
    ">>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
    "\n",
    "```\n",
    "\n",
    "## Parallelism (并行化)\n",
    "\n",
    "```py\n",
    "torch.get_num_threads() → int\n",
    "```\n",
    "\n",
    "获得 OpenMP 并行化操作的线程数目\n",
    "\n",
    "```py\n",
    "torch.set_num_threads(int)\n",
    "```\n",
    "\n",
    "设置 OpenMP 并行化操作的线程数目\n",
    "\n",
    "## Math operations (数学操作)\n",
    "\n",
    "### Pointwise Ops (逐点操作)\n",
    "\n",
    "```py\n",
    "torch.abs(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算给定 `input` 张量的元素的绝对值.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.abs(torch.FloatTensor([-1, -2, 3]))\n",
    "FloatTensor([1, 2, 3])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.acos(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "用 `input` 元素的反余弦返回一个新的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input `Tensor`\n",
    "*   `out (Tensor, 可选)` – The result `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.acos(a)\n",
    " 2.2608\n",
    " 1.2956\n",
    " 1.1075\n",
    " nan\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.add()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.add(input, value, out=None)\n",
    "```\n",
    "\n",
    "将标量值 `value` 添加到输入张量 attr:`input` 的每个元素并返回一个新的结果张量.\n",
    "\n",
    "![out = tensor + value](img/tex-ac47755bc8dea983c6ad7c80c4581151.gif)\n",
    "\n",
    "如果输入张量 `input` 是 FloatTensor 或者 DoubleTensor 类型, 则 `value` 必须为实数, 否则为整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `value (Number)` – 要添加到 `input` 每个元素的数\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 0.4050\n",
    "-1.2227\n",
    " 1.8688\n",
    "-0.4185\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.add(a, 20)\n",
    "\n",
    " 20.4050\n",
    " 18.7773\n",
    " 21.8688\n",
    " 19.5815\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.add(input, value=1, other, out=None)\n",
    "```\n",
    "\n",
    "张量 `other` 的每个元素乘以标量值 `value` 并加到张量 `input` 上, 返回生成的张量 `out` .\n",
    "\n",
    "张量 `input` 的形状与张量 `other` 的形状必须 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "![out = input + (other * value)](img/tex-b0c1f202403038a0ada5db34d989338a.gif)\n",
    "\n",
    "如果张量 `other` 是 FloatTensor 或者 DoubleTensor 类型, 则 `value` 必须为实数, 否则为整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 第一个输入 `Tensor`\n",
    "*   `value (Number)` – 张量 `other` 的标量乘数\n",
    "*   `other (Tensor)` – 第二个输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> import torch\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    "-0.9310\n",
    " 2.0330\n",
    " 0.0852\n",
    "-0.2941\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> b = torch.randn(2, 2)\n",
    ">>> b\n",
    "\n",
    " 1.0663  0.2544\n",
    "-0.1513  0.0749\n",
    "[torch.FloatTensor of size 2x2]\n",
    "\n",
    ">>> torch.add(a, 10, b)\n",
    " 9.7322\n",
    " 4.5770\n",
    "-1.4279\n",
    " 0.4552\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "将张量 `tensor1` 逐元素除以张量 `tensor2`, 然后乘以标量值 `value` 并加到张量 `tensor` 上.\n",
    "\n",
    "张量 `tensor`, 张量 `tensor1`, 张量 `tensor2` 的形状必须 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "对于类型为 `FloatTensor` 或者 `DoubleTensor` 的张量输入, `value` 必须为实数, 否则为整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `tensor (Tensor)` – 张量, 对 `tensor1 ./ tensor2` 进行相加\n",
    "*   `value (Number, 可选)` – 标量, 对 `tensor1 ./ tensor2` 进行相乘\n",
    "*   `tensor1 (Tensor)` – 分子张量, 即作为被除数\n",
    "*   `tensor2 (Tensor)` – 分母张量, 即作为除数\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> t = torch.randn(2, 3)\n",
    ">>> t1 = torch.randn(1, 6)\n",
    ">>> t2 = torch.randn(6, 1)\n",
    ">>> torch.addcdiv(t, 0.1, t1, t2)\n",
    "\n",
    " 0.0122 -0.0188 -0.2354\n",
    " 0.7396 -1.5721  1.2878\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "将张量 `tensor1` 逐元素与张量 `tensor2` 相乘, 然后乘以标量值 `value` 并加到张量 `tensor` 上.\n",
    "\n",
    "张量 `tensor`, 张量 `tensor1`, 张量 `tensor2` 的形状必须 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "对于类型为 `FloatTensor` 或者 `DoubleTensor` 的张量输入, `value` 必须为实数, 否则为整数. :param tensor: 张量, 对 `tensor1 .* tensor2` 进行相加 :type tensor: Tensor :param value: 标量, 对 `tensor1 .* tensor2` 进行相乘 :type value: Number, 可选 :param tensor1: 张量, 作为乘子1 :type tensor1: Tensor :param tensor2: 张量, 作为乘子2 :type tensor2: Tensor :param out: 输出张量 :type out: Tensor, 可选\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> t = torch.randn(2, 3)\n",
    ">>> t1 = torch.randn(1, 6)\n",
    ">>> t2 = torch.randn(6, 1)\n",
    ">>> torch.addcmul(t, 0.1, t1, t2)\n",
    "\n",
    " 0.0122 -0.0188 -0.2354\n",
    " 0.7396 -1.5721  1.2878\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.asin(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的 `Tensor` , 其元素为张量 `input` 的每个元素的反正弦.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.asin(a)\n",
    "-0.6900\n",
    " 0.2752\n",
    " 0.4633\n",
    " nan\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.atan(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的 `Tensor` , 其元素为张量 `input` 的每个元素的反正切.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.atan(a)\n",
    "-0.5669\n",
    " 0.2653\n",
    " 0.4203\n",
    " 0.9196\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.atan2(input1, input2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是输入张量 `input1` 和输入张量 `input2` 元素的反正切.\n",
    "\n",
    "输入张量 `input1` 的形状和输入张量 `input2` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input1 (Tensor)` – 第一个输入 `Tensor`\n",
    "*   `input2 (Tensor)` – 第二个输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.atan2(a, torch.randn(4))\n",
    "-2.4167\n",
    " 2.9755\n",
    " 0.9363\n",
    " 1.6613\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ceil(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 的元素向上取整(取不小于每个元素的最小整数).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.ceil(a)\n",
    "\n",
    " 2\n",
    " 1\n",
    "-0\n",
    "-0\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.clamp(input, min, max, out=None) → Tensor\n",
    "```\n",
    "\n",
    "将输入张量 `input` 所有元素限制在区间 `[min, max]` 中并返回一个结果张量.\n",
    "\n",
    "```py\n",
    "      | min, if x_i < min\n",
    "y_i = | x_i, if min <= x_i <= max\n",
    "      | max, if x_i > max\n",
    "\n",
    "```\n",
    "\n",
    "如果输入张量 `input` 的类型 `FloatTensor` 或者 `DoubleTensor`, 那么参数 `min` 和 `max` 必须为实数, 否则为整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `min (Number)` – 限制范围下限\n",
    "*   `max (Number)` – 限制范围上限\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.clamp(a, min=-0.5, max=0.5)\n",
    "\n",
    " 0.5000\n",
    " 0.3912\n",
    "-0.5000\n",
    "-0.5000\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.clamp(input, *, min, out=None) → Tensor\n",
    "```\n",
    "\n",
    "张量 `input` 的所有元素值大于或者等于 `min`.\n",
    "\n",
    "如果张量 `input` 的类型是 `FloatTensor` 或者 `DoubleTensor`, 则 `value` 必须是实数, 否则应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `value (Number)` – 输出中每个元素的最小值\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.clamp(a, min=0.5)\n",
    "\n",
    " 1.3869\n",
    " 0.5000\n",
    " 0.5000\n",
    " 0.5000\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.clamp(input, *, max, out=None) → Tensor\n",
    "```\n",
    "\n",
    "张量 `input` 的所有元素值小于或者等于 `max`.\n",
    "\n",
    "如果张量 `input` 的类型是 `FloatTensor` 或者 `DoubleTensor`, 则 `value` 必须是实数, 否则应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `value (Number)` – 输出中每个元素的最大值\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.clamp(a, max=0.5)\n",
    "\n",
    " 0.5000\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.cos(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 每个元素的余弦.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.cos(a)\n",
    " 0.8041\n",
    " 0.9633\n",
    " 0.9018\n",
    " 0.2557\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.cosh(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 每个元素的双曲余弦.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.cosh(a)\n",
    " 1.2095\n",
    " 1.0372\n",
    " 1.1015\n",
    " 1.9917\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.div()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.div(input, value, out=None)\n",
    "```\n",
    "\n",
    "将张量 `input` 的元素逐一除以标量值 `value` , 其结果作为一个新的张量返回.\n",
    "\n",
    "![out = tensor / value](img/tex-4e40d7ead3c8f578a1b7b071ed53489b.gif)\n",
    "\n",
    "如果张量 `input` 的类型是 `FloatTensor` 或者 `DoubleTensor`, 则标量值 `value` 必须是实数, 否则应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `value (Number)` – 除数, 被张量 `input` 的元素除\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(5)\n",
    ">>> a\n",
    "\n",
    "-0.6147\n",
    "-1.1237\n",
    "-0.1604\n",
    "-0.6853\n",
    " 0.1063\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.div(a, 0.5)\n",
    "\n",
    "-1.2294\n",
    "-2.2474\n",
    "-0.3208\n",
    "-1.3706\n",
    " 0.2126\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.div(input, other, out=None)\n",
    "```\n",
    "\n",
    "张量 `input` 的元素与张量 `other` 的元素逐一相除. 返回一个新的结果张量 `out` . 张量 `input` 与张量 `other` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "![out_i = input_i / other_i](img/tex-56a7e74c24c6530b63af32b9792a1775.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 分子 `Tensor` (被除数)\n",
    "*   `other (Tensor)` – 分母 `Tensor` (除数)\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4,4)\n",
    ">>> a\n",
    "\n",
    "-0.1810  0.4017  0.2863 -0.1013\n",
    " 0.6183  2.0696  0.9012 -1.5933\n",
    " 0.5679  0.4743 -0.0117 -0.1266\n",
    "-0.1213  0.9629  0.2682  1.5968\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> b = torch.randn(8, 2)\n",
    ">>> b\n",
    "\n",
    " 0.8774  0.7650\n",
    " 0.8866  1.4805\n",
    "-0.6490  1.1172\n",
    " 1.4259 -0.8146\n",
    " 1.4633 -0.1228\n",
    " 0.4643 -0.6029\n",
    " 0.3492  1.5270\n",
    " 1.6103 -0.6291\n",
    "[torch.FloatTensor of size 8x2]\n",
    "\n",
    ">>> torch.div(a, b)\n",
    "\n",
    "-0.2062  0.5251  0.3229 -0.0684\n",
    "-0.9528  1.8525  0.6320  1.9559\n",
    " 0.3881 -3.8625 -0.0253  0.2099\n",
    "-0.3473  0.6306  0.1666 -2.5381\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.erf(tensor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算每个元素的误差函数.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.erf(torch.Tensor([0, -1., 10.]))\n",
    "torch.FloatTensor([0., -0.8427, 1.])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.erfinv(tensor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算每个元素的反向误差函数.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.erfinv(torch.Tensor([0, 0.5., -1.]))\n",
    "torch.FloatTensor([0., 0.4769, -inf])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.exp(tensor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算每个元素的指数.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.exp(torch.Tensor([0, math.log(2)]))\n",
    "torch.FloatTensor([1, 2])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.floor(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 的元素向下取整(取不大于每个元素的最大整数).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.floor(a)\n",
    "\n",
    " 1\n",
    " 0\n",
    "-1\n",
    "-1\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.fmod(input, divisor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算除法余数.\n",
    "\n",
    "被除数和除数可能同时含有整数和浮点数. 这时余数的正负与被除数 `tensor` 相同.\n",
    "\n",
    "当除数 `divisor` 是一个张量时r, 张量 `input` 和张量 `divisor` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 被除数\n",
    "*   `divisor (Tensor 或 float)` – 除数. 可能是一个数或者是一个与被除数相同形状的张量.\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.fmod(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)\n",
    "torch.FloatTensor([-1, -0, -1, 1, 0, 1])\n",
    ">>> torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5)\n",
    "torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])\n",
    "\n",
    "```\n",
    "\n",
    "See also\n",
    "\n",
    "`torch.remainder()`, 其计算等价于 Python’s `%` 操作符的元素余数\n",
    "\n",
    "```py\n",
    "torch.frac(tensor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算张量 `tensor` 每个元素的分数部分.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.frac(torch.Tensor([1, 2.5, -3.2])\n",
    "torch.FloatTensor([0, 0.5, -0.2])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.lerp(start, end, weight, out=None)\n",
    "```\n",
    "\n",
    "基于标量值 `weight`: , 在张量 `start` 与张量 `end` 之间做线性插值 并返回结果张量 `out` .\n",
    "\n",
    "![out_i = start_i + weight * (end_i - start_i)](img/tex-ef591522596ccf5d38cdb23fb75fbab9.gif)\n",
    "\n",
    "张量 `start` 和张量 `end` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `start (Tensor)` – 起始点 `Tensor`\n",
    "*   `end (Tensor)` – 终点 `Tensor`\n",
    "*   `weight (float)` – 插值公式的权重\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> start = torch.arange(1, 5)\n",
    ">>> end = torch.Tensor(4).fill_(10)\n",
    ">>> start\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> end\n",
    "\n",
    " 10\n",
    " 10\n",
    " 10\n",
    " 10\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.lerp(start, end, 0.5)\n",
    "\n",
    " 5.5000\n",
    " 6.0000\n",
    " 6.5000\n",
    " 7.0000\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.log(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 所有元素的自然对数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(5)\n",
    ">>> a\n",
    "\n",
    "-0.4183\n",
    " 0.3722\n",
    "-0.3091\n",
    " 0.4149\n",
    " 0.5857\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.log(a)\n",
    "\n",
    " nan\n",
    "-0.9883\n",
    " nan\n",
    "-0.8797\n",
    "-0.5349\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.log1p(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是(1 + `input`) 的自然对数.\n",
    "\n",
    "![y_i = log(x_i + 1)](img/tex-44ae3e6c45bdb0992887549eecbdcca1.gif)\n",
    "\n",
    "注解：\n",
    "\n",
    "对于较小的张量 `input` 的值, 此函数比 `torch.log()` 更精确.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(5)\n",
    ">>> a\n",
    "\n",
    "-0.4183\n",
    " 0.3722\n",
    "-0.3091\n",
    " 0.4149\n",
    " 0.5857\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.log1p(a)\n",
    "\n",
    "-0.5418\n",
    " 0.3164\n",
    "-0.3697\n",
    " 0.3471\n",
    " 0.4611\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mul()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mul(input, value, out=None)\n",
    "```\n",
    "\n",
    "将输入张量 `input` 的每个元素与标量值 `value` 相乘并返回一个新的结果张量.\n",
    "\n",
    "![out = tensor * value](img/tex-90772d102c1d9f559ae6fa994b1923c1.gif)\n",
    "\n",
    "如果张量 `input` 的类型为 `FloatTensor` or `DoubleTensor`, 则 `value` 应该是实数, 否则为整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `value (Number)` – 与张量 `input` 每个元素相乘的数\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3)\n",
    ">>> a\n",
    "\n",
    "-0.9374\n",
    "-0.5254\n",
    "-0.6069\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    ">>> torch.mul(a, 100)\n",
    "\n",
    "-93.7411\n",
    "-52.5374\n",
    "-60.6908\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mul(input, other, out=None)\n",
    "```\n",
    "\n",
    "张量 `input` 的元素与张量 `other` 的元素逐一相乘. 其结果作为一个新的张量返回.\n",
    "\n",
    "张量 `input` 和张量 `other` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "![out_i = input_i * other_i](img/tex-66ff7c38b998757c54474f8da6085fa7.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 第一个乘数 `Tensor`\n",
    "*   `other (Tensor)` – 第二个乘数 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4,4)\n",
    ">>> a\n",
    "\n",
    "-0.7280  0.0598 -1.4327 -0.5825\n",
    "-0.1427 -0.0690  0.0821 -0.3270\n",
    "-0.9241  0.5110  0.4070 -1.1188\n",
    "-0.8308  0.7426 -0.6240 -1.1582\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> b = torch.randn(2, 8)\n",
    ">>> b\n",
    "\n",
    " 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742\n",
    "-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974\n",
    "[torch.FloatTensor of size 2x8]\n",
    "\n",
    ">>> torch.mul(a, b)\n",
    "\n",
    "-0.0313 -0.0645 -0.8618 -0.6784\n",
    " 0.0934 -0.0021 -0.0137 -0.3513\n",
    " 1.1638  0.0149 -0.0346 -0.5068\n",
    "-1.0304 -0.3460  0.1148 -0.6919\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.neg(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 的元素的负值.\n",
    "\n",
    "![out = -1 * input](img/tex-12f8b36dc85a819313fa0fdebe068228.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(5)\n",
    ">>> a\n",
    "\n",
    "-0.4430\n",
    " 1.1690\n",
    "-0.8836\n",
    "-0.4565\n",
    " 0.2968\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.neg(a)\n",
    "\n",
    " 0.4430\n",
    "-1.1690\n",
    " 0.8836\n",
    " 0.4565\n",
    "-0.2968\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.pow()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.pow(input, exponent, out=None)\n",
    "```\n",
    "\n",
    "对输入张量 `input` 按元素求 `exponent` 次幂值并返回结果张量(其值作为结果张量的元素).\n",
    "\n",
    "幂值 `exponent` 可以是一个单一的浮点数 `float` 或者是一个与张量 `input` 有相同元素数的张量 `Tensor` .\n",
    "\n",
    "当指数 `exponent` 是一个标量时, 执行操作:\n",
    "\n",
    "![out_i = x_i ^ {exponent}](img/tex-7d5081fb4d383f1287f3abc01c783d5c.gif)\n",
    "\n",
    "当指数 `exponent` 是一个张量, 执行操作:\n",
    "\n",
    "![out_i = x_i ^ {exponent_i}](img/tex-45f9b0f3e07ffc7cdba45900c800d5d8.gif)\n",
    "\n",
    "当幂值 `exponent` 是一个张量, 张量 `input` 和张量 `exponent` 的形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `exponent (float 或 Tensor)` – 指数\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    "-0.5274\n",
    "-0.8232\n",
    "-2.1128\n",
    " 1.7558\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.pow(a, 2)\n",
    "\n",
    " 0.2781\n",
    " 0.6776\n",
    " 4.4640\n",
    " 3.0829\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> exp = torch.arange(1, 5)\n",
    ">>> a = torch.arange(1, 5)\n",
    ">>> a\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> exp\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.pow(a, exp)\n",
    "\n",
    " 1\n",
    " 4\n",
    " 27\n",
    " 256\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.pow(base, input, out=None)\n",
    "```\n",
    "\n",
    "`base` 是一个标量浮点值, `input` 是一个张量. 返回的张量 `out` 的形状与张量 `input` 的形状相同.\n",
    "\n",
    "执行操作:\n",
    "\n",
    "![out_i = base ^ {input_i}](img/tex-14e62bb86c53bc82b02aea5663311bbb.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `base (float)` – 幂运算的底数\n",
    "*   `input (Tensor)` – 指数\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> exp = torch.arange(1, 5)\n",
    ">>> base = 2\n",
    ">>> torch.pow(base, exp)\n",
    "\n",
    " 2\n",
    " 4\n",
    " 8\n",
    " 16\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.reciprocal(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的 `Tensor` , 其元素是张量 `input` 元素的倒数, i.e. ![1.0 / x](img/tex-e8d4c459fa54ec9efacf485b78522de6.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.reciprocal(a)\n",
    "\n",
    " 0.7210\n",
    " 2.5565\n",
    "-1.1583\n",
    "-1.8289\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.remainder(input, divisor, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算元素的除法的余数.\n",
    "\n",
    "除数与被除数可能同时包含整数或浮点数. 余数与除数有相同的符号.\n",
    "\n",
    "当除数 `divisor` 是一个张量, 张量 `input` 的形状和张量 `divisor` 得形状必须可 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 被除数\n",
    "*   `divisor (Tensor 或 float)` – 除数. 可能是一个数或者可能是一个与被除数大小相同的张量\n",
    "*   `out (Tensor, 可选)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.remainder(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)\n",
    "torch.FloatTensor([1, 0, 1, 1, 0, 1])\n",
    ">>> torch.remainder(torch.Tensor([1, 2, 3, 4, 5]), 1.5)\n",
    "torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])\n",
    "\n",
    "```\n",
    "\n",
    "See also\n",
    "\n",
    "`torch.fmod()` 同样计算除法余数, 等效于C库函数中的 `fmod()`\n",
    "\n",
    "```py\n",
    "torch.round(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是输入张量的元素四舍五入到最近的整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.2290\n",
    " 1.3409\n",
    "-0.5662\n",
    "-0.0899\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.round(a)\n",
    "\n",
    " 1\n",
    " 1\n",
    "-1\n",
    "-0\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.rsqrt(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的平方根的倒数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.2290\n",
    " 1.3409\n",
    "-0.5662\n",
    "-0.0899\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.rsqrt(a)\n",
    "\n",
    " 0.9020\n",
    " 0.8636\n",
    " nan\n",
    " nan\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sigmoid(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的sigmoid值.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    "-0.4972\n",
    " 1.3512\n",
    " 0.1056\n",
    "-0.2650\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.sigmoid(a)\n",
    "\n",
    " 0.3782\n",
    " 0.7943\n",
    " 0.5264\n",
    " 0.4341\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sign(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的符号.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.sign(a)\n",
    "\n",
    "-1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sin(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的正弦.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.sin(a)\n",
    "-0.5944\n",
    " 0.2684\n",
    " 0.4322\n",
    " 0.9667\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sinh(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的双曲正弦.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.sinh(a)\n",
    "-0.6804\n",
    " 0.2751\n",
    " 0.4619\n",
    " 1.7225\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sqrt(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的平方根.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.2290\n",
    " 1.3409\n",
    "-0.5662\n",
    "-0.0899\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.sqrt(a)\n",
    "\n",
    " 1.1086\n",
    " 1.1580\n",
    " nan\n",
    " nan\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.tan(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的正切.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.tan(a)\n",
    "-0.7392\n",
    " 0.2786\n",
    " 0.4792\n",
    " 3.7801\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.tanh(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的双曲正切.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "-0.6366\n",
    " 0.2718\n",
    " 0.4469\n",
    " 1.3122\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.tanh(a)\n",
    "-0.5625\n",
    " 0.2653\n",
    " 0.4193\n",
    " 0.8648\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.trunc(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个新的张量 `Tensor` , 其元素是张量 `input` 元素的截断整数值 (直接去除小数部分) .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    "-0.4972\n",
    " 1.3512\n",
    " 0.1056\n",
    "-0.2650\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.trunc(a)\n",
    "\n",
    "-0\n",
    " 1\n",
    " 0\n",
    "-0\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "### Reduction Ops (归约操作)\n",
    "\n",
    "```py\n",
    "torch.cumprod(input, dim, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回元素 `input` 在给定维度 `dim` 下的累积积.\n",
    "\n",
    "例如, 如果 `input` 是一个N元张量, 结果也是一个N元张量, 元素为: ![y_i = x_1 * x_2 * x_3 * ... * x_i](img/tex-06f4d1ef079a78930f949d6df01e2cb1.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `dim (int)` – 进行操作的维度\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(10)\n",
    ">>> a\n",
    "\n",
    " 1.1148\n",
    " 1.8423\n",
    " 1.4143\n",
    "-0.4403\n",
    " 1.2859\n",
    "-1.2514\n",
    "-0.4748\n",
    " 1.1735\n",
    "-1.6332\n",
    "-0.4272\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    ">>> torch.cumprod(a, dim=0)\n",
    "\n",
    " 1.1148\n",
    " 2.0537\n",
    " 2.9045\n",
    "-1.2788\n",
    "-1.6444\n",
    " 2.0578\n",
    "-0.9770\n",
    "-1.1466\n",
    " 1.8726\n",
    "-0.8000\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    ">>> a[5] = 0.0\n",
    ">>> torch.cumprod(a, dim=0)\n",
    "\n",
    " 1.1148\n",
    " 2.0537\n",
    " 2.9045\n",
    "-1.2788\n",
    "-1.6444\n",
    "-0.0000\n",
    " 0.0000\n",
    " 0.0000\n",
    "-0.0000\n",
    " 0.0000\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.cumsum(input, dim, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回元素 `input` 在给定维度 `dim` 下的累积和.\n",
    "\n",
    "例如, 如果 `input` 是一个N元张量, 结果将也是一个N元张量, 元素为: ![y_i = x_1 + x_2 + x_3 + ... + x_i](img/tex-ee3d5bc08d5e2b0c0ad809ad0a991bd8.gif)\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `dim (int)` – 进行操作的维度\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(10)\n",
    ">>> a\n",
    "\n",
    "-0.6039\n",
    "-0.2214\n",
    "-0.3705\n",
    "-0.0169\n",
    " 1.3415\n",
    "-0.1230\n",
    " 0.9719\n",
    " 0.6081\n",
    "-0.1286\n",
    " 1.0947\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    ">>> torch.cumsum(a, dim=0)\n",
    "\n",
    "-0.6039\n",
    "-0.8253\n",
    "-1.1958\n",
    "-1.2127\n",
    " 0.1288\n",
    " 0.0058\n",
    " 0.9777\n",
    " 1.5858\n",
    " 1.4572\n",
    " 2.5519\n",
    "[torch.FloatTensor of size 10]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.dist(input, other, p=2) → float\n",
    "```\n",
    "\n",
    "返回(`input` - `other`)的p-范数 `input` 和 `other` 的形状必须满足 [broadcastable](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `other (Tensor)` – 右侧输入 `Tensor`\n",
    "*   `p (float, 可选)` – 所计算的范数.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(4)\n",
    ">>> x\n",
    "\n",
    " 0.2505\n",
    "-0.4571\n",
    "-0.3733\n",
    " 0.7807\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> y = torch.randn(4)\n",
    ">>> y\n",
    "\n",
    " 0.7782\n",
    "-0.5185\n",
    " 1.4106\n",
    "-2.4063\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.dist(x, y, 3.5)\n",
    "3.302832063224223\n",
    ">>> torch.dist(x, y, 3)\n",
    "3.3677282206393286\n",
    ">>> torch.dist(x, y, 0)\n",
    "inf\n",
    ">>> torch.dist(x, y, 1)\n",
    "5.560028076171875\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mean()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mean(input) → float\n",
    "```\n",
    "\n",
    "返回张量 `input` 所有元素的均值.\n",
    "\n",
    "参数：`input (Tensor)` – 输入 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    "-0.2946 -0.9143  2.1809\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.mean(a)\n",
    "0.32398951053619385\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mean(input, dim, keepdim=False, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回张量 `input` 在给定维度 `dim` 上每行的均值.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool, 可选)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `out (Tensor)` – 输出张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 4)\n",
    ">>> a\n",
    "\n",
    "-1.2738 -0.3058  0.1230 -1.9615\n",
    " 0.8771 -0.5430 -0.9233  0.9879\n",
    " 1.4107  0.0317 -0.6823  0.2255\n",
    "-1.3854  0.4953 -0.2160  0.2435\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> torch.mean(a, 1)\n",
    "\n",
    "-0.8545\n",
    " 0.0997\n",
    " 0.2464\n",
    "-0.2157\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.mean(a, 1, True)\n",
    "\n",
    "-0.8545\n",
    " 0.0997\n",
    " 0.2464\n",
    "-0.2157\n",
    "[torch.FloatTensor of size 4x1]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.median()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.median(input) → float\n",
    "```\n",
    "\n",
    "返回输出张量 `input` 所有元素的中位数.\n",
    "\n",
    "参数：`input (Tensor)` – the input `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    " 0.4729 -0.2266 -0.2085\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.median(a)\n",
    "-0.2085\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.median(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "返回输出张量 `input` 在给定维度 `dim` 下每行的中位数. 同时返回一个包含中位数的索引 `LongTensor`.\n",
    "\n",
    "`dim` 的缺省值为输入张量 `input` 的最后一维.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量与输入张量 `input` 形状相同, 除了维数 `dim` 是1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量比输入张量 `input` 少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保留与否\n",
    "*   `values (Tensor, 可选)` – 结果张量\n",
    "*   `indices (Tensor, 可选)` – 结果张量索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a\n",
    "\n",
    " -0.6891 -0.6662\n",
    " 0.2697  0.7412\n",
    " 0.5254 -0.7402\n",
    " 0.5528 -0.2399\n",
    "[torch.FloatTensor of size 4x2]\n",
    "\n",
    ">>> a = torch.randn(4, 5)\n",
    ">>> a\n",
    "\n",
    " 0.4056 -0.3372  1.0973 -2.4884  0.4334\n",
    " 2.1336  0.3841  0.1404 -0.1821 -0.7646\n",
    "-0.2403  1.3975 -2.0068  0.1298  0.0212\n",
    "-1.5371 -0.7257 -0.4871 -0.2359 -1.1724\n",
    "[torch.FloatTensor of size 4x5]\n",
    "\n",
    ">>> torch.median(a, 1)\n",
    "(\n",
    " 0.4056\n",
    " 0.1404\n",
    " 0.0212\n",
    "-0.7257\n",
    "[torch.FloatTensor of size 4]\n",
    ",\n",
    " 0\n",
    " 2\n",
    " 4\n",
    " 1\n",
    "[torch.LongTensor of size 4]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mode(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维数 `dim` 下每行元素的众数值. 同时也返回众数值的索引 `LongTensor`.\n",
    "\n",
    "维度 `dim` 的缺省值是输入张量 `input` 的最后一维. .\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数至今没有为 `torch.cuda.Tensor` 定义.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `values (Tensor, 可选)` – 结果张量\n",
    "*   `indices (Tensor, 可选)` – 结果索引张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a\n",
    "\n",
    " -0.6891 -0.6662\n",
    " 0.2697  0.7412\n",
    " 0.5254 -0.7402\n",
    " 0.5528 -0.2399\n",
    "[torch.FloatTensor of size 4x2]\n",
    "\n",
    ">>> a = torch.randn(4, 5)\n",
    ">>> a\n",
    "\n",
    " 0.4056 -0.3372  1.0973 -2.4884  0.4334\n",
    " 2.1336  0.3841  0.1404 -0.1821 -0.7646\n",
    "-0.2403  1.3975 -2.0068  0.1298  0.0212\n",
    "-1.5371 -0.7257 -0.4871 -0.2359 -1.1724\n",
    "[torch.FloatTensor of size 4x5]\n",
    "\n",
    ">>> torch.mode(a, 1)\n",
    "(\n",
    "-2.4884\n",
    "-0.7646\n",
    "-2.0068\n",
    "-1.5371\n",
    "[torch.FloatTensor of size 4]\n",
    ",\n",
    " 3\n",
    " 4\n",
    " 2\n",
    " 0\n",
    "[torch.LongTensor of size 4]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.norm()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.norm(input, p=2) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 的p-范数\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `p (float, 可选)` – 范数计算中的幂指数值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    "-0.4376 -0.5328  0.9547\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.norm(a, 3)\n",
    "1.0338925067372466\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.norm(input, p, dim, keepdim=False, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行元素的p-范数.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除非维度 `dim` 是1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `p (float)` – 范数计算中的幂指数值\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 2)\n",
    ">>> a\n",
    "\n",
    "-0.6891 -0.6662\n",
    " 0.2697  0.7412\n",
    " 0.5254 -0.7402\n",
    " 0.5528 -0.2399\n",
    "[torch.FloatTensor of size 4x2]\n",
    "\n",
    ">>> torch.norm(a, 2, 1)\n",
    "\n",
    " 0.9585\n",
    " 0.7888\n",
    " 0.9077\n",
    " 0.6026\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.norm(a, 0, 1, True)\n",
    "\n",
    " 2\n",
    " 2\n",
    " 2\n",
    " 2\n",
    "[torch.FloatTensor of size 4x1]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.prod()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.prod(input) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 所有元素的乘积.\n",
    "\n",
    "参数：`input (Tensor)` – 输入张量 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    " 0.6170  0.3546  0.0253\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.prod(a)\n",
    "0.005537458061418483\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.prod(input, dim, keepdim=False, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行元素的积.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 2)\n",
    ">>> a\n",
    "\n",
    " 0.1598 -0.6884\n",
    "-0.1831 -0.4412\n",
    "-0.9925 -0.6244\n",
    "-0.2416 -0.8080\n",
    "[torch.FloatTensor of size 4x2]\n",
    "\n",
    ">>> torch.prod(a, 1)\n",
    "\n",
    "-0.1100\n",
    " 0.0808\n",
    " 0.6197\n",
    " 0.1952\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.std()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.std(input, unbiased=True) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 所有元素的标准差.\n",
    "\n",
    "如果 `unbiased` 是 `False` , 那么标准差将通过有偏估计计算.否则, Bessel’s correction 将被使用.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `unbiased (bool)` – 是否使用无偏估计\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    "-1.3063  1.4182 -0.3061\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.std(a)\n",
    "1.3782334731508061\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.std(input, dim, keepdim=False, unbiased=True, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行元素的标准差.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是 1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "如果 `unbiased` 是 `False` , 那么标准差将通过有偏估计来计算. 否则, Bessel’s correction 将被使用.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `unbiased (bool)` – 是否使用无偏估计\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 4)\n",
    ">>> a\n",
    "\n",
    " 0.1889 -2.4856  0.0043  1.8169\n",
    "-0.7701 -0.4682 -2.2410  0.4098\n",
    " 0.1919 -1.1856 -1.0361  0.9085\n",
    " 0.0173  1.0662  0.2143 -0.5576\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> torch.std(a, dim=1)\n",
    "\n",
    " 1.7756\n",
    " 1.1025\n",
    " 1.0045\n",
    " 0.6725\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sum()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sum(input) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 所有元素的和.\n",
    "\n",
    "参数：`input (Tensor)` – 输入张量 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    " 0.6170  0.3546  0.0253\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.sum(a)\n",
    "0.9969287421554327\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sum(input, dim, keepdim=False, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行元素的和.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是 1. 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量减少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 4)\n",
    ">>> a\n",
    "\n",
    "-0.4640  0.0609  0.1122  0.4784\n",
    "-1.3063  1.6443  0.4714 -0.7396\n",
    "-1.3561 -0.1959  1.0609 -1.9855\n",
    " 2.6833  0.5746 -0.5709 -0.4430\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> torch.sum(a, 1)\n",
    "\n",
    " 0.1874\n",
    " 0.0698\n",
    "-2.4767\n",
    " 2.2440\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.var()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.var(input, unbiased=True) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 的方差.\n",
    "\n",
    "如果 `unbiased` 是 `False` , 方差的计算将通过有偏估计计算. 否则, Bessel’s correction 将会被使用.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `unbiased (bool)` – 是否使用无偏估计\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    "-1.3063  1.4182 -0.3061\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.var(a)\n",
    "1.899527506513334\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.var(input, dim, keepdim=False, unbiased=True, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行的方差.\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维度 `dim` 是 1. 另外, `dim` 被挤压 (参看 `torch.squeeze()`), 导致输出张量减少一维.\n",
    "\n",
    "如果 `unbiased` 是``False``, 方差的计算将通过有偏估计计算. 否则, Bessel’s correction 将会被使用.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保留与否\n",
    "*   `unbiased (bool)` – 是否使用无偏估计\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 4)\n",
    ">>> a\n",
    "\n",
    "-1.2738 -0.3058  0.1230 -1.9615\n",
    " 0.8771 -0.5430 -0.9233  0.9879\n",
    " 1.4107  0.0317 -0.6823  0.2255\n",
    "-1.3854  0.4953 -0.2160  0.2435\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> torch.var(a, 1)\n",
    "\n",
    " 0.8859\n",
    " 0.9509\n",
    " 0.7548\n",
    " 0.6949\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "### Comparison Ops (比较操作)\n",
    "\n",
    "```py\n",
    "torch.eq(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "比较元素是否相等\n",
    "\n",
    "第二个元素可以是一个数字或 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为与第一个参数形状相同的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待比较张量\n",
    "*   `other (Tensor 或 float)` – 比较张量或数\n",
    "*   `out (Tensor, 可选)` – 输出张量, 须为 ByteTensor 类型或与 input (Tensor) 同类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 torch.ByteTensor 张量, 待比较和要比较张量逐位置比较, 相等为 1 , 不等为 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.eq(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    "1  0\n",
    "0  1\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.equal(tensor1, tensor2) → bool\n",
    "```\n",
    "\n",
    "如果两个张量有相同的形状和元素值, 则返回 `True` , 否则 `False` .\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2]))\n",
    "True\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ge(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "逐元素比较 `input` 和 `other` , 即是否 **input&gt;=other** .\n",
    "\n",
    "第二个参数可以为一个数或形状可 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为和第一个参数相同类型的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待对比的张量\n",
    "*   `other (Tensor 或 float)` – 对比的张量或 `float` 值\n",
    "*   `out (Tensor, 可选)` – 输出张量. 必须为 `ByteTensor` 或者与第一个参数 `tensor` 相同类型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 `torch.ByteTensor` 张量, 包含了每个位置的比较结果(是否 input &gt;= other ).\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.ge(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    " 1  1\n",
    " 0  1\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.gt(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "逐元素比较 `input` 和 `other` , 即是否 **input&gt;other** 如果两个张量有相同的形状和元素值, 则返回 `True` ,否则 `False`.\n",
    "\n",
    "第二个参数可以为一个数或形状可 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为和第一个参数相同类型的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待对比的张量\n",
    "*   `other (Tensor 或 float)` – 对比的张量或 `float` 值\n",
    "*   `out (Tensor, 可选)` – 输出张量. 必须为 `ByteTensor` 或者与第一个参数 `tensor` 相同类型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 `torch.ByteTensor` 张量, 包含了每个位置的比较结果(是否 input &gt; other ).\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.gt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    " 0  1\n",
    " 0  0\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.kthvalue(input, k, dim=None, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "取输入张量 `input` 指定维上第 `k` 个最小值. 如果不指定 `dim` , 则默认为 `input` 的最后一维.\n",
    "\n",
    "返回一个元组 `(values,indices)` ,其中 `indices` 是原始输入张量 `input` 中沿 `dim` 维的第 `k` 个最小值下标.\n",
    "\n",
    "如果 `keepdim` 为 `True` , `values` 和 `indices` 张量都和 `input` 大小相同, 除了在所有值都为1的 `dim` 维度上. 如果 `keepdim` 为 `False` , `dim` 被压缩. (参见 `torch.squeeze()` ), 使 `values` 和 `indices` 两个张量比 `input` 张量小一个的维度.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `k (int)` – 第 `k` 个最小值\n",
    "*   `dim (int, 可选)` – 沿着此维进行排序\n",
    "*   `keepdim (bool)` – 输出张量是否保持维度 `dim` 不变\n",
    "*   `out (tuple, 可选)` – 输出元组 ( Tensor, LongTensor ) 可选参数(作为输出 buffers )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.arange(1, 6)\n",
    ">>> x\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    " 5\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.kthvalue(x, 4)\n",
    "(\n",
    " 4\n",
    "[torch.FloatTensor of size 1]\n",
    ",\n",
    " 3\n",
    "[torch.LongTensor of size 1]\n",
    ")\n",
    "\n",
    ">>> x=torch.arange(1,7).resize_(2,3)\n",
    ">>> x\n",
    "\n",
    "1  2  3\n",
    "4  5  6\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    ">>> torch.kthvalue(x,2,0,True)\n",
    "(\n",
    "4  5  6\n",
    "[torch.FloatTensor of size 1x3]\n",
    " ,\n",
    "1  1  1\n",
    "[torch.LongTensor of size 1x3]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.le(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "逐元素比较 `input` 和 `other` , 即是否 **input&lt;=other** 如果两个张量有相同的形状和元素值, 则返回 `True` ,否则 `False` .\n",
    "\n",
    "第二个参数可以为一个数或形状可 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为和第一个参数相同类型的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待对比的张量\n",
    "*   `other (Tensor 或 float)` – 对比的张量或 `float` 值\n",
    "*   `out (Tensor, 可选)` – 输出张量. 必须为 `ByteTensor` 或者与第一个参数 `tensor` 相同类型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 `torch.ByteTensor` 张量, 包含了每个位置的比较结果(是否 input &lt;= other ).\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.le(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    " 1  0\n",
    " 1  1\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.lt(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "逐元素比较 `input` 和 `other` , 即是否 **input&lt;other** 如果两个张量有相同的形状和元素值, 则返回 `True` ,否则 `False` .\n",
    "\n",
    "第二个参数可以为一个数或形状可 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为和第一个参数相同类型的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待对比的张量\n",
    "*   `other (Tensor 或 float)` – 对比的张量或 `float` 值\n",
    "*   `out (Tensor, 可选)` – 输出张量. 必须为 `ByteTensor` 或者与第一个参数 `tensor` 相同类型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 `torch.ByteTensor` 张量, 包含了每个位置的比较结果(是否 input &lt; other ).\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.lt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    " 0  0\n",
    " 1  0\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.max()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.max(input) → float\n",
    "```\n",
    "\n",
    "返回输入 `input` 张量所有元素的最大值.\n",
    "\n",
    "参数：`input (Tensor)` – 输入 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    " 0.4729 -0.2266 -0.2085\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.max(a)\n",
    "0.4729\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 上每行的最大值, 并同时返回每个最大值的位置索引.\n",
    "\n",
    "如果 `keepdim` 为 `True` , `values` 和 `indices` 张量都和 `input` 尺寸相同, 除了在所有值都为 1 的 `dim` 维度上. 如果 `keepdim` 为 `False` , `dim` 被压缩. (参见 `torch.squeeze()` ), 使 `values` 和 `indices` 两个张量比 `input` 张量小一个的维度.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `k (int)` – 第 `k` 个最小值\n",
    "*   `dim (int, 可选)` – 沿着此维进行排序\n",
    "*   `keepdim (bool)` – 输出张量是否保持维度 `dim` 不变\n",
    "*   `out (tuple, 可选)` – 输出元组 (max, max_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">> a = torch.randn(4, 4)\n",
    ">> a\n",
    "\n",
    "0.0692  0.3142  1.2513 -0.5428\n",
    "0.9288  0.8552 -0.2073  0.6409\n",
    "1.0695 -0.0101 -2.4507 -1.2230\n",
    "0.7426 -0.7666  0.4862 -0.6628\n",
    "torch.FloatTensor of size 4x4]\n",
    "\n",
    ">>> torch.max(a, 1)\n",
    "(\n",
    " 1.2513\n",
    " 0.9288\n",
    " 1.0695\n",
    " 0.7426\n",
    "[torch.FloatTensor of size 4]\n",
    ",\n",
    " 2\n",
    " 0\n",
    " 0\n",
    " 0\n",
    "[torch.LongTensor of size 4]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.max(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "输入 `input` 每一个元素和对应的比较张量 `other` 进行比较, 留下较大的元素 `max`.\n",
    "\n",
    "要比较的张量 `input` 与比较张量 `other` 不必大小一致, 但它们一定要能 [broadcastable](notes/broadcasting.html#broadcasting-semantics) .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 要比较张量 `Tensor`\n",
    "*   `other (Tensor)` – 比较张量 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 输出张量 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> b = torch.randn(4)\n",
    ">>> b\n",
    "\n",
    " 1.0067\n",
    "-0.8010\n",
    " 0.6258\n",
    " 0.3627\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.max(a, b)\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    " 0.6258\n",
    " 0.3627\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.min()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.min(input) → float\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 所有元素的最小值.\n",
    "\n",
    "参数：`input (Tensor)` – 输入 `Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(1, 3)\n",
    ">>> a\n",
    "\n",
    " 0.4729 -0.2266 -0.2085\n",
    "[torch.FloatTensor of size 1x3]\n",
    "\n",
    ">>> torch.min(a)\n",
    "-0.22663167119026184\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.min(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "返回输入张量 `input` 在给定维度 `dim` 下每行元素的最小值. 其中第二个返回值是每个被找出的最小值的索引位置 ( argmin ) .\n",
    "\n",
    "如果 `keepdim` 是 `True`, 输出张量的大小与输入张量 `input` 相同, 除了维数 `dim` 是 1 . 另外, `dim` 被挤压 (参看 `torch.squeeze()` ), 导致输出张量比输入张量 `input` 少一维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量 `Tensor`\n",
    "*   `dim (int)` – 要减少的维度\n",
    "*   `keepdim (bool)` – 输出张量的维度 `dim` 保持与否\n",
    "*   `out (tuple, 可选)` – 两个输出张量的结果元组 (min, min_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">> a = torch.randn(4, 4)\n",
    ">> a\n",
    "\n",
    "0.0692  0.3142  1.2513 -0.5428\n",
    "0.9288  0.8552 -0.2073  0.6409\n",
    "1.0695 -0.0101 -2.4507 -1.2230\n",
    "0.7426 -0.7666  0.4862 -0.6628\n",
    "torch.FloatTensor of size 4x4]\n",
    "\n",
    ">> torch.min(a, 1)\n",
    "\n",
    "0.5428\n",
    "0.2073\n",
    "2.4507\n",
    "0.7666\n",
    "torch.FloatTensor of size 4]\n",
    "\n",
    "3\n",
    "2\n",
    "2\n",
    "1\n",
    "torch.LongTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.min(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "输入 `input` 每一个元素和对应的比较张量 `other` 进行比较, 留下较小的元素 `min` .\n",
    "\n",
    "要比较的张量 `input` 与比较张量 `other` 不必尺寸一致, 但它们一定要能广播 [broadcastable](notes/broadcasting.html#broadcasting-semantics) .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 第一个张量 `Tensor`\n",
    "*   `other (Tensor)` – 第二个张量 `Tensor`\n",
    "*   `out (Tensor, 可选)` – 输出的张量 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4)\n",
    ">>> a\n",
    "\n",
    " 1.3869\n",
    " 0.3912\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> b = torch.randn(4)\n",
    ">>> b\n",
    "\n",
    " 1.0067\n",
    "-0.8010\n",
    " 0.6258\n",
    " 0.3627\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    ">>> torch.min(a, b)\n",
    "\n",
    " 1.0067\n",
    "-0.8010\n",
    "-0.8634\n",
    "-0.5468\n",
    "[torch.FloatTensor of size 4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ne(input, other, out=None) → Tensor\n",
    "```\n",
    "\n",
    "逐元素比较 `input` 和 `other` , 即是否 **tensor != other** 如果两个张量有相同的形状和元素值, 则返回 `True` , 否则 `False` .\n",
    "\n",
    "第二个参数可以为一个数或形状广播 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 为和第一个参数相同类型的张量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 待对比的张量\n",
    "*   `other (Tensor 或 float)` – 对比的张量或 `float` 值\n",
    "*   `out (Tensor, 可选)` – 输出张量. 必须为 `ByteTensor` 或者与第一个参数 `tensor` 相同类型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：一个 `torch.ByteTensor` 张量, 包含了每个位置的比较结果 (是否 input != other ) .\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.ne(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))\n",
    " 0  1\n",
    " 1  0\n",
    "[torch.ByteTensor of size 2x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.sort(input, dim=None, descending=False, out=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "对输入张量 `input` 沿着指定维按升序排序.\n",
    "\n",
    "如果不给定 `dim` ,则默认为输入的最后一维.\n",
    "\n",
    "如果指定参数 `descending` 为 `True` , 则按降序排序.\n",
    "\n",
    "返回元组 (sorted_tensor, sorted_indices) , sorted_indices 为原始输入中的下标.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 要对比的张量\n",
    "*   `dim (int, 可选)` – 沿着此维排序\n",
    "*   `descending (bool, 可选)` – 布尔值, 控制升降排序\n",
    "*   `out (tuple, 可选)` – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.randn(3, 4)\n",
    ">>> sorted, indices = torch.sort(x)\n",
    ">>> sorted\n",
    "\n",
    "-1.6747  0.0610  0.1190  1.4137\n",
    "-1.4782  0.7159  1.0341  1.3678\n",
    "-0.3324 -0.0782  0.3518  0.4763\n",
    "[torch.FloatTensor of size 3x4]\n",
    "\n",
    ">>> indices\n",
    "\n",
    " 0  1  3  2\n",
    " 2  1  0  3\n",
    " 3  1  0  2\n",
    "[torch.LongTensor of size 3x4]\n",
    "\n",
    ">>> sorted, indices = torch.sort(x, 0)\n",
    ">>> sorted\n",
    "\n",
    "-1.6747 -0.0782 -1.4782 -0.3324\n",
    " 0.3518  0.0610  0.4763  0.1190\n",
    " 1.0341  0.7159  1.4137  1.3678\n",
    "[torch.FloatTensor of size 3x4]\n",
    "\n",
    ">>> indices\n",
    "\n",
    " 0  2  1  2\n",
    " 2  0  2  0\n",
    " 1  1  0  1\n",
    "[torch.LongTensor of size 3x4]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\n",
    "```\n",
    "\n",
    "沿给定 dim 维度返回输入张量 `input` 中 `k` 个最大值. 如果不指定 `dim` , 则默认为 `input` 的最后一维. 如果为 `largest` 为 `False` ,则返回最小的 `k` 个值. 返回一个元组 `(values, indices)` , 其中 indices 是原始输入张量 input 中测元素下标. 如果设定布尔值 `sorted` 为 `True` , 将会确保返回的 `k` 个值被排序.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `k (int)` – “top-k” 中的 k\n",
    "*   `dim (int, 可选)` – 排序的维\n",
    "*   `largest (bool, 可选)` – 布尔值, 控制返回最大或最小值\n",
    "*   `sorted (bool, 可选)` – 布尔值, 控制返回值是否排序\n",
    "*   `out (tuple, 可选)` – 可选输出张量 (Tensor, LongTensor) output buffers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.arange(1, 6)\n",
    ">>> x\n",
    "\n",
    " 1\n",
    " 2\n",
    " 3\n",
    " 4\n",
    " 5\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> torch.topk(x, 3)\n",
    "(\n",
    " 5\n",
    " 4\n",
    " 3\n",
    "[torch.FloatTensor of size 3]\n",
    ",\n",
    " 4\n",
    " 3\n",
    " 2\n",
    "[torch.LongTensor of size 3]\n",
    ")\n",
    ">>> torch.topk(x, 3, 0, largest=False)\n",
    "(\n",
    " 1\n",
    " 2\n",
    " 3\n",
    "[torch.FloatTensor of size 3]\n",
    ",\n",
    " 0\n",
    " 1\n",
    " 2\n",
    "[torch.LongTensor of size 3]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "### Other Operations (其它操作)\n",
    "\n",
    "```py\n",
    "torch.cross(input, other, dim=-1, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回沿着维度 `dim` 上, 两个张量 `input` 和 `other` 的向量积 (叉积), `input` 和 `other` 必须有相同的形状, 且指定的 `dim` 维上 `size` 必须为 3.\n",
    "\n",
    "如果不指定 `dim`, 则默认为第一个尺度为 3 的维.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `other (Tensor)` – 第二个输入 `Tensor`\n",
    "*   `dim (int, 可选)` – 沿着此维进行叉积操作.\n",
    "*   `out (Tensor, 可选)` – 结果 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(4, 3)\n",
    ">>> a\n",
    "\n",
    "-0.6652 -1.0116 -0.6857\n",
    " 0.2286  0.4446 -0.5272\n",
    " 0.0476  0.2321  1.9991\n",
    " 0.6199  1.1924 -0.9397\n",
    "[torch.FloatTensor of size 4x3]\n",
    "\n",
    ">>> b = torch.randn(4, 3)\n",
    ">>> b\n",
    "\n",
    "-0.1042 -1.1156  0.1947\n",
    " 0.9947  0.1149  0.4701\n",
    "-1.0108  0.8319 -0.0750\n",
    " 0.9045 -1.3754  1.0976\n",
    "[torch.FloatTensor of size 4x3]\n",
    "\n",
    ">>> torch.cross(a, b, dim=1)\n",
    "\n",
    "-0.9619  0.2009  0.6367\n",
    " 0.2696 -0.6318 -0.4160\n",
    "-1.6805 -2.0171  0.2741\n",
    " 0.0163 -1.5304 -1.9311\n",
    "[torch.FloatTensor of size 4x3]\n",
    "\n",
    ">>> torch.cross(a, b)\n",
    "\n",
    "-0.9619  0.2009  0.6367\n",
    " 0.2696 -0.6318 -0.4160\n",
    "-1.6805 -2.0171  0.2741\n",
    " 0.0163 -1.5304 -1.9311\n",
    "[torch.FloatTensor of size 4x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.diag(input, diagonal=0, out=None) → Tensor\n",
    "```\n",
    "\n",
    "*   如果输入是一个向量( `1D` 张量), 则返回一个以 `input` 为对角线元素的 `2D` 方阵.\n",
    "*   如果输入是一个矩阵( `2D` 张量), 则返回一个包含 `input` 对角线元素的1D张量.\n",
    "\n",
    "参数 `diagonal` 指定对角线:\n",
    "\n",
    "*   `diagonal` = 0, 主对角线.\n",
    "*   `diagonal` &gt; 0, 主对角线之上.\n",
    "*   `diagonal` &lt; 0, 主对角线之下.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `diagonal (int, 可选)` – 指定对角线\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "获得以 `input` 为对角线的方阵:\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3)\n",
    ">>> a\n",
    "\n",
    " 1.0480\n",
    "-2.3405\n",
    "-1.1138\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    ">>> torch.diag(a)\n",
    "\n",
    " 1.0480  0.0000  0.0000\n",
    " 0.0000 -2.3405  0.0000\n",
    " 0.0000  0.0000 -1.1138\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.diag(a, 1)\n",
    "\n",
    " 0.0000  1.0480  0.0000  0.0000\n",
    " 0.0000  0.0000 -2.3405  0.0000\n",
    " 0.0000  0.0000  0.0000 -1.1138\n",
    " 0.0000  0.0000  0.0000  0.0000\n",
    "[torch.FloatTensor of size 4x4]\n",
    "\n",
    "```\n",
    "\n",
    "获得给定矩阵的第k条对角线:\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3, 3)\n",
    ">>> a\n",
    "\n",
    "-1.5328 -1.3210 -1.5204\n",
    " 0.8596  0.0471 -0.2239\n",
    "-0.6617  0.0146 -1.0817\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.diag(a, 0)\n",
    "\n",
    "-1.5328\n",
    " 0.0471\n",
    "-1.0817\n",
    "[torch.FloatTensor of size 3]\n",
    "\n",
    ">>> torch.diag(a, 1)\n",
    "\n",
    "-1.3210\n",
    "-0.2239\n",
    "[torch.FloatTensor of size 2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.histc(input, bins=100, min=0, max=0, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算输入张量的直方图.\n",
    "\n",
    "以 `min` 和 `max` 为 `range` 边界, 将其均分成 `bins` 个直条, 然后将排序好的数据划分到各个直条 `(bins)` 中. 如果 `min` 和 `max` 都为 0, 则利用数据中的最大最小值作为边界.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入张量\n",
    "*   `bins (int)` – 直方图 `bins` (直条)的个数(默认100个)\n",
    "*   `min (int)` – `range` 的下边界(包含)\n",
    "*   `max (int)` – `range` 的上边界(包含)\n",
    "*   `out (Tensor, 可选)` – 结果张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：直方图\n",
    "\n",
    "返回类型：`Tensor`\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3)\n",
    "FloatTensor([0, 2, 1, 0])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.renorm(input, p, dim, maxnorm, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个张量, 包含规范化后的各个子张量, 使得沿着 `dim` 维划分的各子张量的 `p` 范数小于 `maxnorm`\n",
    "\n",
    "注解：\n",
    "\n",
    "如果 p 范数的值小于 `maxnorm`, 则当前子张量不需要修改.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `p (float)` – 范数的 `p`\n",
    "*   `dim (int)` – 沿着此维切片, 得到张量子集\n",
    "*   `maxnorm (float)` – 每个子张量的范数的最大值\n",
    "*   `out (Tensor, 可选)` – 结果张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.ones(3, 3)\n",
    ">>> x[1].fill_(2)\n",
    ">>> x[2].fill_(3)\n",
    ">>> x\n",
    "\n",
    " 1  1  1\n",
    " 2  2  2\n",
    " 3  3  3\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.renorm(x, 1, 0, 5)\n",
    "\n",
    " 1.0000  1.0000  1.0000\n",
    " 1.6667  1.6667  1.6667\n",
    " 1.6667  1.6667  1.6667\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.trace(input) → float\n",
    "```\n",
    "\n",
    "返回输入 2 维矩阵对角线元素的和(迹).\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.arange(1, 10).view(3, 3)\n",
    ">>> x\n",
    "\n",
    " 1  2  3\n",
    " 4  5  6\n",
    " 7  8  9\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.trace(x)\n",
    "15.0\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.tril(input, diagonal=0, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个张量, 包含输入矩阵 ( `2D` 张量)的下三角部分, 其余部分被设为 0.\n",
    "\n",
    "这里所说的下三角部分为矩阵指定对角线 `diagonal` 在线里的和下面的元素.\n",
    "\n",
    "参数 `diagonal` 控制对角线.\n",
    "\n",
    "*   `diagonal` = 0, 主对角线.\n",
    "*   `diagonal` &gt; 0, 主对角线之上.\n",
    "*   `diagonal` &lt; 0, 主对角线之下.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `diagonal (int, 可选)` – 指定对角线\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a\n",
    "\n",
    " 1.3225  1.7304  1.4573\n",
    "-0.3052 -0.3111 -0.1809\n",
    " 1.2469  0.0064 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.tril(a)\n",
    "\n",
    " 1.3225  0.0000  0.0000\n",
    "-0.3052 -0.3111  0.0000\n",
    " 1.2469  0.0064 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.tril(a, diagonal=1)\n",
    "\n",
    " 1.3225  1.7304  0.0000\n",
    "-0.3052 -0.3111 -0.1809\n",
    " 1.2469  0.0064 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.tril(a, diagonal=-1)\n",
    "\n",
    " 0.0000  0.0000  0.0000\n",
    "-0.3052  0.0000  0.0000\n",
    " 1.2469  0.0064  0.0000\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.triu(input, diagonal=0, out=None) → Tensor\n",
    "```\n",
    "\n",
    "返回一个张量, 包含输入矩阵 ( `2D` 张量)的上三角部分, 其余部分被设为 0.\n",
    "\n",
    "这里所说的下三角部分为矩阵指定对角线 `diagonal` 在线里的和上面的元素.\n",
    "\n",
    "参数 `diagonal` 控制对角线.\n",
    "\n",
    "*   `diagonal` = 0, 主对角线.\n",
    "*   `diagonal` &gt; 0, 主对角线之上.\n",
    "*   `diagonal` &lt; 0, 主对角线之下.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – 输入 `Tensor`\n",
    "*   `diagonal (int, 可选)` – 指定对角线\n",
    "*   `out (Tensor, 可选)` – 输出 `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a\n",
    "\n",
    " 1.3225  1.7304  1.4573\n",
    "-0.3052 -0.3111 -0.1809\n",
    " 1.2469  0.0064 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.triu(a)\n",
    "\n",
    " 1.3225  1.7304  1.4573\n",
    " 0.0000 -0.3111 -0.1809\n",
    " 0.0000  0.0000 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.triu(a, diagonal=1)\n",
    "\n",
    " 0.0000  1.7304  1.4573\n",
    " 0.0000  0.0000 -0.1809\n",
    " 0.0000  0.0000  0.0000\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.triu(a, diagonal=-1)\n",
    "\n",
    " 1.3225  1.7304  1.4573\n",
    "-0.3052 -0.3111 -0.1809\n",
    " 0.0000  0.0064 -1.6250\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "### BLAS and LAPACK Operations (BLAS和LAPACK操作)\n",
    "\n",
    "```py\n",
    "torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行保存在 `batch1` 和 `batch2` 中的矩阵的批量点乘, 伴随着一个减少的相加步骤 (所有的矩阵乘法沿第一维累加). `mat` 被相加到最终的结果中.\n",
    "\n",
    "`batch1` 和 `batch2` 必须是三维的张量, 且每个包含相同数量的矩阵.\n",
    "\n",
    "如果 `batch1` 是一个 `b x n x m` 的张量, `batch2` 是一个 `b x m x p`的张量, 那么 `mat` 必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 且是一个 `n x p` 的张量, 同时 attr:`out` 将是一个 `n x p` 的张量.\n",
    "\n",
    "换句话说, ![res = (beta * M) + (alpha * sum(batch1_i @ batch2_i, i = 0, b))](img/tex-7ef2304a9f7469a9bd7902e33b85981c.gif)\n",
    "\n",
    "对于 `FloatTensor` 或者 `DoubleTensor` 类型的输入, 参数 `beta` 和 `alpha` 必须是实数, 否则他们应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `beta (Number, 可选)` – 作用于 `mat` 的乘子 (系数)\n",
    "*   `mat (Tensor)` – 要被相加的矩阵\n",
    "*   `alpha (Number, 可选)` – 作用于 `batch1 @ batch2` 的乘子\n",
    "*   `batch1 (Tensor)` – 要相乘的第一批矩阵\n",
    "*   `batch2 (Tensor)` – 要相乘的第二批矩阵\n",
    "*   `out (Tensor, 可选)` – 输出的张量结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> M = torch.randn(3, 5)\n",
    ">>> batch1 = torch.randn(10, 3, 4)\n",
    ">>> batch2 = torch.randn(10, 4, 5)\n",
    ">>> torch.addbmm(M, batch1, batch2)\n",
    "\n",
    " -3.1162  11.0071   7.3102   0.1824  -7.6892\n",
    " 1.8265   6.0739   0.4589  -0.5641  -5.4283\n",
    " -9.3387  -0.1794  -1.2318  -6.8841  -4.7239\n",
    "[torch.FloatTensor of size 3x5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行矩阵 `mat1` 和 `mat2` 的相乘. 矩阵 `mat` 将与相乘的最终计算结果相加.\n",
    "\n",
    "如果 `mat1` 是一个 `n x m` 的张量, `mat2` 是一个 `m x p`的张量, 那么 `mat` 必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 且是一个 `n x p` 的张量, 同时 attr:`out` 将是一个 `n x p` 的张量.\n",
    "\n",
    "换句话说, ![out = (beta * M) + (alpha * mat1 @ mat2)](img/tex-3136ca146acddc296c21d3faf3238418.gif)\n",
    "\n",
    "对于 `FloatTensor` 或者 `DoubleTensor` 类型的输入, 参数 `beta` 和 `alpha` 必须是实数, 否则他们应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `beta (Number, 可选)` – 作用于`mat`的乘子\n",
    "*   `mat (Tensor)` – 要被相加的矩阵\n",
    "*   `alpha (Number, 可选)` – 作用于`mat1 @ mat2`的乘子\n",
    "*   `mat1 (Tensor)` – 要相乘的第一个矩阵\n",
    "*   `mat2 (Tensor)` – 要相乘的第二个矩阵\n",
    "*   `out (Tensor, 可选)` – 输出结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> M = torch.randn(2, 3)\n",
    ">>> mat1 = torch.randn(2, 3)\n",
    ">>> mat2 = torch.randn(3, 3)\n",
    ">>> torch.addmm(M, mat1, mat2)\n",
    "\n",
    "-0.4095 -1.9703  1.3561\n",
    " 5.7674 -4.9760  2.7378\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行矩阵 `mat` 和向量 `vec` 的相乘. 矩阵 `tensor` 将与相乘的最终计算结果相加.\n",
    "\n",
    "如果 `mat` 是一个 `n x m` 的张量, `vec` 是一个长度为 `m` 的一维张量, 那么 :`tensor` 必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 且是一个长度为 `n` 的一维张量, 同时 attr:`out` 将是一个长度为 `n` 的一维张量.\n",
    "\n",
    "`alpha` 和 `beta` 分别是 `mat * vec` 和 `tensor` 的缩放因子.\n",
    "\n",
    "换句话说, ![out = (beta * tensor) + (alpha * (mat @ vec2))](img/tex-cbf642b6dbf68ac19bcc426976b8a0d5.gif)\n",
    "\n",
    "对于 `FloatTensor` 或者 `DoubleTensor` 类型的输入, 参数 `beta` 和 `alpha` 必须是实数, 否则他们应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `beta (Number, 可选)` – 作用于 `tensor` 的乘子\n",
    "*   `tensor (Tensor)` – 要被相加的向量\n",
    "*   `alpha (Number, 可选)` – 作用于 `mat @ vec` 的乘子\n",
    "*   `mat (Tensor)` – 要被相乘的矩阵\n",
    "*   `vec (Tensor)` – 要被要乘的向量\n",
    "*   `out (Tensor, 可选)` – 输出结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> M = torch.randn(2)\n",
    ">>> mat = torch.randn(2, 3)\n",
    ">>> vec = torch.randn(3)\n",
    ">>> torch.addmv(M, mat, vec)\n",
    "\n",
    "-2.0939\n",
    "-2.2950\n",
    "[torch.FloatTensor of size 2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.addr(beta=1, mat, alpha=1, vec1, vec2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行向量 `vec1` 和 `vec2` 的外积, 并把外积计算结果与矩阵 `mat` 相加.\n",
    "\n",
    "可选值 `beta` 和 `alpha` 是标量, 分别与 `mat` 和 ![(vec1 \\otimes vec2)](img/tex-ab16a4d3626255c0f2ff1b18ec903b95.gif) 相乘.\n",
    "\n",
    "换句话说, ![out = (beta * mat) + (alpha * vec1 \\otimes vec2)](img/tex-bbe0ebf0dbe9721a25240f560ff6e3ff.gif)\n",
    "\n",
    "如果 `vec1` 是一个长度为 `n` 的向量, `vec2` 是一个长度为 `m` 的向量, 那么 `mat` 必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 且是一个大小为 `n x m` 的矩阵, 同时 `out` 将是一个大小为 `n x m` 的矩阵.\n",
    "\n",
    "对于 `FloatTensor` 或者 `DoubleTensor` 类型的输入, 参数 `beta` 和 `alpha` 必须是实数, 否则他们应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `beta (Number, 可选)` – 作用于 `mat` 的乘子\n",
    "*   `mat (Tensor)` – 要被相加的矩阵\n",
    "*   `alpha (Number, 可选)` – 作用于 `vec1` 和 `vec2` 外积计算结果的乘子\n",
    "*   `vec1 (Tensor)` – 外积计算的第一个向量\n",
    "*   `vec2 (Tensor)` – 外积计算的第二个向量\n",
    "*   `out (Tensor, 可选)` – 输出结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> vec1 = torch.arange(1, 4)\n",
    ">>> vec2 = torch.arange(1, 3)\n",
    ">>> M = torch.zeros(3, 2)\n",
    ">>> torch.addr(M, vec1, vec2)\n",
    " 1  2\n",
    " 2  4\n",
    " 3  6\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.baddbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行保存在 `batch1` 和 `batch2` 中的矩阵的批量点乘. `mat` 被相加到最终的结果中.\n",
    "\n",
    "`batch1` 和 `batch2` 必须是三维的张量, 且每个包含相同数量的矩阵.\n",
    "\n",
    "如果 `batch1` 是一个 `b x n x m` 的张量, `batch2` 是一个 `b x m x p`的张量, 那么 `mat` 必须是 [broadcastable](notes/broadcasting.html#broadcasting-semantics) 且是一个 `b x n x p` 的张量, 同时 attr:`out` 将是一个 `b x n x p` 的张量.\n",
    "\n",
    "换句话说, ![res_i = (beta * M_i) + (alpha * batch1_i \\times batch2_i)](img/tex-4c174ea27877cea5aeef8649acf33a61.gif)\n",
    "\n",
    "对于 `FloatTensor` 或者 `DoubleTensor` 类型的输入, 参数 `beta` 和 `alpha` 必须是实数, 否则他们应该是整数.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `beta (Number, 可选)` – 作用于 `mat` 的乘子 (系数)\n",
    "*   `mat (Tensor)` – 要被相加的张量\n",
    "*   `alpha (Number, 可选)` – 作用于 `batch1 @ batch2` 的乘子\n",
    "*   `batch1 (Tensor)` – 要相乘的第一批矩阵\n",
    "*   `batch2 (Tensor)` – 要相乘的第二批矩阵\n",
    "*   `out (Tensor, 可选)` – 输出的张量结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> M = torch.randn(10, 3, 5)\n",
    ">>> batch1 = torch.randn(10, 3, 4)\n",
    ">>> batch2 = torch.randn(10, 4, 5)\n",
    ">>> torch.baddbmm(M, batch1, batch2).size()\n",
    "torch.Size([10, 3, 5])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.bmm(batch1, batch2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行保存在 `batch1` 和 `batch2` 中的矩阵的批量点乘.\n",
    "\n",
    "`batch1` 和 `batch2` 必须是三维的张量, 且每个包含相同数量的矩阵.\n",
    "\n",
    "如果 `batch1` 是一个 `b x n x m` 的张量, `batch2` 是一个 `b x m x p` 的张量, `out` 将是一个 `b x n x p` 的张量.\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数不能参考 broadcast](notes/broadcasting.html#broadcasting-semantics). 对于广播矩阵相乘, 参见 [`torch.matmul()`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `batch1 (Tensor)` – 要相乘的第一批矩阵\n",
    "*   `batch2 (Tensor)` – 要相乘的第二批矩阵\n",
    "*   `out (Tensor, 可选)` – 输出结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> batch1 = torch.randn(10, 3, 4)\n",
    ">>> batch2 = torch.randn(10, 4, 5)\n",
    ">>> res = torch.bmm(batch1, batch2)\n",
    ">>> res.size()\n",
    "torch.Size([10, 3, 5])\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.btrifact(A, info=None, pivot=True) → Tensor, IntTensor\n",
    "```\n",
    "\n",
    "批量 LU 分解.\n",
    "\n",
    "返回一个包含 LU 分解和枢轴的元组. 对于每个 minibatch 示例, 如果分解成功, 可选参数 `info` 将提供分解信息. `info` 的值来自 dgetrf, 若是非零值, 则表示有错误发生. 如果 cuda 被使用的话, 具体的值来自 cublas, 否则来自 LAPACK. 如果设置了 pivot, 那么旋转操作将被执行.\n",
    "\n",
    "参数：`A (Tensor)` – 要分解的张量."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> A = torch.randn(2, 3, 3)\n",
    ">>> A_LU = A.btrifact()\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.btrisolve(b, LU_data, LU_pivots) → Tensor\n",
    "```\n",
    "\n",
    "批量 LU 解.\n",
    "\n",
    "返回线性系统 Ax = b 的 LU 解.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `b (Tensor)` – RHS tensor.\n",
    "*   `LU_data (Tensor)` – Pivoted LU factorization of A from btrifact.\n",
    "*   `LU_pivots (IntTensor)` – Pivots of the LU factorization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> A = torch.randn(2, 3, 3)\n",
    ">>> b = torch.randn(2, 3)\n",
    ">>> A_LU = torch.btrifact(A)\n",
    ">>> x = b.btrisolve(*A_LU)\n",
    ">>> torch.norm(A.bmm(x.unsqueeze(2)) - b)\n",
    "6.664001874625056e-08\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.dot(tensor1, tensor2) → float\n",
    "```\n",
    "\n",
    "计算两个张量的点乘 (内积).\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数不支持 [broadcast](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))\n",
    "7.0\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.eig(a, eigenvectors=False, out=None) -> (Tensor, Tensor)\n",
    "```\n",
    "\n",
    "计算实数方阵的特征值和特征向量.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `a (Tensor)` – 一个要被计算特征值与特征向量的方阵\n",
    "*   `eigenvectors (bool)` – 若为 `True`, 表示特征值与特征向量都被计算. 否则, 仅计算特征值.\n",
    "*   `out (tuple, 可选)` – 输出张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：包含以下的元组：\n",
    "\n",
    "*   `e (Tensor)`: `a` 的左特征值\n",
    "*   `v (Tensor)`: 如果 `eigenvectors` 为 `True`, 表示 `a` 的特征向量; 否则是一个空的张量\n",
    "\n",
    "返回类型：返回一个元组, `(Tensor, Tensor)`\n",
    "\n",
    "```py\n",
    "torch.gels(B, A, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算秩为 ![m](img/tex-6f8f57715090da2632453988d9a1501b.gif) 的， 大小为 m x n 的矩阵 ![A](img/tex-7fc56270e7a70fa81a5935b72eacbe29.gif) 最小二乘和最小范数问题的解\n",
    "\n",
    "如果 !m &gt;= n](img/tex-67ab86856a95fdd869cf2a0fff67d8be.gif), [`gels()` 求解最小二乘问题:\n",
    "\n",
    "![\\begin{array}{ll} \\mbox{minimize} & \\|AX-B\\|_F. \\end{array}](img/tex-e616b1701f9adb598d4bc4809d5d9d13.gif)\n",
    "\n",
    "如果 !m &lt; n](img/tex-ad3a40ab7b4c9be133873408eb36bcc1.gif), [`gels()` 求解最小范数问题:\n",
    "\n",
    "![\\begin{array}{ll} \\mbox{minimize} & \\|X\\|_F & \\mbox{subject to} & AX = B. \\end{array}](img/tex-3f143297c60126363ebd87566cbf4d03.gif)\n",
    "\n",
    "返回的矩阵 ![X](img/tex-02129bb861061d1a052c592e2dc6b383.gif) 的头 ![n](img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif) 行包含解信息. 其余行包含剩余信息: 从第 ![n](img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif) 行开始的每列的 euclidean 范数, 是对应列的剩余.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `B (Tensor)` – The matrix ![B](img/tex-9d5ed678fe57bcca610140957afab571.gif)\n",
    "*   `A (Tensor)` – The ![m](img/tex-6f8f57715090da2632453988d9a1501b.gif) by ![n](img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif) matrix ![A](img/tex-7fc56270e7a70fa81a5935b72eacbe29.gif)\n",
    "*   `out (tuple, 可选)` – Optional destination tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回值：包含以下的元组：\n",
    "\n",
    "*   `X (Tensor)`: 最小二乘解\n",
    "*   `qr (Tensor)`: QR 分解的详细信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回类型：`(Tensor, Tensor)`\n",
    "\n",
    "注解：\n",
    "\n",
    "不管输入矩阵的步长如何, 返回来的矩阵将总是被转置. 也就是, 他们的步长是 `(1, m)` 而不是 `(m, 1)`.\n",
    "\n",
    "示例：\n",
    "\n",
    "```py\n",
    ">>> A = torch.Tensor([[1, 1, 1],\n",
    "...                   [2, 3, 4],\n",
    "...                   [3, 5, 2],\n",
    "...                   [4, 2, 5],\n",
    "...                   [5, 4, 3]])\n",
    ">>> B = torch.Tensor([[-10, -3],\n",
    " [ 12, 14],\n",
    " [ 14, 12],\n",
    " [ 16, 16],\n",
    " [ 18, 16]])\n",
    ">>> X, _ = torch.gels(B, A)\n",
    ">>> X\n",
    "2.0000  1.0000\n",
    "1.0000  1.0000\n",
    "1.0000  2.0000\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.geqrf(input, out=None) -> (Tensor, Tensor)\n",
    "```\n",
    "\n",
    "这是直接调用 LAPACK 的低层函数.\n",
    "\n",
    "通常您应该使用 `torch.qr()` 来代替之.\n",
    "\n",
    "计算 `input` 的 QR 分解, 但不构造 `Q` 和 `R` 作为显示分开的矩阵.\n",
    "\n",
    "然而, 这样直接调用 LAPACK 的底层函数 `?geqrf`, 会产生一连串的 ‘elementary reflectors’.\n",
    "\n",
    "更多信息请参见 [LAPACK documentation](https://software.intel.com/en-us/node/521004) .\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input matrix\n",
    "*   `out (tuple, 可选)` – The result tuple of (Tensor, Tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.ger(vec1, vec2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算 `vec1` 和 `vec2` 的外积. 如果 `vec1` 是一个长度为 `n` 的向量, `vec2` 是一个长度为 `m` 的向量, 那么 `out` 必须是一个 `n x m` 的矩阵.\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数不支持 [broadcast](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `vec1 (Tensor)` – 1D input vector\n",
    "*   `vec2 (Tensor)` – 1D input vector\n",
    "*   `out (Tensor, 可选)` – optional output matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> v1 = torch.arange(1, 5)\n",
    ">>> v2 = torch.arange(1, 4)\n",
    ">>> torch.ger(v1, v2)\n",
    "\n",
    " 1   2   3\n",
    " 2   4   6\n",
    " 3   6   9\n",
    " 4   8  12\n",
    "[torch.FloatTensor of size 4x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.gesv(B, A, out=None) -> (Tensor, Tensor)\n",
    "```\n",
    "\n",
    "`X, LU = torch.gesv(B, A)` , 该函数返回线性系统 ![AX = B](img/tex-87f9241ed3c96b751dca1150b5510ed0.gif) 的解.\n",
    "\n",
    "`LU` 包含 `A` 的 LU 分解因子 `L` 和 `U`.\n",
    "\n",
    "`A` 必须是方阵, 且是非奇异的 (2维可逆张量).\n",
    "\n",
    "如果 `A` 是一个 `m x m` 矩阵, `B` 是一个 `m x k` 的矩阵, 那么结果 `LU` 的大小为 `m x m`, `X` 的大小为 `m x k` .\n",
    "\n",
    "注解：\n",
    "\n",
    "Irrespective of the original strides, the returned matrices `X` and `LU` will be transposed, i.e. with strides `(1, m)` instead of `(m, 1)`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `B (Tensor)` – input matrix of `m x k` dimensions\n",
    "*   `A (Tensor)` – input square matrix of `m x m` dimensions\n",
    "*   `out (Tensor, 可选)` – optional output matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> A = torch.Tensor([[6.80, -2.11,  5.66,  5.97,  8.23],\n",
    "...                   [-6.05, -3.30,  5.36, -4.44,  1.08],\n",
    "...                   [-0.45,  2.58, -2.70,  0.27,  9.04],\n",
    "...                   [8.32,  2.71,  4.35,  -7.17,  2.14],\n",
    "...                   [-9.67, -5.14, -7.26,  6.08, -6.87]]).t()\n",
    ">>> B = torch.Tensor([[4.02,  6.19, -8.22, -7.57, -3.03],\n",
    "...                   [-1.56,  4.00, -8.67,  1.75,  2.86],\n",
    "...                   [9.81, -4.09, -4.57, -8.61,  8.99]]).t()\n",
    ">>> X, LU = torch.gesv(B, A)\n",
    ">>> torch.dist(B, torch.mm(A, X))\n",
    "9.250057093890353e-06\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.inverse(input, out=None) → Tensor\n",
    "```\n",
    "\n",
    "计算方阵 `input` 的逆.\n",
    "\n",
    "注解：\n",
    "\n",
    "Irrespective of the original strides, the returned matrix will be transposed, i.e. with strides `(1, m)` instead of `(m, 1)`\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input 2D square `Tensor`\n",
    "*   `out (Tensor, 可选)` – the optional output `Tensor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> x = torch.rand(10, 10)\n",
    ">>> x\n",
    "\n",
    " 0.7800  0.2267  0.7855  0.9479  0.5914  0.7119  0.4437  0.9131  0.1289  0.1982\n",
    " 0.0045  0.0425  0.2229  0.4626  0.6210  0.0207  0.6338  0.7067  0.6381  0.8196\n",
    " 0.8350  0.7810  0.8526  0.9364  0.7504  0.2737  0.0694  0.5899  0.8516  0.3883\n",
    " 0.6280  0.6016  0.5357  0.2936  0.7827  0.2772  0.0744  0.2627  0.6326  0.9153\n",
    " 0.7897  0.0226  0.3102  0.0198  0.9415  0.9896  0.3528  0.9397  0.2074  0.6980\n",
    " 0.5235  0.6119  0.6522  0.3399  0.3205  0.5555  0.8454  0.3792  0.4927  0.6086\n",
    " 0.1048  0.0328  0.5734  0.6318  0.9802  0.4458  0.0979  0.3320  0.3701  0.0909\n",
    " 0.2616  0.3485  0.4370  0.5620  0.5291  0.8295  0.7693  0.1807  0.0650  0.8497\n",
    " 0.1655  0.2192  0.6913  0.0093  0.0178  0.3064  0.6715  0.5101  0.2561  0.3396\n",
    " 0.4370  0.4695  0.8333  0.1180  0.4266  0.4161  0.0699  0.4263  0.8865  0.2578\n",
    "[torch.FloatTensor of size 10x10]\n",
    "\n",
    ">>> x = torch.rand(10, 10)\n",
    ">>> y = torch.inverse(x)\n",
    ">>> z = torch.mm(x, y)\n",
    ">>> z\n",
    "\n",
    " 1.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000\n",
    " 0.0000  1.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000 -0.0000\n",
    " 0.0000  0.0000  1.0000 -0.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000\n",
    " 0.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000  0.0000\n",
    " 0.0000  0.0000 -0.0000 -0.0000  1.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000\n",
    " 0.0000  0.0000  0.0000 -0.0000  0.0000  1.0000 -0.0000 -0.0000 -0.0000 -0.0000\n",
    " 0.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  1.0000  0.0000 -0.0000  0.0000\n",
    " 0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000  1.0000 -0.0000  0.0000\n",
    "-0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000 -0.0000  1.0000 -0.0000\n",
    "-0.0000  0.0000 -0.0000 -0.0000 -0.0000  0.0000 -0.0000 -0.0000  0.0000  1.0000\n",
    "[torch.FloatTensor of size 10x10]\n",
    "\n",
    ">>> torch.max(torch.abs(z - torch.eye(10))) # Max nonzero\n",
    "5.096662789583206e-07\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.matmul(tensor1, tensor2, out=None)\n",
    "```\n",
    "\n",
    "Matrix product of two tensors.\n",
    "\n",
    "The behavior depends on the dimensionality of the tensors as follows:\n",
    "\n",
    "*   If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
    "*   If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
    "*   If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.\n",
    "*   If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.\n",
    "*   If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N &gt; 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are [broadcasted](notes/broadcasting.html#broadcasting-semantics) (and thus must be broadcastable). For example, if `tensor1` is a `j x 1 x n x m` Tensor and `tensor2` is a `k x m x p` Tensor, `out` will be an `j x k x n x p` Tensor.\n",
    "\n",
    "注解：\n",
    "\n",
    "The 1-dimensional dot product version of this function does not support an `out` parameter.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `tensor1 (Tensor)` – First tensor to be multiplied\n",
    "*   `tensor2 (Tensor)` – Second tensor to be multiplied\n",
    "*   `out (Tensor, 可选)` – Output tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.mm(mat1, mat2, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行 `mat1` 和 `mat2` 的矩阵乘法.\n",
    "\n",
    "如果 `mat1` 是一个 `n x m` 张量, `mat2` 是一个 `m x p` 张量, `out` 将是一个 `n x p` 张量.\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数不支持 broadcast](notes/broadcasting.html#broadcasting-semantics). 要使用支持广播矩阵乘法, 参见 [`torch.matmul()`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `mat1 (Tensor)` – First matrix to be multiplied\n",
    "*   `mat2 (Tensor)` – Second matrix to be multiplied\n",
    "*   `out (Tensor, 可选)` – Output tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> mat1 = torch.randn(2, 3)\n",
    ">>> mat2 = torch.randn(3, 3)\n",
    ">>> torch.mm(mat1, mat2)\n",
    " 0.0519 -0.3304  1.2232\n",
    " 4.3910 -5.1498  2.7571\n",
    "[torch.FloatTensor of size 2x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.mv(mat, vec, out=None) → Tensor\n",
    "```\n",
    "\n",
    "执行矩阵 `mat` 与向量 `vec` 的乘法操作.\n",
    "\n",
    "如果 `mat` 是一个 `n x m` 张量, `vec` 是一个大小为 `m` 的一维张量, `out` 将是一个大小为 `n` 的张量.\n",
    "\n",
    "注解：\n",
    "\n",
    "这个函数不支持 [broadcast](notes/broadcasting.html#broadcasting-semantics).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `mat (Tensor)` – matrix to be multiplied\n",
    "*   `vec (Tensor)` – vector to be multiplied\n",
    "*   `out (Tensor, 可选)` – Output tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> mat = torch.randn(2, 3)\n",
    ">>> vec = torch.randn(3)\n",
    ">>> torch.mv(mat, vec)\n",
    "-2.0939\n",
    "-2.2950\n",
    "[torch.FloatTensor of size 2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.orgqr()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.ormqr()\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.potrf(a, out=None)\n",
    "```\n",
    "\n",
    "potrf(a, upper, out=None)\n",
    "\n",
    "计算半正定矩阵 `a`: 的 Cholesky 分解. 返回结果 `u`, 若 `upper` 设为 `True` 或未提供时, `u` 是一个上三角矩阵, 使得 ![a = u^T u](img/tex-a495982217ecb8f8c1c154c349699217.gif) 成立; 若 `upper` 设为 `False`, `u` 是一个下三角矩阵, 使得 ![a = u u^T](img/tex-af2a8f54be49d4fb8cc53b20d501b681.gif) 成立.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `a (Tensor)` – the input 2D `Tensor`, a symmetric positive semidefinite matrix\n",
    "*   `upper (bool, 可选)` – Return upper (default) or lower triangular matrix\n",
    "*   `out (Tensor, 可选)` – A Tensor for u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a = torch.mm(a, a.t()) # make symmetric positive definite\n",
    ">>> u = torch.potrf(a)\n",
    ">>> a\n",
    "\n",
    " 2.3563  3.2318 -0.9406\n",
    " 3.2318  4.9557 -2.1618\n",
    "-0.9406 -2.1618  2.2443\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> u\n",
    "\n",
    " 1.5350  2.1054 -0.6127\n",
    " 0.0000  0.7233 -1.2053\n",
    " 0.0000  0.0000  0.6451\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.mm(u.t(),u)\n",
    "\n",
    " 2.3563  3.2318 -0.9406\n",
    " 3.2318  4.9557 -2.1618\n",
    "-0.9406 -2.1618  2.2443\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.potri(u, out=None)\n",
    "```\n",
    "\n",
    "potri(u, upper, out=None)\n",
    "\n",
    "给定一个半正定矩阵的 Cholesky 分解因子 `u`, 计算该半正定矩阵的逆. 返回矩阵 `inv`, 若 `upper` 设为 `True` 或为提供, `u` 是一个上三角矩阵, 使得 ![inv = (u^T u)^{-1}](img/tex-9c4b0a3ec8f2662acb48158c085131b6.gif) 成立; 若 `upper` 设为 `False`, `u` 是一个下三角矩阵, 使得 ![inv = (u u^T)^{-1}](img/tex-a516e9c3e09592a93fa8a11efe052352.gif) 成立.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `u (Tensor)` – the input 2D `Tensor`, a upper or lower triangular Cholesky factor\n",
    "*   `upper (bool, 可选)` – Flag if upper (default) or lower triangular matrix\n",
    "*   `out (Tensor, 可选)` – A Tensor for inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a = torch.mm(a, a.t()) # make symmetric positive definite\n",
    ">>> u = torch.potrf(a)\n",
    ">>> a\n",
    "\n",
    " 2.3563  3.2318 -0.9406\n",
    " 3.2318  4.9557 -2.1618\n",
    "-0.9406 -2.1618  2.2443\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.potri(u)\n",
    "\n",
    " 12.5724 -10.1765  -4.5333\n",
    "-10.1765   8.5852   4.0047\n",
    " -4.5333   4.0047   2.4031\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> a.inverse()\n",
    "\n",
    " 12.5723 -10.1765  -4.5333\n",
    "-10.1765   8.5852   4.0047\n",
    " -4.5333   4.0047   2.4031\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.potrs(b, u, out=None)\n",
    "```\n",
    "\n",
    "potrs(b, u, upper, out=None)\n",
    "\n",
    "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its given a Cholesky factor matrix `u`: returns matrix `c` If `upper` is `True` or not provided, `u` is and upper triangular such that ![c = (u^T u)^{-1} b](img/tex-8adaa3f465e6b647154735a77655849a.gif). If `upper` is `False`, `u` is and lower triangular such that ![c = (u u^T)^{-1} b](img/tex-d746800a59c0e059328a7275a82f2109.gif).\n",
    "\n",
    "注解：\n",
    "\n",
    "`b` is always a 2D `Tensor`, use `b.unsqueeze(1)` to convert a vector.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `b (Tensor)` – the right hand side 2D `Tensor`\n",
    "*   `u (Tensor)` – the input 2D `Tensor`, a upper or lower triangular Cholesky factor\n",
    "*   `upper (bool, 可选)` – Return upper (default) or lower triangular matrix\n",
    "*   `out (Tensor, 可选)` – A Tensor for c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a = torch.mm(a, a.t()) # make symmetric positive definite\n",
    ">>> u = torch.potrf(a)\n",
    ">>> a\n",
    "\n",
    " 2.3563  3.2318 -0.9406\n",
    " 3.2318  4.9557 -2.1618\n",
    "-0.9406 -2.1618  2.2443\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> b = torch.randn(3,2)\n",
    ">>> b\n",
    "\n",
    "-0.3119 -1.8224\n",
    "-0.2798  0.1789\n",
    "-0.3735  1.7451\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    ">>> torch.potrs(b,u)\n",
    "\n",
    " 0.6187 -32.6438\n",
    "-0.7234  27.0703\n",
    "-0.6039  13.1717\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    ">>> torch.mm(a.inverse(),b)\n",
    "\n",
    " 0.6187 -32.6436\n",
    "-0.7234  27.0702\n",
    "-0.6039  13.1717\n",
    "[torch.FloatTensor of size 3x2]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.pstrf(a, out=None)\n",
    "```\n",
    "\n",
    "pstrf(a, upper, out=None)\n",
    "\n",
    "Computes the pivoted Cholesky decomposition of a positive semidefinite matrix `a`: returns matrices `u` and `piv`. If `upper` is `True` or not provided, `u` is and upper triangular such that ![a = p^T u^T u p](img/tex-a15f289c6963aee50745ebf64701af1a.gif), with `p` the permutation given by `piv`. If `upper` is `False`, `u` is and lower triangular such that ![a = p^T u u^T p](img/tex-09b54d58ebd0ed1f4092bda5c5ecb4f8.gif).\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `a (Tensor)` – the input 2D `Tensor`\n",
    "*   `upper (bool, 可选)` – Return upper (default) or lower triangular matrix\n",
    "*   `out (tuple, 可选)` – A tuple of u and piv Tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.randn(3,3)\n",
    ">>> a = torch.mm(a, a.t()) # make symmetric positive definite\n",
    ">>> a\n",
    "\n",
    " 5.4417 -2.5280  1.3643\n",
    "-2.5280  2.9689 -2.1368\n",
    " 1.3643 -2.1368  4.6116\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> u,piv = torch.pstrf(a)\n",
    ">>> u\n",
    "\n",
    " 2.3328  0.5848 -1.0837\n",
    " 0.0000  2.0663 -0.7274\n",
    " 0.0000  0.0000  1.1249\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> piv\n",
    "\n",
    " 0\n",
    " 2\n",
    " 1\n",
    "[torch.IntTensor of size 3]\n",
    "\n",
    ">>> p = torch.eye(3).index_select(0,piv.long()).index_select(0,piv.long()).t() # make pivot permutation\n",
    ">>> torch.mm(torch.mm(p.t(),torch.mm(u.t(),u)),p) # reconstruct\n",
    "\n",
    " 5.4417  1.3643 -2.5280\n",
    " 1.3643  4.6116 -2.1368\n",
    "-2.5280 -2.1368  2.9689\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.qr(input, out=None) -> (Tensor, Tensor)\n",
    "```\n",
    "\n",
    "计算矩阵 `input` 的 QR 分解. 返回矩阵 `q` 和 `r` 使得 ![x = q * r](img/tex-cdbaa8a802c8ac5fb33dc85e271f4b34.gif), 且 `q` 是一个 正交矩阵, `r` 是一个上三角矩阵.\n",
    "\n",
    "This returns the thin (reduced) QR factorization.\n",
    "\n",
    "注解：\n",
    "\n",
    "如果矩阵 `input` 中的元素太大, 那么精度可能会丢失.\n",
    "\n",
    "注解：\n",
    "\n",
    "尽管该函数总是能给您一个有效的分解, 但在不同平台上结果可能不同 - 取决于该平台上 LAPACK 的实现.\n",
    "\n",
    "注解：\n",
    "\n",
    "Irrespective of the original strides, the returned matrix `q` will be transposed, i.e. with strides `(1, m)` instead of `(m, 1)`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input 2D `Tensor`\n",
    "*   `out (tuple, 可选)` – A tuple of Q and R Tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.Tensor([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])\n",
    ">>> q, r = torch.qr(a)\n",
    ">>> q\n",
    "\n",
    "-0.8571  0.3943  0.3314\n",
    "-0.4286 -0.9029 -0.0343\n",
    " 0.2857 -0.1714  0.9429\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> r\n",
    "\n",
    " -14.0000  -21.0000   14.0000\n",
    " 0.0000 -175.0000   70.0000\n",
    " 0.0000    0.0000  -35.0000\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.mm(q, r).round()\n",
    "\n",
    " 12  -51    4\n",
    " 6  167  -68\n",
    " -4   24  -41\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    ">>> torch.mm(q.t(), q).round()\n",
    "\n",
    " 1 -0  0\n",
    "-0  1  0\n",
    " 0  0  1\n",
    "[torch.FloatTensor of size 3x3]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.svd(input, some=True, out=None) -> (Tensor, Tensor, Tensor)\n",
    "```\n",
    "\n",
    "`U, S, V = torch.svd(A)` 返回大小为 `(n x m)` 的实矩阵 `A` 的奇异值分解, 使得 ![A = USV'*](img/tex-c887f05a8f17cc1865be06bf5709faef.gif).\n",
    "\n",
    "`U` 的大小为 `n x n`\n",
    "\n",
    "`S` 的大小为`n x m`\n",
    "\n",
    "`V` 的大小为 `m x m`.\n",
    "\n",
    "`some` 表示将被计算的奇异值的总数. 如果 `some=True`, 它将计算指定的 some 数量个奇异值, 如果 `some=False`, 则计算所有奇异值.\n",
    "\n",
    "注解：\n",
    "\n",
    "Irrespective of the original strides, the returned matrix `U` will be transposed, i.e. with strides `(1, n)` instead of `(n, 1)`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input 2D Tensor\n",
    "*   `some (bool, 可选)` – controls the number of singular values to be computed\n",
    "*   `out (tuple, 可选)` – the result tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "```py\n",
    ">>> a = torch.Tensor([[8.79,  6.11, -9.15,  9.57, -3.49,  9.84],\n",
    "...                   [9.93,  6.91, -7.93,  1.64,  4.02,  0.15],\n",
    "...                   [9.83,  5.04,  4.86,  8.83,  9.80, -8.99],\n",
    "...                   [5.45, -0.27,  4.85,  0.74, 10.00, -6.02],\n",
    "...                   [3.16,  7.98,  3.01,  5.80,  4.27, -5.31]]).t()\n",
    ">>> a\n",
    "\n",
    " 8.7900   9.9300   9.8300   5.4500   3.1600\n",
    " 6.1100   6.9100   5.0400  -0.2700   7.9800\n",
    " -9.1500  -7.9300   4.8600   4.8500   3.0100\n",
    " 9.5700   1.6400   8.8300   0.7400   5.8000\n",
    " -3.4900   4.0200   9.8000  10.0000   4.2700\n",
    " 9.8400   0.1500  -8.9900  -6.0200  -5.3100\n",
    "[torch.FloatTensor of size 6x5]\n",
    "\n",
    ">>> u, s, v = torch.svd(a)\n",
    ">>> u\n",
    "\n",
    "-0.5911  0.2632  0.3554  0.3143  0.2299\n",
    "-0.3976  0.2438 -0.2224 -0.7535 -0.3636\n",
    "-0.0335 -0.6003 -0.4508  0.2334 -0.3055\n",
    "-0.4297  0.2362 -0.6859  0.3319  0.1649\n",
    "-0.4697 -0.3509  0.3874  0.1587 -0.5183\n",
    " 0.2934  0.5763 -0.0209  0.3791 -0.6526\n",
    "[torch.FloatTensor of size 6x5]\n",
    "\n",
    ">>> s\n",
    "\n",
    " 27.4687\n",
    " 22.6432\n",
    " 8.5584\n",
    " 5.9857\n",
    " 2.0149\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> v\n",
    "\n",
    "-0.2514  0.8148 -0.2606  0.3967 -0.2180\n",
    "-0.3968  0.3587  0.7008 -0.4507  0.1402\n",
    "-0.6922 -0.2489 -0.2208  0.2513  0.5891\n",
    "-0.3662 -0.3686  0.3859  0.4342 -0.6265\n",
    "-0.4076 -0.0980 -0.4932 -0.6227 -0.4396\n",
    "[torch.FloatTensor of size 5x5]\n",
    "\n",
    ">>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))\n",
    "8.934150226306685e-06\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.symeig(input, eigenvectors=False, upper=True, out=None) -> (Tensor, Tensor)\n",
    "```\n",
    "\n",
    "`e, V = torch.symeig(input)` 返回实对称矩阵 `input` 的特征值和特征向量.\n",
    "\n",
    "`input` 和 `V` 是 `m x m` 矩阵, `e` 是一个 `m` 维的向量.\n",
    "\n",
    "这个函数计算矩阵 `input` 的所有特征值 (和向量), 使得 `input = V diag(e) V’`.\n",
    "\n",
    "布尔参数 `eigenvectors` 定义了是否计算特征向量. 如果它为 `False`, 那么只有特征值会被计算. 如果它为 `True`, 特征值和特征向量都会被计算.\n",
    "\n",
    "由于输入矩阵 `input` 被假定是对称的, 因此默认地只有它的上三角部分会被使用.\n",
    "\n",
    "如果 `upper` 是 `False`, 那么它的下三角部分会被使用.\n",
    "\n",
    "Note: Irrespective of the original strides, the returned matrix `V` will be transposed, i.e. with strides `(1, m)` instead of `(m, 1)`.\n",
    "\n",
    "参数：\n",
    "\n",
    "*   `input (Tensor)` – the input symmetric matrix\n",
    "*   `eigenvectors (boolean, 可选)` – controls whether eigenvectors have to be computed\n",
    "*   `upper (boolean, 可选)` – controls whether to consider upper-triangular or lower-triangular region\n",
    "*   `out (tuple, 可选)` – The result tuple of (Tensor, Tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "\n",
    "```py\n",
    ">>> a = torch.Tensor([[ 1.96,  0.00,  0.00,  0.00,  0.00],\n",
    "...                   [-6.49,  3.80,  0.00,  0.00,  0.00],\n",
    "...                   [-0.47, -6.39,  4.17,  0.00,  0.00],\n",
    "...                   [-7.20,  1.50, -1.51,  5.70,  0.00],\n",
    "...                   [-0.65, -6.34,  2.67,  1.80, -7.10]]).t()\n",
    "\n",
    ">>> e, v = torch.symeig(a, eigenvectors=True)\n",
    ">>> e\n",
    "\n",
    "-11.0656\n",
    " -6.2287\n",
    " 0.8640\n",
    " 8.8655\n",
    " 16.0948\n",
    "[torch.FloatTensor of size 5]\n",
    "\n",
    ">>> v\n",
    "\n",
    "-0.2981 -0.6075  0.4026 -0.3745  0.4896\n",
    "-0.5078 -0.2880 -0.4066 -0.3572 -0.6053\n",
    "-0.0816 -0.3843 -0.6600  0.5008  0.3991\n",
    "-0.0036 -0.4467  0.4553  0.6204 -0.4564\n",
    "-0.8041  0.4480  0.1725  0.3108  0.1622\n",
    "[torch.FloatTensor of size 5x5]\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "torch.trtrs()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

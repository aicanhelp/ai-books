{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概率分布 - torch.distributions\n",
    "\n",
    "> 译者：[hijkzzz](https://github.com/hijkzzz)\n",
    "\n",
    "`distributions` 包含可参数化的概率分布和采样函数. 这允许构造用于优化的随机计算图和随机梯度估计器.  这个包一般遵循 [TensorFlow Distributions](https://arxiv.org/abs/1711.10604) 包的设计.\n",
    "\n",
    "通常, 不可能直接通过随机样本反向传播.  但是, 有两种主要方法可创建可以反向传播的代理函数.  即得分函数估计器/似然比估计器/REINFORCE和pathwise derivative估计器.  REINFORCE通常被视为强化学习中策略梯度方法的基础, 并且pathwise derivative估计器常见于变分自动编码器中的重新参数化技巧. 得分函数仅需要样本的值 ![](img/cb804637f7fdaaf91569cfe4f047b418.jpg), pathwise derivative 需要导数 ![](img/385dbaaac9dd8aad33acc31ac64d2f27.jpg). 接下来的部分将在一个强化学习示例中讨论这两个问题.  有关详细信息, 请参阅 [Gradient Estimation Using Stochastic Computation Graphs](https://arxiv.org/abs/1506.05254) .\n",
    "\n",
    "## 得分函数\n",
    "\n",
    "当概率密度函数相对于其参数可微分时, 我们只需要`sample()`和`log_prob()`来实现REINFORCE:\n",
    "\n",
    "![](img/b50e881c13615b1d9aa00ad0c9cdfa99.jpg)\n",
    "\n",
    "![](img/51b8359f970d2bfe2ad4cdc3ac1aed3c.jpg) 是参数, ![](img/82005cc2e0087e2a52c7e43df4a19a00.jpg) 是学习速率, ![](img/f9f040e861365a0560b2552b4e4e17da.jpg) 是奖励 并且 ![](img/2e84bb32ea0808870a16b888aeaf8d0d.jpg) 是在状态 ![](img/0492c0bfd615cb5e61c847ece512ff51.jpg) 以及给定策略 ![](img/5f3ddae3395c04f9346a3ac1d327ae2a.jpg)执行动作 ![](img/070b1af5eca3a5c5d72884b536090f17.jpg) 的概率.\n",
    "\n",
    "在实践中, 我们将从网络输出中采样一个动作, 将这个动作应用于一个环境中, 然后使用`log_prob`构造一个等效的损失函数. 请注意, 我们使用负数是因为优化器使用梯度下降, 而上面的规则假设梯度上升. 有了确定的策略, REINFORCE的实现代码如下:\n",
    "\n",
    "```py\n",
    "probs = policy_network(state)\n",
    "# Note that this is equivalent to what used to be called multinomial\n",
    "m = Categorical(probs)\n",
    "action = m.sample()\n",
    "next_state, reward = env.step(action)\n",
    "loss = -m.log_prob(action) * reward\n",
    "loss.backward()\n",
    "\n",
    "```\n",
    "\n",
    "## Pathwise derivative\n",
    "\n",
    "实现这些随机/策略梯度的另一种方法是使用来自`rsample()`方法的重新参数化技巧, 其中参数化随机变量可以通过无参数随机变量的参数确定性函数构造.  因此, 重新参数化的样本变得可微分.  实现Pathwise derivative的代码如下:\n",
    "\n",
    "```py\n",
    "params = policy_network(state)\n",
    "m = Normal(*params)\n",
    "# Any distribution with .has_rsample == True could work based on the application\n",
    "action = m.rsample()\n",
    "next_state, reward = env.step(action)  # Assuming that reward is differentiable\n",
    "loss = -reward\n",
    "loss.backward()\n",
    "\n",
    "```\n",
    "\n",
    "## 分布\n",
    "\n",
    "```py\n",
    "class torch.distributions.distribution.Distribution(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`object`](https://docs.python.org/3/library/functions.html#object \"(in Python v3.7)\")\n",
    "\n",
    "Distribution是概率分布的抽象基类.\n",
    "\n",
    "```py\n",
    "arg_constraints\n",
    "```\n",
    "\n",
    "从参数名称返回字典到 [`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\") 对象（应该满足这个分布的每个参数）.不是张量的arg不需要出现在这个字典中.\n",
    "\n",
    "```py\n",
    "batch_shape\n",
    "```\n",
    "\n",
    "返回批量参数的形状.\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "返回`value`处的累积密度/质量函数估计.\n",
    "\n",
    "| 参数: | **value** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "返回分布的熵, 批量的形状为 batch_shape.\n",
    "\n",
    "| 返回值: | Tensor 形状为 batch_shape. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "返回包含离散分布支持的所有值的张量. 结果将在维度0上枚举, 所以结果的形状将是 `(cardinality,) + batch_shape + event_shape` (对于单变量分布 `event_shape = ()`).\n",
    "\n",
    "注意, 这在lock-step中枚举了所有批处理张量`[[0, 0], [1, 1], …]`. 当 `expand=False`, 枚举沿着维度 0进行, 但是剩下的批处理维度是单维度, `[[0], [1], ..`.\n",
    "\n",
    "遍历整个笛卡尔积的使用 `itertools.product(m.enumerate_support())`.\n",
    "\n",
    "| 参数: | **expand** ([_bool_](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.7)\")) – 是否扩展对批处理dim的支持以匹配分布的 `batch_shape`. |\n",
    "\n",
    "| 返回值: | 张量在维上0迭代. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "event_shape\n",
    "```\n",
    "\n",
    "返回单个样本的形状 (非批量).\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "返回一个新的分布实例(或填充派生类提供的现有实例), 其批处理维度扩展为 `batch_shape`.  这个方法调用 [`expand`](tensors.html#torch.Tensor.expand \"torch.Tensor.expand\") 在分布的参数上. 因此, 这不会为扩展的分布实例分配新的内存.  此外, 第一次创建实例时, 这不会在中重复任何参数检查或参数广播在 `__init__.py`.\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **batch_shape** (_torch.Size_) – 所需的扩展尺寸.\n",
    "*   **_instance** – 由需要重写`.expand`的子类提供的新实例."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 返回值: | 批处理维度扩展为`batch_size`的新分布实例. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    " 返回按`value`计算的反向累积密度/质量函数.\n",
    "\n",
    "| 参数: | **value** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "返回按`value`计算的概率密度/质量函数的对数.\n",
    "\n",
    "| 参数: | **value** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "返回分布的平均值.\n",
    "\n",
    "```py\n",
    "perplexity()\n",
    "```\n",
    "\n",
    "返回分布的困惑度, 批量的关于 batch_shape.\n",
    "\n",
    "| 返回值: | 形状为 batch_shape 的张量. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "如果分布的参数是批量的, 则生成sample_shape形状的重新参数化样本或sample_shape形状的批量重新参数化样本.\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "如果分布的参数是批量的, 则生成sample_shape形状的样本或sample_shape形状的批量样本.\n",
    "\n",
    "```py\n",
    "sample_n(n)\n",
    "```\n",
    "\n",
    "如果分布参数是分批的, 则生成n个样本或n批样本.\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "返回分布的标准差.\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "返回[`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\") 对象表示该分布的支持.\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "返回分布的方差.\n",
    "\n",
    "## ExponentialFamily\n",
    "\n",
    "```py\n",
    "class torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "指数族是指数族概率分布的抽象基类, 其概率质量/密度函数的形式定义如下\n",
    "\n",
    "![](img/0c8313886f5c82dfae90e21b65152815.jpg)\n",
    "\n",
    "![](img/51b8359f970d2bfe2ad4cdc3ac1aed3c.jpg) 表示自然参数, ![](img/e705d3772de12f4df3b0cd75af5110a1.jpg) 表示充分统计量, ![](img/f876c4d8353c747436006e70fb6c4f5d.jpg) 是给定族的对数归一化函数  ![](img/d3b6af2f20ffbc8480c6ee97c42958b2.jpg) 是carrier measure.\n",
    "\n",
    "注意\n",
    "\n",
    "该类是`Distribution`类与指数族分布之间的中介, 主要用于检验`.entropy()`和解析KL散度方法的正确性. 我们使用这个类来计算熵和KL散度使用AD框架和Bregman散度 (出自: Frank Nielsen and Richard Nock, Entropies and Cross-entropies of Exponential Families).\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "利用对数归一化器的Bregman散度计算熵的方法.\n",
    "\n",
    "## Bernoulli\n",
    "\n",
    "```py\n",
    "class torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建参数化的伯努利分布, 根据 [`probs`](#torch.distributions.bernoulli.Bernoulli.probs \"torch.distributions.bernoulli.Bernoulli.probs\") 或者 [`logits`](#torch.distributions.bernoulli.Bernoulli.logits \"torch.distributions.bernoulli.Bernoulli.logits\") (但不是同时都有).\n",
    "\n",
    "样本是二值的 (0 或者 1). 取值 `1` 伴随概率 `p` , 或者 `0` 伴随概率 `1 - p`.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Bernoulli(torch.tensor([0.3]))\n",
    ">>> m.sample()  # 30% chance 1; 70% chance 0\n",
    "tensor([ 0.])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **probs** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – the probabilty of sampling `1`\n",
    "*   **logits** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – the log-odds of sampling `1`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_enumerate_support = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Boolean()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Beta\n",
    "\n",
    "```py\n",
    "class torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "Beta 分布, 参数为 [`concentration1`](#torch.distributions.beta.Beta.concentration1 \"torch.distributions.beta.Beta.concentration1\") 和 [`concentration0`](#torch.distributions.beta.Beta.concentration0 \"torch.distributions.beta.Beta.concentration0\").\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))\n",
    ">>> m.sample()  # Beta distributed with concentration concentration1 and concentration0\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **concentration1** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的第一个浓度参数（通常称为alpha）\n",
    "*   **concentration0** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的第二个浓度参数(通常称为beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'concentration0': GreaterThan(lower_bound=0.0), 'concentration1': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "concentration0\n",
    "```\n",
    "\n",
    "```py\n",
    "concentration1\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=())\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Interval(lower_bound=0.0, upper_bound=1.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Binomial\n",
    "\n",
    "```py\n",
    "class torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建一个Binomial 分布, 参数为 `total_count` 和 [`probs`](#torch.distributions.binomial.Binomial.probs \"torch.distributions.binomial.Binomial.probs\") 或者 [`logits`](#torch.distributions.binomial.Binomial.logits \"torch.distributions.binomial.Binomial.logits\") (但不是同时都有使用). `total_count` 必须和 [`probs`] 之间可广播(#torch.distributions.binomial.Binomial.probs \"torch.distributions.binomial.Binomial.probs\")/[`logits`](#torch.distributions.binomial.Binomial.logits \"torch.distributions.binomial.Binomial.logits\").\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Binomial(100, torch.tensor([0 , .2, .8, 1]))\n",
    ">>> x = m.sample()\n",
    "tensor([   0.,   22.,   71.,  100.])\n",
    "\n",
    ">>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8]))\n",
    ">>> x = m.sample()\n",
    "tensor([[ 4.,  5.],\n",
    " [ 7.,  6.]])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **total_count** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 伯努利试验次数\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件概率\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件 log-odds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0), 'total_count': IntegerGreaterThan(lower_bound=0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_enumerate_support = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Categorical\n",
    "\n",
    "```py\n",
    "class torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建一个 categorical 分布, 参数为 [`probs`](#torch.distributions.categorical.Categorical.probs \"torch.distributions.categorical.Categorical.probs\") 或者 [`logits`](#torch.distributions.categorical.Categorical.logits \"torch.distributions.categorical.Categorical.logits\") (但不是同时都有).\n",
    "\n",
    "注意\n",
    "\n",
    "它等价于从 [`torch.multinomial()`](torch.html#torch.multinomial \"torch.multinomial\") 的采样.\n",
    "\n",
    "样本是整数来自![](img/7c6904e60a8ff7044a079e10eaee1f57.jpg) `K` 是 `probs.size(-1)`.\n",
    "\n",
    "如果 [`probs`](#torch.distributions.categorical.Categorical.probs \"torch.distributions.categorical.Categorical.probs\") 是 1D 的, 长度为`K`, 每个元素是在该索引处对类进行抽样的相对概率.\n",
    "\n",
    "如果 [`probs`](#torch.distributions.categorical.Categorical.probs \"torch.distributions.categorical.Categorical.probs\") 是 2D 的, 它被视为一组相对概率向量.\n",
    "\n",
    "注意\n",
    "\n",
    "[`probs`](#torch.distributions.categorical.Categorical.probs \"torch.distributions.categorical.Categorical.probs\")  必须是非负的、有限的并且具有非零和, 并且它将被归一化为和为1.\n",
    "\n",
    "请参阅: [`torch.multinomial()`](torch.html#torch.multinomial \"torch.multinomial\")\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    ">>> m.sample()  # equal probability of 0, 1, 2, 3\n",
    "tensor(3)\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – event probabilities\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – event log probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Simplex()}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_enumerate_support = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Cauchy\n",
    "\n",
    "```py\n",
    "class torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "样本来自柯西(洛伦兹)分布. 均值为0的独立正态分布随机变量之比服从柯西分布. \n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # sample from a Cauchy distribution with loc=0 and scale=1\n",
    "tensor([ 2.3214])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的模态或中值.\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – half width at half maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Chi2\n",
    "\n",
    "```py\n",
    "class torch.distributions.chi2.Chi2(df, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.gamma.Gamma`](#torch.distributions.gamma.Gamma \"torch.distributions.gamma.Gamma\")\n",
    "\n",
    " 创建由形状参数[`df`](#torch.distributions.chi2.Chi2.df \"torch.distributions.chi2.Chi2.df\")参数化的Chi2分布.  这完全等同于 `Gamma(alpha=0.5*df, beta=0.5)`\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Chi2(torch.tensor([1.0]))\n",
    ">>> m.sample()  # Chi2 distributed with shape df=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **df** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的形状参数 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'df': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "df\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "## Dirichlet\n",
    "\n",
    "```py\n",
    "class torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建一个 Dirichlet 分布, 参数为`concentration`.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Dirichlet(torch.tensor([0.5, 0.5]))\n",
    ">>> m.sample()  # Dirichlet distributed with concentrarion concentration\n",
    "tensor([ 0.1046,  0.8954])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **concentration** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  分布的浓度参数（通常称为alpha） |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'concentration': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=())\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Simplex()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Exponential\n",
    "\n",
    "```py\n",
    "class torch.distributions.exponential.Exponential(rate, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建由`rate`参数化的指数分布.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Exponential(torch.tensor([1.0]))\n",
    ">>> m.sample()  # Exponential distributed with rate=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **rate** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – rate = 1 / 分布的scale  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## FisherSnedecor\n",
    "\n",
    "```py\n",
    "class torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建由`df1`和`df2`参数化的Fisher-Snedecor分布\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))\n",
    ">>> m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2\n",
    "tensor([ 0.2453])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **df1** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  自由度参数1\n",
    "*   **df2** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 自由度参数2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'df1': GreaterThan(lower_bound=0.0), 'df2': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Gamma\n",
    "\n",
    "```py\n",
    "class torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建由`concentration`和`rate`参数化的伽马分布. .\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # Gamma distributed with concentration=1 and rate=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **concentration** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的形状参数（通常称为alpha）\n",
    "*   **rate** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – rate = 1 /  分布scale (通常称为beta )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'rate': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Geometric\n",
    "\n",
    "```py\n",
    "class torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建由`probs`参数化的几何分布, 其中`probs`是伯努利试验成功的概率. 它表示概率在 ![](img/10396db36bab7b7242cfe94f04374444.jpg) 次伯努利试验中,  前 ![](img/a1c2f8d5b1226e67bdb44b12a6ddf18b.jpg) 试验失败, 然后成功.\n",
    "\n",
    "样本是非负整数 [0, ![](img/06485c2c6e992cf346fdfe033a86a10d.jpg)).\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Geometric(torch.tensor([0.3]))\n",
    ">>> m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0\n",
    "tensor([ 2.])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **probs** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  抽样`1`的概率 . 必须是在范围 (0, 1]\n",
    "*   **logits** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 抽样 `1`的log-odds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = IntegerGreaterThan(lower_bound=0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Gumbel\n",
    "\n",
    "```py\n",
    "class torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "来自Gumbel分布的样本.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```py\n",
    ">>> m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0]))\n",
    ">>> m.sample()  # sample from Gumbel distribution with loc=1, scale=2\n",
    "tensor([ 1.0124])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  分布的位置参数\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  分布的scale 参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## HalfCauchy\n",
    "\n",
    "```py\n",
    "class torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "创建`scale`参数化的半正态分布:\n",
    "\n",
    "```py\n",
    "X ~ Cauchy(0, scale)\n",
    "Y = |X| ~ HalfCauchy(scale)\n",
    "\n",
    "```\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = HalfCauchy(torch.tensor([1.0]))\n",
    ">>> m.sample()  # half-cauchy distributed with scale=1\n",
    "tensor([ 2.3214])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 完全柯西分布的scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(prob)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "scale\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## HalfNormal\n",
    "\n",
    "```py\n",
    "class torch.distributions.half_normal.HalfNormal(scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "创建按`scale`参数化的半正态分布:\n",
    "\n",
    "```py\n",
    "X ~ Normal(0, scale)\n",
    "Y = |X| ~ HalfNormal(scale)\n",
    "\n",
    "```\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = HalfNormal(torch.tensor([1.0]))\n",
    ">>> m.sample()  # half-normal distributed with scale=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 完全正态分布的scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(prob)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "scale\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Independent\n",
    "\n",
    "```py\n",
    "class torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "重新解释一些分布的批量 dims 作为 event dims.\n",
    "\n",
    " 这主要用于改变[`log_prob()`](#torch.distributions.independent.Independent.log_prob \"torch.distributions.independent.Independent.log_prob\")结果的形状.例如, 要创建与多元正态分布形状相同的对角正态分布(因此它们是可互换的), 您可以这样做:\n",
    "\n",
    "```py\n",
    ">>> loc = torch.zeros(3)\n",
    ">>> scale = torch.ones(3)\n",
    ">>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    ">>> [mvn.batch_shape, mvn.event_shape]\n",
    "[torch.Size(()), torch.Size((3,))]\n",
    ">>> normal = Normal(loc, scale)\n",
    ">>> [normal.batch_shape, normal.event_shape]\n",
    "[torch.Size((3,)), torch.Size(())]\n",
    ">>> diagn = Independent(normal, 1)\n",
    ">>> [diagn.batch_shape, diagn.event_shape]\n",
    "[torch.Size(()), torch.Size((3,))]\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **base_distribution** ([_torch.distributions.distribution.Distribution_](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")) – 基础分布\n",
    "*   **reinterpreted_batch_ndims** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\")) –要重解释的批量dims的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_enumerate_support\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Laplace\n",
    "\n",
    "```py\n",
    "class torch.distributions.laplace.Laplace(loc, scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建参数化的拉普拉斯分布, 参数是 `loc` 和 :attr:’scale’.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # Laplace distributed with loc=0, scale=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布均值\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## LogNormal\n",
    "\n",
    "```py\n",
    "class torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    " 创建参数化的对数正态分布, 参数为 [`loc`](#torch.distributions.log_normal.LogNormal.loc \"torch.distributions.log_normal.LogNormal.loc\") 和 [`scale`](#torch.distributions.log_normal.LogNormal.scale \"torch.distributions.log_normal.LogNormal.scale\"):\n",
    "\n",
    "```py\n",
    "X ~ Normal(loc, scale)\n",
    "Y = exp(X) ~ LogNormal(loc, scale)\n",
    "\n",
    "```\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # log-normal distributed with mean=0 and stddev=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  分布对数平均值\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  分布对数的标准差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "loc\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "scale\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## LowRankMultivariateNormal\n",
    "\n",
    "```py\n",
    "class torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "使用由`cov_factor`和`cov_diag`参数化的低秩形式的协方差矩阵创建多元正态分布:\n",
    "\n",
    "```py\n",
    "covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
    "\n",
    "```\n",
    "\n",
    "Example\n",
    "\n",
    "```py\n",
    ">>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1]))\n",
    ">>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]`\n",
    "tensor([-0.2102, -0.5429])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的均值, 形状为 `batch_shape + event_shape`\n",
    "*   **cov_factor** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 协方差矩阵低秩形式的因子部分, 形状为 `batch_shape + event_shape + (rank,)`\n",
    "*   **cov_diag** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 协方差矩阵的低秩形式的对角部分, 形状为 `batch_shape + event_shape`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意\n",
    "\n",
    "避免了协方差矩阵的行列式和逆的计算, 当 `cov_factor.shape[1] << cov_factor.shape[0]` 由于 [Woodbury matrix identity](https://en.wikipedia.org/wiki/Woodbury_matrix_identity) 和 [matrix determinant lemma](https://en.wikipedia.org/wiki/Matrix_determinant_lemma).  由于这些公式, 我们只需要计算小尺寸“capacitance”矩阵的行列式和逆:\n",
    "\n",
    "```py\n",
    "capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
    "\n",
    "```\n",
    "\n",
    "```py\n",
    "arg_constraints = {'cov_diag': GreaterThan(lower_bound=0.0), 'cov_factor': Real(), 'loc': Real()}\n",
    "```\n",
    "\n",
    "```py\n",
    "covariance_matrix\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "precision_matrix\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "scale_tril\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Multinomial\n",
    "\n",
    "```py\n",
    "class torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建由`total_count`和`probs`或`logits`（但不是两者）参数化的多项式分布.  `probs`的最内层维度是对类别的索引.  所有其他维度索引批次. \n",
    "\n",
    "注意 `total_count` 不需要指定, 当只有 [`log_prob()`](#torch.distributions.multinomial.Multinomial.log_prob \"torch.distributions.multinomial.Multinomial.log_prob\") 被调用\n",
    "\n",
    "注意\n",
    "\n",
    "[`probs`](#torch.distributions.multinomial.Multinomial.probs \"torch.distributions.multinomial.Multinomial.probs\") 必须是非负的、有限的并且具有非零和, 并且它将被归一化为和为1.\n",
    "\n",
    "*   [`sample()`](#torch.distributions.multinomial.Multinomial.sample \"torch.distributions.multinomial.Multinomial.sample\") 所有参数和样本都需要一个共享的`total_count`.\n",
    "*   [`log_prob()`](#torch.distributions.multinomial.Multinomial.log_prob \"torch.distributions.multinomial.Multinomial.log_prob\")  允许每个参数和样本使用不同的`total_count`.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n",
    ">>> x = m.sample()  # equal probability of 0, 1, 2, 3\n",
    "tensor([ 21.,  24.,  30.,  25.])\n",
    "\n",
    ">>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n",
    "tensor([-4.1338])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **total_count** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\")) – 试验次数\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件概率\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件对数概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Simplex()}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## MultivariateNormal\n",
    "\n",
    "```py\n",
    "class torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建由均值向量和协方差矩阵参数化的多元正态(也称为高斯)分布.\n",
    "\n",
    "多元正态分布可以用正定协方差矩阵![](img/ea86c11eaef9af2b4d699b88c2474ffd.jpg)来参数化或者一个正定的精度矩阵 ![](img/1949bfcc1decf198a2ff50b6e25f4cf6.jpg)  或者是一个正对角项的下三角矩阵 ![](img/f4996f1b5056dd364eab16f975b808ff.jpg), 例如 ![](img/6749b6afc75abfc8e0652ac8e5c0b8d8.jpg). 这个三角矩阵可以通过协方差的Cholesky分解得到.\n",
    "\n",
    "例子\n",
    "\n",
    "```py\n",
    ">>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    ">>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`\n",
    "tensor([-0.2102, -0.5429])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的均值\n",
    "*   **covariance_matrix** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 正定协方差矩阵\n",
    "*   **precision_matrix** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 正定精度矩阵\n",
    "*   **scale_tril** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 具有正值对角线的下三角协方差因子\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意\n",
    "\n",
    "仅仅一个 [`covariance_matrix`](#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix \"torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix\") 或者 [`precision_matrix`](#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix \"torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix\") 或者 [`scale_tril`](#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril \"torch.distributions.multivariate_normal.MultivariateNormal.scale_tril\") 可被指定.\n",
    "\n",
    "使用 [`scale_tril`](#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril \"torch.distributions.multivariate_normal.MultivariateNormal.scale_tril\")  会更有效率: 内部的所有计算都基于 [`scale_tril`](#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril \"torch.distributions.multivariate_normal.MultivariateNormal.scale_tril\"). 如果 [`covariance_matrix`](#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix \"torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix\") 或者 [`precision_matrix`](#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix \"torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix\") 已经被传入, 它仅用于使用Cholesky分解计算相应的下三角矩阵.\n",
    "\n",
    "```py\n",
    "arg_constraints = {'covariance_matrix': PositiveDefinite(), 'loc': RealVector(), 'precision_matrix': PositiveDefinite(), 'scale_tril': LowerCholesky()}\n",
    "```\n",
    "\n",
    "```py\n",
    "covariance_matrix\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "precision_matrix\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "scale_tril\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## NegativeBinomial\n",
    "\n",
    "```py\n",
    "class torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建一个负二项分布, 即在达到`total_count`失败之前所需的独立相同伯努利试验的数量的分布. 每次伯努利试验成功的概率都是`probs`. \n",
    "\n",
    "参数: \n",
    "\n",
    "*   **total_count** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  非负数伯努利试验停止的次数, 虽然分布仍然对实数有效\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件概率, 区间为 [0, 1)\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件对数几率 - 成功概率的几率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': HalfOpenInterval(lower_bound=0.0, upper_bound=1.0), 'total_count': GreaterThanEq(lower_bound=0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = IntegerGreaterThan(lower_bound=0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Normal\n",
    "\n",
    "```py\n",
    "class torch.distributions.normal.Normal(loc, scale, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建由`loc`和`scale`参数化的正态（也称为高斯）分布\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # normally distributed with loc=0 and scale=1\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 均值 (也被称为 mu)\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 标准差(也被称为) sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## OneHotCategorical\n",
    "\n",
    "```py\n",
    "class torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "创建一个由`probs`或l`ogits`参数化的One Hot Categorical 分布\n",
    "\n",
    "样本是大小为 `probs.size(-1)`热编码向量.\n",
    "\n",
    "注意\n",
    "\n",
    "`probs`必须是非负的, 有限的并且具有非零和, 并且它将被归一化为总和为1. \n",
    "\n",
    "请参见: `torch.distributions.Categorical()` 对于指定 [`probs`](#torch.distributions.one_hot_categorical.OneHotCategorical.probs \"torch.distributions.one_hot_categorical.OneHotCategorical.probs\") 和 [`logits`](#torch.distributions.one_hot_categorical.OneHotCategorical.logits \"torch.distributions.one_hot_categorical.OneHotCategorical.logits\").\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    ">>> m.sample()  # equal probability of 0, 1, 2, 3\n",
    "tensor([ 0.,  0.,  0.,  1.])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – event probabilities\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – event log probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Simplex()}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "enumerate_support(expand=True)\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_enumerate_support = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "param_shape\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Simplex()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Pareto\n",
    "\n",
    "```py\n",
    "class torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "来自Pareto Type 1分布的样本.\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1\n",
    "tensor([ 1.5623])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的Scale\n",
    "*   **alpha** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的Shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'alpha': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Poisson\n",
    "\n",
    "```py\n",
    "class torch.distributions.poisson.Poisson(rate, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.exp_family.ExponentialFamily`](#torch.distributions.exp_family.ExponentialFamily \"torch.distributions.exp_family.ExponentialFamily\")\n",
    "\n",
    "创建按`rate`参数化的泊松分布\n",
    "\n",
    "样本是非负整数, pmf是\n",
    "\n",
    "![](img/32c47de57300c954795486fea3201bdc.jpg)\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Poisson(torch.tensor([4]))\n",
    ">>> m.sample()\n",
    "tensor([ 3.])\n",
    "\n",
    "```\n",
    "\n",
    "| 参数: | **rate** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – rate 参数 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = IntegerGreaterThan(lower_bound=0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## RelaxedBernoulli\n",
    "\n",
    "```py\n",
    "class torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "创建一个RelaxedBernoulli分布, 通过[`temperature`](#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature \"torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature\")参数化, 以及`probs`或`logits`（但不是两者）.  这是伯努利分布的松弛版本, 因此值在（0,1）中, 并且具有可重参数化的样本. \n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = RelaxedBernoulli(torch.tensor([2.2]),\n",
    " torch.tensor([0.1, 0.2, 0.3, 0.99]))\n",
    ">>> m.sample()\n",
    "tensor([ 0.2951,  0.3442,  0.8918,  0.9021])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **temperature** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 松弛 temperature\n",
    "*   **probs** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –采样 `1` 的概率\n",
    "*   **logits** (_Number__,_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 采样 `1` 的对数概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Interval(lower_bound=0.0, upper_bound=1.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "temperature\n",
    "```\n",
    "\n",
    "## RelaxedOneHotCategorical\n",
    "\n",
    "```py\n",
    "class torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "创建一个由温度参数化的`RelaxedOneHotCategorical`分布, 以及`probs`或`logits`.  这是`OneHotCategorical`分布的松弛版本, 因此它的样本是单一的, 并且可以重参数化. \n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = RelaxedOneHotCategorical(torch.tensor([2.2]),\n",
    " torch.tensor([0.1, 0.2, 0.3, 0.4]))\n",
    ">>> m.sample()\n",
    "tensor([ 0.1294,  0.2324,  0.3859,  0.2523])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **temperature** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 松弛 temperature\n",
    "*   **probs** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 事件概率\n",
    "*   **logits** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –对数事件概率.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'logits': Real(), 'probs': Simplex()}\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "logits\n",
    "```\n",
    "\n",
    "```py\n",
    "probs\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Simplex()\n",
    "```\n",
    "\n",
    "```py\n",
    "temperature\n",
    "```\n",
    "\n",
    "## StudentT\n",
    "\n",
    "```py\n",
    "class torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "根据自由度`df`, 平均`loc`和`scale`创建学生t分布. \n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = StudentT(torch.tensor([2.0]))\n",
    ">>> m.sample()  # Student's t-distributed with degrees of freedom=2\n",
    "tensor([ 0.1046])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **df** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 自由度\n",
    "*   **loc** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 均值\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 分布的scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'df': GreaterThan(lower_bound=0.0), 'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "support = Real()\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## TransformedDistribution\n",
    "\n",
    "```py\n",
    "class torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")\n",
    "\n",
    "Distribution类的扩展, 它将一系列变换应用于基本分布. 假设f是所应用变换的组成:\n",
    "\n",
    "```py\n",
    "X ~ BaseDistribution\n",
    "Y = f(X) ~ TransformedDistribution(BaseDistribution, f)\n",
    "log p(Y) = log p(X) + log |det (dX/dY)|\n",
    "\n",
    "```\n",
    "\n",
    "注意 `.event_shape` of a [`TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\") 是其基本分布及其变换的最大形状, 因为变换可以引入事件之间的相关性.\n",
    "\n",
    "一个使用例子 [`TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\"):\n",
    "\n",
    "```py\n",
    "# Building a Logistic Distribution\n",
    "# X ~ Uniform(0, 1)\n",
    "# f = a + b * logit(X)\n",
    "# Y ~ f(X) ~ Logistic(a, b)\n",
    "base_distribution = Uniform(0, 1)\n",
    "transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)]\n",
    "logistic = TransformedDistribution(base_distribution, transforms)\n",
    "\n",
    "```\n",
    "\n",
    "有关更多示例, 请查看有关实现 [`Gumbel`](#torch.distributions.gumbel.Gumbel \"torch.distributions.gumbel.Gumbel\"), [`HalfCauchy`](#torch.distributions.half_cauchy.HalfCauchy \"torch.distributions.half_cauchy.HalfCauchy\"), [`HalfNormal`](#torch.distributions.half_normal.HalfNormal \"torch.distributions.half_normal.HalfNormal\"), [`LogNormal`](#torch.distributions.log_normal.LogNormal \"torch.distributions.log_normal.LogNormal\"), [`Pareto`](#torch.distributions.pareto.Pareto \"torch.distributions.pareto.Pareto\"), [`Weibull`](#torch.distributions.weibull.Weibull \"torch.distributions.weibull.Weibull\"), [`RelaxedBernoulli`](#torch.distributions.relaxed_bernoulli.RelaxedBernoulli \"torch.distributions.relaxed_bernoulli.RelaxedBernoulli\") 和 [`RelaxedOneHotCategorical`](#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical \"torch.distributions.relaxed_categorical.RelaxedOneHotCategorical\")\n",
    "\n",
    "```py\n",
    "arg_constraints = {}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "通过逆变换和计算基分布的分数来计算累积分布函数.\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "使用transform(s)计算逆累积分布函数, 并计算基分布的分数.\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "通过反转变换并使用基本分布的分数和日志abs det jacobian计算分数来对样本进行评分\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "如果分布参数是批处理的, 则生成sample_shape形状的重新参数化样本或sample_shape形状的重新参数化样本批次.  首先从基本分布中采样, 并对列表中的每个变换应用`transform()`\n",
    "\n",
    "```py\n",
    "sample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "如果分布参数是批处理的, 则生成sample_shape形样本或sample_shape形样本批处理.  首先从基本分布中采样, 并对列表中的每个变换应用`transform()`. \n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "## Uniform\n",
    "\n",
    "```py\n",
    "class torch.distributions.uniform.Uniform(low, high, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.distribution.Distribution`](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从半开区间`[low, high)`生成均匀分布的随机样本\n",
    "\n",
    "例子:\n",
    "\n",
    "```py\n",
    ">>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))\n",
    ">>> m.sample()  # uniformly distributed in the range [0.0, 5.0)\n",
    "tensor([ 2.3418])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **low** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) –  下限（含）.\n",
    "*   **high** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 上限(排除)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'high': Dependent(), 'low': Dependent()}\n",
    "```\n",
    "\n",
    "```py\n",
    "cdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "has_rsample = True\n",
    "```\n",
    "\n",
    "```py\n",
    "icdf(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "log_prob(value)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "rsample(sample_shape=torch.Size([]))\n",
    "```\n",
    "\n",
    "```py\n",
    "stddev\n",
    "```\n",
    "\n",
    "```py\n",
    "support\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## Weibull\n",
    "\n",
    "```py\n",
    "class torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)\n",
    "```\n",
    "\n",
    "基类: [`torch.distributions.transformed_distribution.TransformedDistribution`](#torch.distributions.transformed_distribution.TransformedDistribution \"torch.distributions.transformed_distribution.TransformedDistribution\")\n",
    "\n",
    "来自双参数Weibull分布的样本.\n",
    "\n",
    "Example\n",
    "\n",
    "```py\n",
    ">>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n",
    ">>> m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\n",
    "tensor([ 0.4784])\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **scale** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – Scale (lambda).\n",
    "*   **concentration** ([_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – Concentration (k/shape).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "arg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}\n",
    "```\n",
    "\n",
    "```py\n",
    "entropy()\n",
    "```\n",
    "\n",
    "```py\n",
    "expand(batch_shape, _instance=None)\n",
    "```\n",
    "\n",
    "```py\n",
    "mean\n",
    "```\n",
    "\n",
    "```py\n",
    "support = GreaterThan(lower_bound=0.0)\n",
    "```\n",
    "\n",
    "```py\n",
    "variance\n",
    "```\n",
    "\n",
    "## `KL Divergence`\n",
    "\n",
    "```py\n",
    "torch.distributions.kl.kl_divergence(p, q)\n",
    "```\n",
    "\n",
    "计算Kullback-Leibler散度 ![](img/739a8e4cd0597805c3e4daf35c0fc7c6.jpg) 对于两个分布.\n",
    "\n",
    "![](img/ff8dcec3abe559720f8b0b464d2471b2.jpg)\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **p** ([_Distribution_](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")) – `Distribution` 对象.\n",
    "*   **q** ([_Distribution_](#torch.distributions.distribution.Distribution \"torch.distributions.distribution.Distribution\")) – `Distribution` 对象."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 返回值: | 批量的 KL 散度, 形状为 `batch_shape`. |\n",
    "\n",
    "| 返回类型： | [Tensor](tensors.html#torch.Tensor \"torch.Tensor\") |\n",
    "\n",
    "| 异常: | [`NotImplementedError`](https://docs.python.org/3/library/exceptions.html#NotImplementedError \"(in Python v3.7)\") – 如果分布类型尚未通过注册 [`register_kl()`](#torch.distributions.kl.register_kl \"torch.distributions.kl.register_kl\"). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "torch.distributions.kl.register_kl(type_p, type_q)\n",
    "```\n",
    "\n",
    "装饰器注册[`kl_divergence()`](#torch.distributions.kl.kl_divergence \"torch.distributions.kl.kl_divergence\")的成对函数\n",
    "\n",
    "```py\n",
    "@register_kl(Normal, Normal)\n",
    "def kl_normal_normal(p, q):\n",
    "    # insert implementation here\n",
    "\n",
    "```\n",
    "\n",
    "Lookup返回由子类排序的最具体(type,type)匹配.  如果匹配不明确, 则会引发`RuntimeWarning`.  例如, 解决模棱两可的情况\n",
    "\n",
    "```py\n",
    "@register_kl(BaseP, DerivedQ)\n",
    "def kl_version1(p, q): ...\n",
    "@register_kl(DerivedP, BaseQ)\n",
    "def kl_version2(p, q): ...\n",
    "\n",
    "```\n",
    "\n",
    "你应该注册第三个最具体的实现, 例如:\n",
    "\n",
    "```py\n",
    "register_kl(DerivedP, DerivedQ)(kl_version1)  # Break the tie.\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **type_p** ([_type_](https://docs.python.org/3/library/functions.html#type \"(in Python v3.7)\")) – 子类 `Distribution`.\n",
    "*   **type_q** ([_type_](https://docs.python.org/3/library/functions.html#type \"(in Python v3.7)\")) – 子类 `Distribution`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Transforms`\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.Transform(cache_size=0)\n",
    "```\n",
    "\n",
    "有可计算的log det jacobians进行可逆变换的抽象类.  它们主要用于 `torch.distributions.TransformedDistribution`.\n",
    "\n",
    "缓存对于其反转昂贵或数值不稳定的变换很有用.  请注意, 必须注意记忆值, 因为可以颠倒自动记录图.  例如, 以下操作有或没有缓存:\n",
    "\n",
    "```py\n",
    "y = t(x)\n",
    "t.log_abs_det_jacobian(x, y).backward()  # x will receive gradients.\n",
    "\n",
    "```\n",
    "\n",
    "但是, 由于依赖性反转, 缓存时会出现以下错误:\n",
    "\n",
    "```py\n",
    "y = t(x)\n",
    "z = t.inv(y)\n",
    "grad(z.sum(), [y])  # error because z is x\n",
    "\n",
    "```\n",
    "\n",
    " 派生类应该实现`_call()`或`_inverse()`中的一个或两个.  设置`bijective=True`的派生类也应该实现`log_abs_det_jacobian()`\n",
    "\n",
    "| 参数: | **cache_size** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\")) – 缓存大小.  如果为零, 则不进行缓存.  如果是, 则缓存最新的单个值.  仅支持0和1 |\n",
    "\n",
    "| Variables: | \n",
    "\n",
    "*   **domain** ([`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\")) –  表示该变换有效输入的约束.\n",
    "*   **codomain** ([`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\")) – 表示此转换的有效输出的约束, 这些输出是逆变换的输入.\n",
    "*   **bijective** ([_bool_](https://docs.python.org/3/library/functions.html#bool \"(in Python v3.7)\")) –  这个变换是否是双射的. 变换 `t` 是双射的 如果 `t.inv(t(x)) == x` 并且 `t(t.inv(y)) == y` 对于每一个 `x` 和 `y`. 不是双射的变形应该至少保持较弱的伪逆属性 `t(t.inv(t(x)) == t(x)` and `t.inv(t(t.inv(y))) == t.inv(y)`.\n",
    "*   **sign** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\") _or_ [_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\")) – 对于双射单变量变换, 它应该是+1或-1, 这取决于变换是单调递增还是递减.\n",
    "*   **event_dim** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\")) – 变换event_shape中相关的维数.  这对于逐点变换应该是0, 对于在矢量上共同作用的变换是1, 对于在矩阵上共同作用的变换是2, 等等."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "inv\n",
    "```\n",
    "\n",
    "返回逆[`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\"). 满足 `t.inv.inv is t`.\n",
    "\n",
    "```py\n",
    "sign\n",
    "```\n",
    "\n",
    "如果适用, 返回雅可比行列式的符号.  一般来说, 这只适用于双射变换.\n",
    "\n",
    "```py\n",
    "log_abs_det_jacobian(x, y)\n",
    "```\n",
    "\n",
    "计算 log det jacobian `log |dy/dx|` 给定输入和输出.\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.ComposeTransform(parts)\n",
    "```\n",
    "\n",
    "在一个链中组合多个转换. 正在组合的转换负责缓存.\n",
    "\n",
    "| 参数: | **parts** (list of [`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\")) – 列表 transforms. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "class torch.distributions.transforms.ExpTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "转换通过映射 ![](img/ec8d939394f24908d017d86153e312ea.jpg).\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.PowerTransform(exponent, cache_size=0)\n",
    "```\n",
    "\n",
    "转换通过映射 ![](img/2062af7179e0c19c3599816de6768cee.jpg).\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.SigmoidTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "转换通过映射 ![](img/749abef3418941161a1c6ff80d9eae76.jpg) and ![](img/6feb73eb74f2267e5caa87d9693362cb.jpg).\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.AbsTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "转换通过映射 ![](img/dca0dc2e17c81b7ec261e70549de5507.jpg).\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)\n",
    "```\n",
    "\n",
    "通过逐点仿射映射![](img/e1df459e7ff26d682fc956b62868f7c4.jpg)进行转换 .\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **loc** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\") _or_ [_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\")) – Location.\n",
    "*   **scale** ([_Tensor_](tensors.html#torch.Tensor \"torch.Tensor\") _or_ [_float_](https://docs.python.org/3/library/functions.html#float \"(in Python v3.7)\")) – Scale.\n",
    "*   **event_dim** ([_int_](https://docs.python.org/3/library/functions.html#int \"(in Python v3.7)\")) – 可选的 `event_shape` 大小. T对于单变量随机变量, 该值应为零, 对于矢量分布, 1应为零, 对于矩阵的分布, 应为2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "class torch.distributions.transforms.SoftmaxTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "从无约束空间到单纯形的转换, 通过 ![](img/ec8d939394f24908d017d86153e312ea.jpg) 然后归一化.\n",
    "\n",
    "这不是双射的, 不能用于HMC.  然而, 这主要是协调的（除了最终的归一化）, 因此适合于坐标方式的优化算法. \n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.StickBreakingTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "将无约束空间通过 stick-breaking 过程转化为一个额外维度的单纯形. \n",
    "\n",
    "这种变换是`Dirichlet`分布的破棒构造中的迭代sigmoid变换:第一个逻辑通过sigmoid变换成第一个概率和所有其他概率, 然后这个过程重复出现. \n",
    "\n",
    "这是双射的, 适合在HMC中使用; 然而, 它将坐标混合在一起, 不太适合优化.\n",
    "\n",
    "```py\n",
    "class torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)\n",
    "```\n",
    "\n",
    "将无约束矩阵转换为具有非负对角项的下三角矩阵.\n",
    "\n",
    "这对于根据Cholesky分解来参数化正定矩阵是有用的.\n",
    "\n",
    "## `Constraints`\n",
    "\n",
    "The following constraints are implemented:\n",
    "\n",
    "*   `constraints.boolean`\n",
    "*   `constraints.dependent`\n",
    "*   `constraints.greater_than(lower_bound)`\n",
    "*   `constraints.integer_interval(lower_bound, upper_bound)`\n",
    "*   `constraints.interval(lower_bound, upper_bound)`\n",
    "*   `constraints.lower_cholesky`\n",
    "*   `constraints.lower_triangular`\n",
    "*   `constraints.nonnegative_integer`\n",
    "*   `constraints.positive`\n",
    "*   `constraints.positive_definite`\n",
    "*   `constraints.positive_integer`\n",
    "*   `constraints.real`\n",
    "*   `constraints.real_vector`\n",
    "*   `constraints.simplex`\n",
    "*   `constraints.unit_interval`\n",
    "\n",
    "```py\n",
    "class torch.distributions.constraints.Constraint\n",
    "```\n",
    "\n",
    "constraints 的抽象基类.\n",
    "\n",
    "constraint对象表示变量有效的区域, 例如,  其中可以优化变量\n",
    "\n",
    "```py\n",
    "check(value)\n",
    "```\n",
    "\n",
    "返回一个字节张量 `sample_shape + batch_shape` 指示值中的每个事件是否满足此约束.\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.dependent_property\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._DependentProperty`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.integer_interval\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._IntegerInterval`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.greater_than\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._GreaterThan`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.greater_than_eq\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._GreaterThanEq`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.less_than\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._LessThan`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.interval\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._Interval`\n",
    "\n",
    "```py\n",
    "torch.distributions.constraints.half_open_interval\n",
    "```\n",
    "\n",
    "alias of `torch.distributions.constraints._HalfOpenInterval`\n",
    "\n",
    "## `Constraint Registry`\n",
    "\n",
    "PyTorch 提供两个全局 [`ConstraintRegistry`](#torch.distributions.constraint_registry.ConstraintRegistry \"torch.distributions.constraint_registry.ConstraintRegistry\") 对象 , 链接 [`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\") 对象到 [`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\") 对象. 这些对象既有输入约束, 也有返回变换, 但是它们对双射性有不同的保证.\n",
    "\n",
    "1.  `biject_to(constraint)`  查找一个双射的 [`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\") 从 `constraints.real` 到给定的 `constraint`.  返回的转换保证具有 `.bijective = True` 并且应该实现了 `.log_abs_det_jacobian()`.\n",
    "2.  `transform_to(constraint)` 查找一个不一定是双射的 [`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\") 从 `constraints.real` 到给定的 `constraint`. 返回的转换不保证实现 `.log_abs_det_jacobian()`.\n",
    "\n",
    "`transform_to()`注册表对于对概率分布的约束参数执行无约束优化非常有用, 这些参数由每个分布的`.arg_constraints`指示.  这些变换通常会过度参数化空间以避免旋转; 因此, 它们更适合像Adam那样的坐标优化算法\n",
    "\n",
    "```py\n",
    "loc = torch.zeros(100, requires_grad=True)\n",
    "unconstrained = torch.zeros(100, requires_grad=True)\n",
    "scale = transform_to(Normal.arg_constraints['scale'])(unconstrained)\n",
    "loss = -Normal(loc, scale).log_prob(data).sum()\n",
    "\n",
    "```\n",
    "\n",
    "`biject_to()` 注册表对于Hamiltonian Monte Carlo非常有用, 其中来自具有约束. `.support`的概率分布的样本在无约束空间中传播, 并且算法通常是旋转不变的\n",
    "\n",
    "```py\n",
    "dist = Exponential(rate)\n",
    "unconstrained = torch.zeros(100, requires_grad=True)\n",
    "sample = biject_to(dist.support)(unconstrained)\n",
    "potential_energy = -dist.log_prob(sample).sum()\n",
    "\n",
    "```\n",
    "\n",
    "注意\n",
    "\n",
    "一个 `transform_to` 和 `biject_to` 不同的例子是 `constraints.simplex`: `transform_to(constraints.simplex)` 返回一个 [`SoftmaxTransform`](#torch.distributions.transforms.SoftmaxTransform \"torch.distributions.transforms.SoftmaxTransform\") 简单地对其输入进行指数化和归一化;  这是一种廉价且主要是坐标的操作, 适用于像SVI这样的算法. 相反, `biject_to(constraints.simplex)` 返回一个 [`StickBreakingTransform`](#torch.distributions.transforms.StickBreakingTransform \"torch.distributions.transforms.StickBreakingTransform\") 将其输入生成一个较小维度的空间; 这是一种更昂贵的数值更少的数值稳定的变换, 但对于像HM​​C这样的算法是必需的. \n",
    "\n",
    "`biject_to` 和 `transform_to` 对象可以通过用户定义的约束进行扩展, 并使用`.register()`方法进行转换, 作为单例约束的函数\n",
    "\n",
    "```py\n",
    "transform_to.register(my_constraint, my_transform)\n",
    "\n",
    "```\n",
    "\n",
    "或作为参数化约束的装饰器:\n",
    "\n",
    "```py\n",
    "@transform_to.register(MyConstraintClass)\n",
    "def my_factory(constraint):\n",
    "    assert isinstance(constraint, MyConstraintClass)\n",
    "    return MyTransform(constraint.param1, constraint.param2)\n",
    "\n",
    "```\n",
    "\n",
    " 您可以通过创建新的[`ConstraintRegistry`](#torch.distributions.constraint_registry.ConstraintRegistry \"torch.distributions.constraint_registry.ConstraintRegistry\")创建自己的注册表.\n",
    "\n",
    "```py\n",
    "class torch.distributions.constraint_registry.ConstraintRegistry\n",
    "```\n",
    "\n",
    "注册表, 将约束链接到转换.\n",
    "\n",
    "```py\n",
    "register(constraint, factory=None)\n",
    "```\n",
    "\n",
    "在此注册表注册一个 [`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\") 子类. 用法:\n",
    "\n",
    "```py\n",
    "@my_registry.register(MyConstraintClass)\n",
    "def construct_transform(constraint):\n",
    "    assert isinstance(constraint, MyConstraint)\n",
    "    return MyTransform(constraint.arg_constraints)\n",
    "\n",
    "```\n",
    "\n",
    "参数: \n",
    "\n",
    "*   **constraint** (subclass of [`Constraint`](#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\")) –  [`Constraint`]的子类(#torch.distributions.constraints.Constraint \"torch.distributions.constraints.Constraint\"), 或者派生类的对象.\n",
    "*   **factory** (_callable_) – 可调用对象, 输入 constraint 对象返回 [`Transform`](#torch.distributions.transforms.Transform \"torch.distributions.transforms.Transform\") 对象.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

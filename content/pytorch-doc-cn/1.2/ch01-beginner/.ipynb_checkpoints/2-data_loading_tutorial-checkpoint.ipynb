{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 数据加载和处理教程\n",
    "\n",
    "> **作者**：[Sasank Chilamkurthy ](https://chsasank.github.io)\n",
    ">\n",
    "> 校验：[宁采晨](https://github.com/yangkae)\n",
    "\n",
    "解决任何机器学习问题都需要花费大量精力来准备数据。PyTorch提供了许多工具来简化数据加载过程，并有望使代码更具可读性。在本教程中，我们将学习如何从非平凡的数据集中加载和预处理/增强数据。\n",
    "\n",
    "要能够运行本教程中的代码，请确保已安装以下软件包：\n",
    "\n",
    "  * `scikit-image `：用于图像io和变换\n",
    "\n",
    "  * `pandas `：为了更方便地处理csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a77eba2f9de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "我们要处理的数据集是面部姿势数据集。这意味着对脸部的标注如下：\n",
    "\n",
    "![](../img/landmarked_face2.png)\n",
    "\n",
    "总体上，每个面孔都标注了68个不同的界标点。\n",
    "\n",
    "- 注意\n",
    "\n",
    "  从[此处](https://download.pytorch.org/tutorial/faces.zip)下载数据集，使图像位于名为`data/faces/`的目录中。该数据集实际上是通过对`imagenet`上的一些标记为“人脸”的图像应用良好的的[dlib姿态估计](https://blog.dlib.net/2014/08/real-time-face-pose-estimation.html)生成的。\n",
    "\n",
    "数据集包含一个带注释的csv文件，如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y\n",
    "    0805personali01.jpg,27,83,27,98, ... 84,134\n",
    "    1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们快速阅读CSV并获取（N，2）数组中的注释，其中N是特征点的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')\n",
    "\n",
    "n = 65\n",
    "img_name = landmarks_frame.iloc[n, 0]\n",
    "landmarks = landmarks_frame.iloc[n, 1:].as_matrix()\n",
    "landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "\n",
    "print('Image name: {}'.format(img_name))\n",
    "print('Landmarks shape: {}'.format(landmarks.shape))\n",
    "print('First 4 Landmarks: {}'.format(landmarks[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出：\n",
    "\n",
    "    Image name: person-7.jpg\n",
    "    Landmarks shape: (68, 2)\n",
    "    First 4 Landmarks: [[32. 65.]\n",
    "     [33. 76.]\n",
    "     [34. 86.]\n",
    "     [34. 97.]]\n",
    "\n",
    "\n",
    "让我们编写一个简单的辅助函数来显示图像及其特征点，并使用它来显示样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def show_landmarks(image, landmarks):\n",
    "        \"\"\"Show image with landmarks\"\"\"\n",
    "        plt.imshow(image)\n",
    "        plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "        plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "    plt.figure()\n",
    "    show_landmarks(io.imread(os.path.join('data/faces/', img_name)),\n",
    "                   landmarks)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sphx_glr_data_loading_tutorial_001.png](../img/sphx_glr_data_loading_tutorial_001.png)\n",
    "\n",
    "## 数据集类\n",
    "\n",
    "`torch.utils.data.Dataset`是表示数据集的抽象类。您的自定义数据集应继承`Dataset `，并覆盖下列方法：\n",
    "\n",
    "  * `__len__`，使得`len(dataset) `返回数据集的大小。\n",
    "  * `__getitem__`支持索引，使得`dataset[i]`可以用来获取第i个样本\n",
    "\n",
    "让我们为面部轮廓数据集创建一个数据集类。我们将在`__init__`中读取csv文件，在`__getitem__\n",
    "`中读取图像。由于所有图像不会立即存储在内存中，而是根据需要读取，因此可以提高内存效率。\n",
    "\n",
    "我们的数据集中的样品是一个字典`{'image': image, 'landmarks': landmarks}`。我们的数据集将采取一个可选的参数`transform\n",
    "`，以便可以对样本进行任何必需的处理。我们将在下一节看到`transform `的用处。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class FaceLandmarksDataset(Dataset):\n",
    "        \"\"\"Face Landmarks dataset.\"\"\"\n",
    "    \n",
    "        def __init__(self, csv_file, root_dir, transform=None):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                csv_file (string): Path to the csv file with annotations.\n",
    "                root_dir (string): Directory with all the images.\n",
    "                transform (callable, optional): Optional transform to be applied\n",
    "                    on a sample.\n",
    "            \"\"\"\n",
    "            self.landmarks_frame = pd.read_csv(csv_file)\n",
    "            self.root_dir = root_dir\n",
    "            self.transform = transform\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.landmarks_frame)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            if torch.is_tensor(idx):\n",
    "                idx = idx.tolist()\n",
    "    \n",
    "            img_name = os.path.join(self.root_dir,\n",
    "                                    self.landmarks_frame.iloc[idx, 0])\n",
    "            image = io.imread(img_name)\n",
    "            landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "            landmarks = np.array([landmarks])\n",
    "            landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "            sample = {'image': image, 'landmarks': landmarks}\n",
    "    \n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "    \n",
    "            return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们实例化该类并遍历数据样本。我们将打印前4个样本的大小并显示其特征点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "face_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                                    root_dir='data/faces/')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['landmarks'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_landmarks(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/sphx_glr_data_loading_tutorial_002.png)\n",
    "\n",
    "输出：\n",
    "\n",
    "    0 (324, 215, 3) (68, 2)\n",
    "    1 (500, 333, 3) (68, 2)\n",
    "    2 (250, 258, 3) (68, 2)\n",
    "    3 (434, 290, 3) (68, 2)\n",
    "\n",
    "## 转换（Transforms）\n",
    "\n",
    "从上面可以看到的一个问题是样本的大小不同。大多数神经网络期望图像的大小固定。因此，我们将需要编写一些前置代码。让我们创建三个转换：：\n",
    "\n",
    "  * `Rescale `：图像缩放\n",
    "  * `RandomCrop`：从图像中随机裁剪。这是数据扩充。\n",
    "  * `ToTensor`：将`numpy`格式的图片转换为`torch`格式的图片（我们需要换轴）。\n",
    "\n",
    "我们将它们编写为可调用的类，而不是简单的函数，这样就不必每次调用转换时都传递其参数。为此，我们只需要实现`__call__`方法，如果需要的话，可以实现`__init__`方法。然后我们可以使用这样的转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tsfm = Transform(params)\n",
    "    transformed_sample = tsfm(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面观察如何将这些变换同时应用于图像和特征点。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合转换（Compose transforms）\n",
    "\n",
    "现在，我们将转换应用于样本。\n",
    "\n",
    "假设我们要将图像的较短边重新缩放为256，然后从中随机裁剪一个尺寸为224的正方形。即我们要组成 `Rescale`和`RandomCrop`变换。 `torchvision.transforms.Compose`是一个简单的可调用类，它使我们可以执行此操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    scale = Rescale(256)\n",
    "    crop = RandomCrop(128)\n",
    "    composed = transforms.Compose([Rescale(256),\n",
    "                                   RandomCrop(224)])\n",
    "    \n",
    "    # Apply each of the above transforms on sample.\n",
    "    fig = plt.figure()\n",
    "    sample = face_dataset[65]\n",
    "    for i, tsfrm in enumerate([scale, crop, composed]):\n",
    "        transformed_sample = tsfrm(sample)\n",
    "    \n",
    "        ax = plt.subplot(1, 3, i + 1)\n",
    "        plt.tight_layout()\n",
    "        ax.set_title(type(tsfrm).__name__)\n",
    "        show_landmarks(**transformed_sample)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sphx_glr_data_loading_tutorial_003.png](../img/sphx_glr_data_loading_tutorial_003.png)\n",
    "\n",
    "## 遍历数据集\n",
    "\n",
    "让我们将所有这些放在一起以创建具有组合转换的数据集。总而言之，每次采样此数据集时：\n",
    "\n",
    "  * 从文件中即时读取图像\n",
    "  * 将变换应用于读取的图像\n",
    "  * 由于其中一种转换是随机的，因此在采样时会增加数据\n",
    "\n",
    "我们可以像之前一样通过一个`for i in range`循环遍历创建的数据集。    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    transformed_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                                               root_dir='data/faces/',\n",
    "                                               transform=transforms.Compose([\n",
    "                                                   Rescale(256),\n",
    "                                                   RandomCrop(224),\n",
    "                                                   ToTensor()\n",
    "                                               ]))\n",
    "    \n",
    "    for i in range(len(transformed_dataset)):\n",
    "        sample = transformed_dataset[i]\n",
    "    \n",
    "        print(i, sample['image'].size(), sample['landmarks'].size())\n",
    "    \n",
    "        if i == 3:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出:\n",
    "\n",
    "    0 torch.Size([3, 224, 224]) torch.Size([68, 2])\n",
    "    1 torch.Size([3, 224, 224]) torch.Size([68, 2])\n",
    "    2 torch.Size([3, 224, 224]) torch.Size([68, 2])\n",
    "    3 torch.Size([3, 224, 224]) torch.Size([68, 2])\n",
    "\n",
    "\n",
    "但是，通过使用简单的`for`循环迭代数据，我们失去了很多功能。特别是，我们错过了：\n",
    "\n",
    "  * 批量处理数据\n",
    "  * 整理数据\n",
    "  * 使用`multiprocessing`并行加载数据。\n",
    "\n",
    "`torch.utils.data.DataLoader`是提供所有这些功能的迭代器。下面使用的参数应该清楚。一个重要参数是`collate_fn`。您可以使用指定要精确批处理样品的数量`collate_fn`。但是，默认排序规则在大多数情况下都可以正常工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "# Helper function to show a batch\n",
    "def show_landmarks_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = \\\n",
    "            sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    grid_border_size = 2\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,\n",
    "                    landmarks_batch[i, :, 1].numpy() + grid_border_size,\n",
    "                    s=10, marker='.', c='r')\n",
    "\n",
    "        plt.title('Batch from dataloader')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['landmarks'].size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        plt.figure()\n",
    "        show_landmarks_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ![sphx_glr_data_loading_tutorial_004.png](../img/sphx_glr_data_loading_tutorial_004.png)\n",
    "\n",
    "输出：\n",
    "\n",
    "    0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])\n",
    "    1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])\n",
    "    2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])\n",
    "    3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2])\n",
    "\n",
    "\n",
    "## 后记：torchvision\n",
    "\n",
    "在本教程中，我们已经看到了如何构造和使用数据集，转换数据和的数据加载。`torchvision`软件包提供了一些常见的数据集和转换。您甚至不必编写自定义类。`torchvision`中可用的更通用的数据集之一是`ImageFolder`。假定图像的组织方式如下：\n",
    "\n",
    "    root/ants/xxx.png\n",
    "    root/ants/xxy.jpeg\n",
    "    root/ants/xxz.png\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    root/bees/123.jpg\n",
    "    root/bees/nsdf3.png\n",
    "    root/bees/asd932_.png\n",
    "\n",
    "其中“ants”，“bees”等是类标签。同样也可以使用`PIL.Image`中的操作像 `RandomHorizontalFlip`和`Scale`来进行通用转换。您可以使用以下代码创建一个数据加载器：    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch\n",
    "    from torchvision import transforms, datasets\n",
    "    \n",
    "    data_transform = transforms.Compose([\n",
    "            transforms.RandomSizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train',\n",
    "                                               transform=data_transform)\n",
    "    dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset,\n",
    "                                                 batch_size=4, shuffle=True,\n",
    "                                                 num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练代码示例，请参见[迁移学习教程](transfer_learning_tutorial.md) \n",
    "\n",
    "**脚本的总运行时间：** （0分钟59.213秒）\n",
    "\n",
    "**下载python文件:**\n",
    "[data_loading_tutorial.py](https://github.com/pytorch/tutorials/blob/master/beginner_source/data_loading_tutorial.py)\n",
    "\n",
    "**下载 Jupyter notebook文件:**\n",
    "[data_loading_tutorial.ipynb](https://pytorch.org/tutorials/_downloads/21adbaecd47a412f8143afb1c48f05a6/data_loading_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&guid=ON&script=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

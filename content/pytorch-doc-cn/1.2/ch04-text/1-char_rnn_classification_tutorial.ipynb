{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP From Scratch：使用char-RNN对姓氏进行分类\n",
    "\n",
    "> 作者：[Sean Robertson](https://github.com/spro/practical-pytorch)\n",
    ">\n",
    "> 译者：[松鼠](https://github.com/HelWireless)\n",
    ">\n",
    "> 校验：[松鼠](https://github.com/HelWireless)、[Aidol](https://github.com/Aidol)\n",
    "\n",
    "我们将构建和训练基本的char-RNN来对单词进行分类。本教程以及以下两个教程展示了如何“从头开始”为NLP建模进行预处理数据，尤其是不使用Torchtext的许多便利功能，因此您可以了解NLP建模的预处理是如何从低层次进行的。\n",
    "\n",
    "char-RNN将单词作为一系列字符读取,在每个步骤输出预测和“隐藏状态”，将其先前的隐藏状态输入到每个下一步。我们将最终的预测作为输出，即单词属于哪个类别。\n",
    "\n",
    "具体来说，我们将训练起源于18种语言的数千种姓氏，并根据拼写来预测姓氏来自哪种语言：\n",
    "\n",
    "    \n",
    "    \n",
    "    $ python predict.py Hinton\n",
    "    (-0.47) Scottish\n",
    "    (-1.52) English\n",
    "    (-3.57) Irish\n",
    "    \n",
    "    $ python predict.py Schmidhuber\n",
    "    (-0.19) German\n",
    "    (-2.48) Czech\n",
    "    (-2.68) Dutch\n",
    "    \n",
    "\n",
    "**建议：**\n",
    "\n",
    "假设你已经至少安装PyTorch，知道Python和理解张量：\n",
    "\n",
    "  * [pytorch](https://pytorch.org/)安装说明\n",
    "  * 观看[《PyTorch进行深度学习：60分钟速成》](../beginner/deep_learning_60min_blitz.html)来开始学习pytorch\n",
    "  * [通过实例深入学习PyTorch](../beginner/pytorch_with_examples.html)\n",
    "  * [pytorch为前torch用户的提供的指南](../beginner/former_torchies_tutorial.html)\n",
    "\n",
    "下面这些是了解RNNs以及它们如何工作的相关联接：\n",
    "\n",
    "  * [回归神经网络](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)展示真实生活中的一系列例子\n",
    "  * [理解LSTM网络](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)虽然是关于LSTMs的但也对RNNs有很多详细的讲解\n",
    "\n",
    "## 准备数据\n",
    "\n",
    ">* Note\n",
    ">从[此处](https://download.pytorch.org/tutorial/data.zip)下载数据，并将其解压到当前目录。\n",
    "\n",
    "包含了在`data/names `目录被命名为`[Language] .txt`\n",
    "的18个文本文件。每个文件都包含了一堆姓氏，每行一个名字，大多都已经罗马字母化了（但我们仍然需要从Unicode转换到到ASCII）。\n",
    "\n",
    "我们将得到一个字典，列出每种语言的名称列表 。通用变量`category`和`line`（在本例中为语言和名称）用于以后的扩展。`{language: [names ...]}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from __future__ import unicode_literals, print_function, division\n",
    "    from io import open\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    def findFiles(path): return glob.glob(path)\n",
    "    \n",
    "    print(findFiles('data/names/*.txt'))\n",
    "    \n",
    "    import unicodedata\n",
    "    import string\n",
    "    \n",
    "    all_letters = string.ascii_letters + \" .,;'\"\n",
    "    n_letters = len(all_letters)\n",
    "    \n",
    "    # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "    # 作用就是把Unicode转换为ASCII\n",
    "    def unicodeToAscii(s):\n",
    "        return ''.join(\n",
    "        # NFD表示字符应该分解为多个组合字符表示\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in all_letters\n",
    "        )\n",
    "    \n",
    "    print(unicodeToAscii('Ślusàrski'))\n",
    "    \n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    \n",
    "    # Read a file and split into lines\n",
    "    def readLines(filename):\n",
    "        lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "        return [unicodeToAscii(line) for line in lines]\n",
    "    \n",
    "    for filename in findFiles('data/names/*.txt'):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(filename)\n",
    "        category_lines[category] = lines\n",
    "    \n",
    "    n_categories = len(all_categories)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "输出：\n",
    "```shell \n",
    "    ['data/names/French.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/Polish.txt', 'data/names/Scottish.txt', 'data/names/Chinese.txt', 'data/names/English.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Japanese.txt', 'data/names/German.txt', 'data/names/Russian.txt', 'data/names/Korean.txt', 'data/names/Arabic.txt', 'data/names/Greek.txt', 'data/names/Vietnamese.txt', 'data/names/Spanish.txt', 'data/names/Irish.txt']\n",
    "    \n",
    "    Slusarski\n",
    "```    \n",
    "\n",
    "现在，我们有了`category_lines`字典，将每个类别（语言）映射到行（姓氏）列表。我们还保持`all_categories`（只是一种语言列表）和`n_categories`为可追加状态，供后续的调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出:\n",
    "```shell\n",
    "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将姓氏转化为张量\n",
    "\n",
    "我们已经处理好了所有的姓氏，现在我们需要将它们转换为张量以使用它们。\n",
    "\n",
    "为了表示单个字母，我们使用大小为`<1 x n letters>`的“独热向量” 。一个独热向量就是在字母索引处填充1，其他都填充为0，例，`\"b\" = <0 1 0 0 0 ...>`\n",
    "\n",
    "为了表达一个单词，我们将一堆字母合并成2D矩阵，其中矩阵的大小为`<line_length x 1 x n_letters>`\n",
    "\n",
    "额外的1维是因为PyTorch假设所有东西都是成批的-我们在这里只使用1的批处理大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch\n",
    "    \n",
    "    # Find letter index from all_letters, e.g. \"a\" = 0\n",
    "    def letterToIndex(letter):\n",
    "        return all_letters.find(letter)\n",
    "    \n",
    "    # Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "    def letterToTensor(letter):\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0][letterToIndex(letter)] = 1\n",
    "        return tensor\n",
    "    \n",
    "    # Turn a line into a <line_length x 1 x n_letters>,\n",
    "    # or an array of one-hot letter vectors\n",
    "    def lineToTensor(line):\n",
    "        tensor = torch.zeros(len(line), 1, n_letters)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][letterToIndex(letter)] = 1\n",
    "        return tensor\n",
    "    \n",
    "    print(letterToTensor('J'))\n",
    "    \n",
    "    print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出:\n",
    "```shell\n",
    "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
    "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "             0., 0., 0.]])\n",
    "\n",
    "torch.Size([5, 1, 57])    \n",
    "```\n",
    "## 创建网络\n",
    "\n",
    "在进行自动求导之前，在Torch中创建一个递归神经网络需要在多个时间状态上克隆图的参数。图保留了隐藏状态和梯度，这些状态和梯度现在完全由图本身处理。这意味着您可以以非常“单纯”的方式将RNN作为常规的前馈网络来实现。\n",
    "\n",
    "这个RNN模块（大部分是从[PyTorch for Torch用户教程](https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net)中复制的）只有2个线性层，它们在输入和隐藏状态下运行，输出之后是LogSoftmax层。\n",
    "\n",
    "![RNN.jpg](https://camo.githubusercontent.com/f8a843661e448e1a75f8319a2eea860ebf09794f/68747470733a2f2f692e696d6775722e636f6d2f5a32786279534f2e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "    import torch.nn as nn\n",
    "    \n",
    "    class RNN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super(RNN, self).__init__()\n",
    "    \n",
    "            self.hidden_size = hidden_size\n",
    "    \n",
    "            self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "            self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "            self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "        def forward(self, input, hidden):\n",
    "            combined = torch.cat((input, hidden), 1)\n",
    "            hidden = self.i2h(combined)\n",
    "            output = self.i2o(combined)\n",
    "            output = self.softmax(output)\n",
    "            return output, hidden\n",
    "    \n",
    "        def initHidden(self):\n",
    "            return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "    n_hidden = 128\n",
    "    rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "运行网络的步骤是，首先我们需要输入（在本例中为当前字母的张量）和先前的隐藏状态（首先将其初始化为零）。我们将返回输出（每种语言的概率）和下一个隐藏状态（我们将其保留用于下一步）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input = letterToTensor('A')\n",
    "    hidden =torch.zeros(1, n_hidden)\n",
    "    \n",
    "    output, next_hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "为了提高效率，我们不想为每个步骤都创建一个新的Tensor，因此我们将使用`lineToTensor`加切片的方式来代替`letterToTensor`。这可以通过预先计算一批张量来进一步优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input = lineToTensor('Albert')\n",
    "    hidden = torch.zeros(1, n_hidden)\n",
    "    \n",
    "    output, next_hidden = rnn(input[0], hidden)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "输出:\n",
    "```shell \n",
    "    tensor([[-2.8636, -2.8199, -2.8899, -2.9073, -2.9117, -2.8644, -2.9027, -2.9334,\n",
    "             -2.8705, -2.8383, -2.8892, -2.9161, -2.8215, -2.9996, -2.9423, -2.9116,\n",
    "             -2.8750, -2.8862]], grad_fn=<LogSoftmaxBackward>)\n",
    "```    \n",
    "\n",
    "正如你看到的输出为`<1  × n_categories>`的张量，其中每一个值都是该类别的可能性（数值越大可能性越高）。\n",
    "\n",
    "## 训练\n",
    "\n",
    "### 准备训练\n",
    "\n",
    "在训练之前，我们需要做一些辅助函数。首先是解释网络的输出，我们知道这是每个类别的可能性。我们可以用`Tensor.topk`来获取最大值对应的索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def categoryFromOutput(output):\n",
    "        top_n, top_i = output.topk(1)\n",
    "        category_i = top_i[0].item()\n",
    "        return all_categories[category_i], category_i\n",
    "    \n",
    "    print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "输出:\n",
    "```shell \n",
    "    ('Czech', 1)\n",
    "```\n",
    "\n",
    "我们也将需要一个快速的方法来获得一个训练例子（姓氏和其所属语言）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    import random\n",
    "    \n",
    "    def randomChoice(l):\n",
    "        return l[random.randint(0, len(l) - 1)]\n",
    "    \n",
    "    def randomTrainingExample():\n",
    "        category = randomChoice(all_categories)\n",
    "        line = randomChoice(category_lines[category])\n",
    "        category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        line_tensor = lineToTensor(line)\n",
    "        return category, line, category_tensor, line_tensor\n",
    "    \n",
    "    for i in range(10):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        print('category =', category, '\\t // \\t line =', line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "输出:\n",
    "\n",
    "```shell    \n",
    "category =  Dutch \t // \t line =  Ryskamp\n",
    "category =  Spanish \t // \t line =  Iniguez\n",
    "category =  Vietnamese \t // \t line =  Thuy\n",
    "category =  Italian \t // \t line =  Nacar\n",
    "category =  Vietnamese \t // \t line =  Le\n",
    "category =  French \t // \t line =  Tremblay\n",
    "category =  Russian \t // \t line =  Bakhchivandzhi\n",
    "category =  Irish \t // \t line =  Kavanagh\n",
    "category =  Irish \t // \t line =  O'Shea\n",
    "category =  Spanish \t // \t line =  Losa\n",
    "```\n",
    "\n",
    "### 网络训练\n",
    "\n",
    "现在，训练该网络所需要做的就是向它喂入大量训练样例，进行预测，并告诉它预测的是否正确。\n",
    "\n",
    "最后因为RNN的最后一层是`nn.LogSoftmax`,所以我们选择损失函数`nn.NLLLoss`比较合适。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个循环的训练将：\n",
    "\n",
    "  * 创建输入和目标张量\n",
    "  * 创建一个零初始隐藏状态\n",
    "  * 读取每个字母\n",
    "    * 保持隐藏状态到下一个字母\n",
    "  * 比较最后输出和目标\n",
    "  * 进行反向传播\n",
    "  * 返回输出值和损失函数的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    learning_rate = 0.005 \n",
    "    # If you set this too high, it might explode. If too low, it might not learn\n",
    "    \n",
    "    def train(category_tensor, line_tensor):\n",
    "        hidden = rnn.initHidden()\n",
    "    \n",
    "        rnn.zero_grad()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "        loss = criterion(output, category_tensor)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Add parameters' gradients to their values, multiplied by learning rate\n",
    "        for p in rnn.parameters():\n",
    "        # 下面一行代码的作用效果为 p.data = p.data -learning_rate*p.grad.data，更新权重\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "        return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们只需要运行大量样例。由于`train`函数同时返回`output`和`loss`，因此我们可以打印其猜测并跟踪绘制损失。由于有1000个样例，因此我们仅打印每个`print_every`样例，并对损失进行平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import time\n",
    "    import math\n",
    "    \n",
    "    n_iters = 100000\n",
    "    print_every = 5000\n",
    "    plot_every = 1000\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Keep track of losses for plotting\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    \n",
    "    def timeSince(since):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        output, loss = train(category_tensor, line_tensor)\n",
    "        current_loss += loss\n",
    "    \n",
    "        # Print iter number, loss, name and guess\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "    \n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出:\n",
    "```shell\n",
    "    5000 5% (0m 7s) 2.7482 Silje / French ✗ (Dutch)\n",
    "    10000 10% (0m 15s) 1.5569 Lillis / Greek ✓\n",
    "    15000 15% (0m 22s) 2.7729 Burt / Korean ✗ (English)\n",
    "    20000 20% (0m 30s) 1.1036 Zhong / Chinese ✓\n",
    "    25000 25% (0m 38s) 1.7088 Sarraf / Portuguese ✗ (Arabic)\n",
    "    30000 30% (0m 45s) 0.7595 Benivieni / Italian ✓\n",
    "    35000 35% (0m 53s) 1.2900 Arreola / Italian ✗ (Spanish)\n",
    "    40000 40% (1m 0s) 2.3171 Gass / Arabic ✗ (German)\n",
    "    45000 45% (1m 8s) 3.1630 Stoppelbein / Dutch ✗ (German)\n",
    "    50000 50% (1m 15s) 1.7478 Berger / German ✗ (French)\n",
    "    55000 55% (1m 23s) 1.3516 Almeida / Spanish ✗ (Portuguese)\n",
    "    60000 60% (1m 31s) 1.8843 Hellewege / Dutch ✗ (German)\n",
    "    65000 65% (1m 38s) 1.7374 Moreau / French ✓\n",
    "    70000 70% (1m 46s) 0.5718 Naifeh / Arabic ✓\n",
    "    75000 75% (1m 53s) 0.6268 Zhui / Chinese ✓\n",
    "    80000 80% (2m 1s) 2.2226 Dasios / Portuguese ✗ (Greek)\n",
    "    85000 85% (2m 9s) 1.3690 Walter / Scottish ✗ (German)\n",
    "    90000 90% (2m 16s) 0.5329 Zhang / Chinese ✓\n",
    "    95000 95% (2m 24s) 3.4474 Skala / Czech ✗ (Polish)\n",
    "    100000 100% (2m 31s) 1.4720 Chi / Korean ✗ (Chinese)\n",
    "```\n",
    "\n",
    "### 绘制结果\n",
    "\n",
    "从绘制`all_losses`的历史损失图可以看出网络的学习："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as ticker\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(all_losses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/sphx_glr_char_rnn_classification_tutorial_001.png](https://pytorch.org/tutorials/_images/sphx_glr_char_rnn_classification_tutorial_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价结果\n",
    "\n",
    "为了了解网络在不同类别上的表现如何，我们将创建一个混淆矩阵，包含姓氏属于的实际语言（行）和网络猜测的是哪种语言（列）。要计算混淆矩阵，将使用`evaluate()`通过网络来评测一些样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "    # Keep track of correct guesses in a confusion matrix\n",
    "    confusion = torch.zeros(n_categories, n_categories)\n",
    "    n_confusion = 10000\n",
    "    \n",
    "    # Just return an output given a line\n",
    "    def evaluate(line_tensor):\n",
    "        hidden = rnn.initHidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "        return output\n",
    "    \n",
    "    # Go through a bunch of examples and record which are correctly guessed\n",
    "    for i in range(n_confusion):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        output = evaluate(line_tensor)\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category_i = all_categories.index(category)\n",
    "        confusion[category_i][guess_i] += 1\n",
    "    \n",
    "    # Normalize by dividing every row by its sum\n",
    "    for i in range(n_categories):\n",
    "        confusion[i] = confusion[i] / confusion[i].sum()\n",
    "    \n",
    "    # Set up plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion.numpy())\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "    ax.set_yticklabels([''] + all_categories)\n",
    "    \n",
    "    # Force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # sphinx_gallery_thumbnail_number = 2\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/sphx_glr_char_rnn_classification_tutorial_002.png](https://pytorch.org/tutorials/_images/sphx_glr_char_rnn_classification_tutorial_002.png)\n",
    "\n",
    "您可以从主轴上挑出一些亮点，以显示错误猜测的语言，例如，中文（朝鲜语）和西班牙语（意大利语）。它似乎与希腊语搭预测得很好，而英语预测的很差（可能是因为与其他语言重叠）。\n",
    "\n",
    "### 运行用户输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(input_line, n_predictions=3):\n",
    "        print('\\n> %s' % input_line)\n",
    "        with torch.no_grad():\n",
    "            output = evaluate(lineToTensor(input_line))\n",
    "    \n",
    "            # Get top N categories\n",
    "            topv, topi = output.topk(n_predictions, 1, True)\n",
    "            predictions = []\n",
    "    \n",
    "            for i in range(n_predictions):\n",
    "                value = topv[0][i].item()\n",
    "                category_index = topi[0][i].item()\n",
    "                print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "                predictions.append([value, all_categories[category_index]])\n",
    "    \n",
    "    predict('Dovesky')\n",
    "    predict('Jackson')\n",
    "    predict('Satoshi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out:\n",
    "```shell\n",
    "    > Dovesky\n",
    "    (-0.47) Russian\n",
    "    (-1.30) Czech\n",
    "    (-2.90) Polish\n",
    "    \n",
    "    > Jackson\n",
    "    (-1.04) Scottish\n",
    "    (-1.72) English\n",
    "    (-1.74) Russian\n",
    "    \n",
    "    > Satoshi\n",
    "    (-0.32) Japanese\n",
    "    (-2.63) Polish\n",
    "    (-2.71) Italian\n",
    "```\n",
    "\n",
    "实际[PyTorch存储库](https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification)中的脚本的最终版本将上述代码分成几个文件：\n",
    "\n",
    "  * `data.py`（加载文件）\n",
    "  * `model.py`（定义RNN）\n",
    "  * `train.py`（训练）\n",
    "  * `predict.py`（`predict()`与命令行参数一起运行）\n",
    "  * `server.py`（通过`bottle.py`将预测用作JSON API）\n",
    "\n",
    "运行`train.py`训练并保存网络。\n",
    "\n",
    "用`predict.py`脚本并加上姓氏运行以查看预测："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell    \n",
    "    $ python predict.py Hazaki\n",
    "    (-0.42) Japanese\n",
    "    (-1.39) Polish\n",
    "    (-3.51) Czech\n",
    "```    \n",
    "\n",
    "运行`server.py`，查看[http://localhost:5533/Yourname ](http://localhost:5533/Yourname)获得预测的JSON输出。\n",
    "\n",
    "## 练习\n",
    "\n",
    "+ 尝试使用line-> category的其他数据集，例如：\n",
    "    - 任何单词->语言\n",
    "    - 名->性别\n",
    "    - 角色名称->作家\n",
    "    - 页面标题-> Blog或subreddit\n",
    "+ 通过更大和/或结构更好的网络获得更好的结果\n",
    "    - 添加更多线性层\n",
    "    - 尝试nn.LSTM和nn.GRU图层\n",
    "    - 将多个这些RNN合并为更高级别的网络\n",
    "\n",
    "**脚本的总运行时间：** （2分钟42.458秒）"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
